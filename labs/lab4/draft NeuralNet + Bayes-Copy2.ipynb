{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "import tensorboard\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(url):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        url (string): the url of the file\n",
    "    Returns:\n",
    "        df: the dataframe filled\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "def KnnAddedFeatures(X,Y):\n",
    "    \"\"\"\n",
    "    Args :\n",
    "        X, features, Y labels \n",
    "    Returns :\n",
    "        tuples corresponding to new features\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    knn = RadiusNeighborsClassifier(radius=0.5, weights = 'distance')\n",
    "    knn.fit(X,Y)\n",
    "    a = knn.predict(X)\n",
    "    print(\"coucou\",a)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def NaiveAddedFeatures(X,y):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(abs(X), y)\n",
    "    res = clf.predict_proba(X)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_class_binary = {'BIG_BAND':[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "          'BLUES_CONTEMPORARY':  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "          'COUNTRY_TRADITIONAL': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "          'DANCE':               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "          'ELECTRONICA':         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "          'EXPERIMENTAL':        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "          'FOLK_INTERNATIONAL':  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "          'GOSPEL':              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'GRUNGE_EMO':          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'HIP_HOP_RAP':         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'JAZZ_CLASSIC':        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'METAL_ALTERNATIVE':   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'METAL_DEATH':         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'METAL_HEAVY':         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'POP_CONTEMPORARY':    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'POP_INDIE':           [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'POP_LATIN':           [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'PUNK':                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'REGGAE':              [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'RNB_SOUL':            [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'ROCK_ALTERNATIVE':    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'ROCK_COLLEGE':        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'ROCK_CONTEMPORARY':   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'ROCK_HARD':           [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'ROCK_NEO_PSYCHEDELIA':[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_class_discrete_to_binary = {1:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                                  2:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                                  3:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                                  4:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                                  5:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                                  6:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                                  7:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                                  8:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  9:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 10:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 11:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 12:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 13:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 14:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 15:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 16:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 17:[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 18:[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 19:[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 20:[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 21:[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 22:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 23:[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 24:[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 25:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_class = {'BIG_BAND':1,\n",
    "          'BLUES_CONTEMPORARY':2,\n",
    "          'COUNTRY_TRADITIONAL':3,\n",
    "          'DANCE':4,\n",
    "          'ELECTRONICA':5,\n",
    "          'EXPERIMENTAL':6,\n",
    "          'FOLK_INTERNATIONAL':7,\n",
    "          'GOSPEL':8,\n",
    "          'GRUNGE_EMO':9,\n",
    "          'HIP_HOP_RAP':10,\n",
    "          'JAZZ_CLASSIC':11,\n",
    "          'METAL_ALTERNATIVE':12,\n",
    "          'METAL_DEATH':13,\n",
    "          'METAL_HEAVY':14,\n",
    "          'POP_CONTEMPORARY':15,\n",
    "          'POP_INDIE':16,\n",
    "          'POP_LATIN':17,\n",
    "          'PUNK':18,\n",
    "          'REGGAE':19,\n",
    "          'RNB_SOUL':20,\n",
    "          'ROCK_ALTERNATIVE':21,\n",
    "          'ROCK_COLLEGE':22,\n",
    "          'ROCK_CONTEMPORARY':23,\n",
    "          'ROCK_HARD':24,\n",
    "          'ROCK_NEO_PSYCHEDELIA':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom metrics function to calculate the F1 score\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMultiPerceptron(nb_layers,nb_perceptron,nb_iteration,learning_rate,nb_essai,path):\n",
    "    \n",
    "    \n",
    "    #Extraire les données des ensembles \n",
    "    dataset = read_csv(path)\n",
    "    dataset.head()\n",
    "    #print(dataset.shape[1])\n",
    "    labels = dataset.loc[:,dataset.columns == (dataset.shape[1]-1)]\n",
    "    labels = labels.to_numpy()\n",
    "    y = []\n",
    "    y_u = []\n",
    "    for e in labels:\n",
    "        y.append(music_class[e[0]])\n",
    "    \n",
    "    dataset = dataset.drop([0,1,(dataset.shape[1]-1)],axis=1)\n",
    "    \n",
    "    X = dataset.to_numpy()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    #Create a Multinomial Classifier\n",
    "    #mlt = MultinomialNB()\n",
    "    \n",
    "    #Train the classifier over all the samples\n",
    "    #mlt.fit(abs(X),y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "    #Predict probabilities which will become new features over each data set\n",
    "    #nf_train = mlt.predict_proba(X_train)\n",
    "    #nf_test = mlt.predict_proba(X_test)\n",
    "    \n",
    "    # scale the data : réduire le execution time\n",
    "    scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    X_train = scaling.transform(X_train)\n",
    "    X_test = scaling.transform(X_test)\n",
    "    \n",
    "    #Add of new features \n",
    "    #X_train = np.concatenate((X_train,nf_train),axis=1)\n",
    "    #X_test = np.concatenate((X_test,nf_test),axis=1)\n",
    "    \n",
    "    y_train_binary = []\n",
    "    for e in y_train:\n",
    "        y_train_binary.append(music_class_discrete_to_binary[e])\n",
    "    \n",
    "    y_train_binary = np.array(y_train_binary)\n",
    "    \n",
    "\n",
    "        \n",
    "    y_test_binary = []\n",
    "    for e in y_test:\n",
    "        y_test_binary.append(music_class_discrete_to_binary[e])\n",
    "        \n",
    "    y_test_binary = np.array(y_test_binary)\n",
    "    y_test = y_test_binary\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_binary, test_size=0.20)\n",
    "    #X_val = scaling.transform(X_val)\n",
    "    \n",
    "    \n",
    "    #Create the model \n",
    "    model = Sequential()\n",
    "    #First hidden layer with specified number of percpetrons \n",
    "    model.add(Dense(units=nb_perceptron, activation='relu', input_dim = X_train.shape[1]))\n",
    "    \n",
    "    for i in range(nb_layers-1):\n",
    "        #Next hidden layers with specified number of percpetrons \n",
    "        model.add(Dense(units=nb_perceptron, activation='relu'))\n",
    "    \n",
    "    #Last layer, the activation layer with 2 outputs\n",
    "    model.add(Dense(units = 25, activation='softmax'))\n",
    "    \n",
    "    #Compile the model\n",
    "    sgd = SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy',f1])\n",
    "    \n",
    "    #3. Entraîner \n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              epochs=nb_iteration, batch_size=100)\n",
    "  \n",
    "    \"\"\"\n",
    "    # Plot training & validation accuracy values\n",
    "    accuracy = pd.DataFrame(history.history['accuracy'])\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"Accuracy\")\n",
    "    print(accuracy.head(nb_iteration))\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    f1score = pd.DataFrame(history.history['f1'])\n",
    "    plt.plot(history.history['f1'])\n",
    "    plt.plot(history.history['val_f1'])\n",
    "    plt.title('Model F1 score')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"F1 score\")\n",
    "    print(f1score.head(nb_iteration))\n",
    "    \n",
    "    \n",
    "    #4 Evaluer le modèle\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print(\"---TEST---\")\n",
    "    print(score)\n",
    "    \"\"\"\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.8539 - accuracy: 0.1441 - f1: 3.0620e-04 - val_loss: 2.8033 - val_accuracy: 0.1593 - val_f1: 0.0122\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.7686 - accuracy: 0.1669 - f1: 0.0025 - val_loss: 2.7543 - val_accuracy: 0.1716 - val_f1: 6.8689e-04\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.7333 - accuracy: 0.1759 - f1: 0.0053 - val_loss: 2.7226 - val_accuracy: 0.1770 - val_f1: 0.0046\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.7172 - accuracy: 0.1811 - f1: 0.0086 - val_loss: 2.7441 - val_accuracy: 0.1745 - val_f1: 0.0169\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.7041 - accuracy: 0.1835 - f1: 0.0122 - val_loss: 2.7099 - val_accuracy: 0.1792 - val_f1: 0.0049\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6901 - accuracy: 0.1874 - f1: 0.0163 - val_loss: 2.6857 - val_accuracy: 0.1865 - val_f1: 0.0286\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6817 - accuracy: 0.1893 - f1: 0.0188 - val_loss: 2.6865 - val_accuracy: 0.1865 - val_f1: 0.0175\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.6745 - accuracy: 0.1916 - f1: 0.0211 - val_loss: 2.6758 - val_accuracy: 0.1898 - val_f1: 0.0221\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.6686 - accuracy: 0.1940 - f1: 0.0224 - val_loss: 2.6895 - val_accuracy: 0.1874 - val_f1: 0.0267\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6623 - accuracy: 0.1944 - f1: 0.0245 - val_loss: 2.6794 - val_accuracy: 0.1901 - val_f1: 0.0210\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6566 - accuracy: 0.1975 - f1: 0.0269 - val_loss: 2.6682 - val_accuracy: 0.1897 - val_f1: 0.0218\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6542 - accuracy: 0.1965 - f1: 0.0255 - val_loss: 2.6685 - val_accuracy: 0.1935 - val_f1: 0.0206\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.6488 - accuracy: 0.1972 - f1: 0.0266 - val_loss: 2.6684 - val_accuracy: 0.1929 - val_f1: 0.0194\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6444 - accuracy: 0.1995 - f1: 0.0278 - val_loss: 2.6680 - val_accuracy: 0.1925 - val_f1: 0.0204\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6415 - accuracy: 0.2002 - f1: 0.0284 - val_loss: 2.6723 - val_accuracy: 0.1916 - val_f1: 0.0303\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6373 - accuracy: 0.2004 - f1: 0.0293 - val_loss: 2.6570 - val_accuracy: 0.1960 - val_f1: 0.0181\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6331 - accuracy: 0.2015 - f1: 0.0300 - val_loss: 2.6566 - val_accuracy: 0.1967 - val_f1: 0.0237\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6321 - accuracy: 0.2027 - f1: 0.0302 - val_loss: 2.6526 - val_accuracy: 0.1997 - val_f1: 0.0204\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.6278 - accuracy: 0.2037 - f1: 0.0316 - val_loss: 2.6568 - val_accuracy: 0.1982 - val_f1: 0.0246\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6254 - accuracy: 0.2037 - f1: 0.0314 - val_loss: 2.6507 - val_accuracy: 0.1970 - val_f1: 0.0341\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6224 - accuracy: 0.2049 - f1: 0.0321 - val_loss: 2.6626 - val_accuracy: 0.1959 - val_f1: 0.0207\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6177 - accuracy: 0.2067 - f1: 0.0331 - val_loss: 2.6532 - val_accuracy: 0.1981 - val_f1: 0.0266\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6163 - accuracy: 0.2068 - f1: 0.0330 - val_loss: 2.6414 - val_accuracy: 0.2000 - val_f1: 0.0332\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6145 - accuracy: 0.2082 - f1: 0.0338 - val_loss: 2.6690 - val_accuracy: 0.1921 - val_f1: 0.0355\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6124 - accuracy: 0.2062 - f1: 0.0337 - val_loss: 2.6491 - val_accuracy: 0.1990 - val_f1: 0.0445\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6081 - accuracy: 0.2090 - f1: 0.0350 - val_loss: 2.6469 - val_accuracy: 0.1964 - val_f1: 0.0239\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6051 - accuracy: 0.2087 - f1: 0.0352 - val_loss: 2.6494 - val_accuracy: 0.1997 - val_f1: 0.0269\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6038 - accuracy: 0.2096 - f1: 0.0354 - val_loss: 2.6516 - val_accuracy: 0.1988 - val_f1: 0.0346\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6015 - accuracy: 0.2108 - f1: 0.0360 - val_loss: 2.6574 - val_accuracy: 0.1936 - val_f1: 0.0275\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5990 - accuracy: 0.2110 - f1: 0.0365 - val_loss: 2.6556 - val_accuracy: 0.1964 - val_f1: 0.0291\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5976 - accuracy: 0.2113 - f1: 0.0382 - val_loss: 2.6507 - val_accuracy: 0.1979 - val_f1: 0.0341\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5932 - accuracy: 0.2140 - f1: 0.0377 - val_loss: 2.6450 - val_accuracy: 0.1993 - val_f1: 0.0329\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5929 - accuracy: 0.2115 - f1: 0.0388 - val_loss: 2.6415 - val_accuracy: 0.2014 - val_f1: 0.0412\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5911 - accuracy: 0.2128 - f1: 0.0388 - val_loss: 2.6519 - val_accuracy: 0.1967 - val_f1: 0.0438\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5878 - accuracy: 0.2142 - f1: 0.0396 - val_loss: 2.6404 - val_accuracy: 0.2015 - val_f1: 0.0418\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5859 - accuracy: 0.2133 - f1: 0.0388 - val_loss: 2.6381 - val_accuracy: 0.2014 - val_f1: 0.0340\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5845 - accuracy: 0.2138 - f1: 0.0399 - val_loss: 2.6487 - val_accuracy: 0.1998 - val_f1: 0.0318\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.5819 - accuracy: 0.2155 - f1: 0.0404 - val_loss: 2.6459 - val_accuracy: 0.2004 - val_f1: 0.0376\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.5816 - accuracy: 0.2155 - f1: 0.0401 - val_loss: 2.6437 - val_accuracy: 0.2019 - val_f1: 0.0347\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.5786 - accuracy: 0.2159 - f1: 0.0409 - val_loss: 2.6475 - val_accuracy: 0.1991 - val_f1: 0.0311\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5750 - accuracy: 0.2174 - f1: 0.0411 - val_loss: 2.6371 - val_accuracy: 0.2021 - val_f1: 0.0478\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5757 - accuracy: 0.2177 - f1: 0.0420 - val_loss: 2.6577 - val_accuracy: 0.1978 - val_f1: 0.0407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5740 - accuracy: 0.2172 - f1: 0.0425 - val_loss: 2.6492 - val_accuracy: 0.2026 - val_f1: 0.0378\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5709 - accuracy: 0.2174 - f1: 0.0426 - val_loss: 2.6555 - val_accuracy: 0.1987 - val_f1: 0.0410\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5707 - accuracy: 0.2178 - f1: 0.0436 - val_loss: 2.6631 - val_accuracy: 0.1980 - val_f1: 0.0475\n",
      "Epoch 46/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5689 - accuracy: 0.2176 - f1: 0.0434 - val_loss: 2.6473 - val_accuracy: 0.2014 - val_f1: 0.0358\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5665 - accuracy: 0.2190 - f1: 0.0437 - val_loss: 2.6689 - val_accuracy: 0.1948 - val_f1: 0.0279\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5647 - accuracy: 0.2188 - f1: 0.0445 - val_loss: 2.6439 - val_accuracy: 0.1999 - val_f1: 0.0291\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5634 - accuracy: 0.2191 - f1: 0.0451 - val_loss: 2.6720 - val_accuracy: 0.1971 - val_f1: 0.0392\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5646 - accuracy: 0.2196 - f1: 0.0439 - val_loss: 2.6440 - val_accuracy: 0.1999 - val_f1: 0.0344\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5613 - accuracy: 0.2207 - f1: 0.0447 - val_loss: 2.6463 - val_accuracy: 0.2011 - val_f1: 0.0358\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5582 - accuracy: 0.2222 - f1: 0.0459 - val_loss: 2.6428 - val_accuracy: 0.2036 - val_f1: 0.0375\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5591 - accuracy: 0.2201 - f1: 0.0456 - val_loss: 2.6545 - val_accuracy: 0.1972 - val_f1: 0.0278\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5561 - accuracy: 0.2205 - f1: 0.0454 - val_loss: 2.6511 - val_accuracy: 0.2017 - val_f1: 0.0498\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5538 - accuracy: 0.2233 - f1: 0.0470 - val_loss: 2.6496 - val_accuracy: 0.2006 - val_f1: 0.0326\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5549 - accuracy: 0.2201 - f1: 0.0475 - val_loss: 2.6579 - val_accuracy: 0.1968 - val_f1: 0.0417\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5532 - accuracy: 0.2225 - f1: 0.0470 - val_loss: 2.6477 - val_accuracy: 0.2033 - val_f1: 0.0540\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5517 - accuracy: 0.2223 - f1: 0.0480 - val_loss: 2.6530 - val_accuracy: 0.1994 - val_f1: 0.0418\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5483 - accuracy: 0.2220 - f1: 0.0489 - val_loss: 2.6684 - val_accuracy: 0.1986 - val_f1: 0.0575\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5495 - accuracy: 0.2225 - f1: 0.0498 - val_loss: 2.6475 - val_accuracy: 0.2021 - val_f1: 0.0407\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5445 - accuracy: 0.2227 - f1: 0.0501 - val_loss: 2.6563 - val_accuracy: 0.2002 - val_f1: 0.0427\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5444 - accuracy: 0.2249 - f1: 0.0494 - val_loss: 2.6596 - val_accuracy: 0.1977 - val_f1: 0.0485\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5441 - accuracy: 0.2244 - f1: 0.0504 - val_loss: 2.6594 - val_accuracy: 0.2005 - val_f1: 0.0434\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5434 - accuracy: 0.2247 - f1: 0.0507 - val_loss: 2.6559 - val_accuracy: 0.1987 - val_f1: 0.0307\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5419 - accuracy: 0.2259 - f1: 0.0507 - val_loss: 2.6548 - val_accuracy: 0.2016 - val_f1: 0.0503\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5395 - accuracy: 0.2257 - f1: 0.0514 - val_loss: 2.6525 - val_accuracy: 0.2018 - val_f1: 0.0582\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5384 - accuracy: 0.2257 - f1: 0.0524 - val_loss: 2.6548 - val_accuracy: 0.1999 - val_f1: 0.0431\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5363 - accuracy: 0.2269 - f1: 0.0522 - val_loss: 2.6542 - val_accuracy: 0.1977 - val_f1: 0.0457\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5355 - accuracy: 0.2279 - f1: 0.0537 - val_loss: 2.6626 - val_accuracy: 0.1972 - val_f1: 0.0397\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5336 - accuracy: 0.2269 - f1: 0.0537 - val_loss: 2.6704 - val_accuracy: 0.1985 - val_f1: 0.0435\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5334 - accuracy: 0.2275 - f1: 0.0535 - val_loss: 2.6740 - val_accuracy: 0.1982 - val_f1: 0.0429\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5314 - accuracy: 0.2276 - f1: 0.0541 - val_loss: 2.6705 - val_accuracy: 0.1969 - val_f1: 0.0454\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5316 - accuracy: 0.2280 - f1: 0.0539 - val_loss: 2.6704 - val_accuracy: 0.1975 - val_f1: 0.0438\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5295 - accuracy: 0.2286 - f1: 0.0550 - val_loss: 2.6655 - val_accuracy: 0.1983 - val_f1: 0.0364\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5271 - accuracy: 0.2294 - f1: 0.0543 - val_loss: 2.6728 - val_accuracy: 0.1995 - val_f1: 0.0452\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5262 - accuracy: 0.2278 - f1: 0.0550 - val_loss: 2.6615 - val_accuracy: 0.2009 - val_f1: 0.0524\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5254 - accuracy: 0.2289 - f1: 0.0559 - val_loss: 2.6649 - val_accuracy: 0.1984 - val_f1: 0.0472\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5251 - accuracy: 0.2286 - f1: 0.0563 - val_loss: 2.6772 - val_accuracy: 0.1954 - val_f1: 0.0357\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5211 - accuracy: 0.2301 - f1: 0.0570 - val_loss: 2.6640 - val_accuracy: 0.1988 - val_f1: 0.0538\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5208 - accuracy: 0.2286 - f1: 0.0568 - val_loss: 2.6763 - val_accuracy: 0.1976 - val_f1: 0.0504\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5206 - accuracy: 0.2300 - f1: 0.0571 - val_loss: 2.6612 - val_accuracy: 0.2000 - val_f1: 0.0472\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5202 - accuracy: 0.2308 - f1: 0.0578 - val_loss: 2.6657 - val_accuracy: 0.1990 - val_f1: 0.0460\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5186 - accuracy: 0.2317 - f1: 0.0574 - val_loss: 2.6586 - val_accuracy: 0.2004 - val_f1: 0.0430\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.5179 - accuracy: 0.2309 - f1: 0.0580 - val_loss: 2.6825 - val_accuracy: 0.1937 - val_f1: 0.0418\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5162 - accuracy: 0.2311 - f1: 0.0591 - val_loss: 2.6802 - val_accuracy: 0.1976 - val_f1: 0.0598\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5149 - accuracy: 0.2308 - f1: 0.0585 - val_loss: 2.6709 - val_accuracy: 0.1988 - val_f1: 0.0462\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5141 - accuracy: 0.2310 - f1: 0.0594 - val_loss: 2.6779 - val_accuracy: 0.1989 - val_f1: 0.0436\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5113 - accuracy: 0.2331 - f1: 0.0597 - val_loss: 2.6725 - val_accuracy: 0.1975 - val_f1: 0.0392\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5129 - accuracy: 0.2320 - f1: 0.0593 - val_loss: 2.6645 - val_accuracy: 0.2006 - val_f1: 0.0470\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5102 - accuracy: 0.2338 - f1: 0.0604 - val_loss: 2.6814 - val_accuracy: 0.2004 - val_f1: 0.0434\n",
      "Epoch 91/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5111 - accuracy: 0.2337 - f1: 0.0593 - val_loss: 2.6707 - val_accuracy: 0.2016 - val_f1: 0.0503\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5083 - accuracy: 0.2331 - f1: 0.0614 - val_loss: 2.6745 - val_accuracy: 0.2005 - val_f1: 0.0481\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5072 - accuracy: 0.2327 - f1: 0.0612 - val_loss: 2.6723 - val_accuracy: 0.2003 - val_f1: 0.0478\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5073 - accuracy: 0.2336 - f1: 0.0613 - val_loss: 2.6781 - val_accuracy: 0.1997 - val_f1: 0.0550\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5050 - accuracy: 0.2345 - f1: 0.0622 - val_loss: 2.6793 - val_accuracy: 0.1972 - val_f1: 0.0506\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5054 - accuracy: 0.2347 - f1: 0.0612 - val_loss: 2.6837 - val_accuracy: 0.1973 - val_f1: 0.0471\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5041 - accuracy: 0.2352 - f1: 0.0627 - val_loss: 2.6798 - val_accuracy: 0.2007 - val_f1: 0.0510\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5032 - accuracy: 0.2345 - f1: 0.0631 - val_loss: 2.6685 - val_accuracy: 0.2020 - val_f1: 0.0456\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4996 - accuracy: 0.2362 - f1: 0.0622 - val_loss: 2.6840 - val_accuracy: 0.1991 - val_f1: 0.0532\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5012 - accuracy: 0.2349 - f1: 0.0631 - val_loss: 2.6790 - val_accuracy: 0.1997 - val_f1: 0.0484\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m1= CreateMultiPerceptron(4,100,100,0.0005,1,\"../music/music/tagged_feature_sets/msd-jmirmoments_dev/msd-jmirmoments_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 6s 48us/step - loss: 2.9956 - accuracy: 0.1199 - f1: 0.0271 - val_loss: 2.9161 - val_accuracy: 0.1382 - val_f1: 0.0362\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.8781 - accuracy: 0.1514 - f1: 0.0487 - val_loss: 2.8080 - val_accuracy: 0.1732 - val_f1: 0.0487\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.8193 - accuracy: 0.1654 - f1: 0.0532 - val_loss: 2.7789 - val_accuracy: 0.1757 - val_f1: 0.0481\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 4s 38us/step - loss: 2.7854 - accuracy: 0.1729 - f1: 0.0551 - val_loss: 2.8206 - val_accuracy: 0.1679 - val_f1: 0.0713\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 4s 37us/step - loss: 2.7712 - accuracy: 0.1755 - f1: 0.0563 - val_loss: 2.8200 - val_accuracy: 0.1676 - val_f1: 0.0584\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7563 - accuracy: 0.1786 - f1: 0.0583 - val_loss: 2.7505 - val_accuracy: 0.1836 - val_f1: 0.0410\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.7430 - accuracy: 0.1819 - f1: 0.0584 - val_loss: 2.7363 - val_accuracy: 0.1865 - val_f1: 0.0482\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.7350 - accuracy: 0.1833 - f1: 0.0600 - val_loss: 2.7541 - val_accuracy: 0.1828 - val_f1: 0.0549\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7297 - accuracy: 0.1856 - f1: 0.0615 - val_loss: 2.7480 - val_accuracy: 0.1807 - val_f1: 0.0469\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 4s 38us/step - loss: 2.7223 - accuracy: 0.1849 - f1: 0.0625 - val_loss: 2.7165 - val_accuracy: 0.1893 - val_f1: 0.0532\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 5s 41us/step - loss: 2.7147 - accuracy: 0.1890 - f1: 0.0623 - val_loss: 2.7166 - val_accuracy: 0.1894 - val_f1: 0.0516\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7075 - accuracy: 0.1901 - f1: 0.0636 - val_loss: 2.7750 - val_accuracy: 0.1735 - val_f1: 0.0423\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7050 - accuracy: 0.1897 - f1: 0.0650 - val_loss: 2.7054 - val_accuracy: 0.1920 - val_f1: 0.0437\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6945 - accuracy: 0.1930 - f1: 0.0661 - val_loss: 2.7014 - val_accuracy: 0.1926 - val_f1: 0.0716\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6856 - accuracy: 0.1952 - f1: 0.0670 - val_loss: 2.7000 - val_accuracy: 0.1927 - val_f1: 0.0688\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.6829 - accuracy: 0.1967 - f1: 0.0666 - val_loss: 2.8267 - val_accuracy: 0.1706 - val_f1: 0.0856\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6777 - accuracy: 0.1969 - f1: 0.0685 - val_loss: 2.7485 - val_accuracy: 0.1826 - val_f1: 0.0665\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.6696 - accuracy: 0.1992 - f1: 0.0694 - val_loss: 2.7126 - val_accuracy: 0.1936 - val_f1: 0.0580\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6669 - accuracy: 0.2011 - f1: 0.0689 - val_loss: 2.7492 - val_accuracy: 0.1844 - val_f1: 0.0701\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6612 - accuracy: 0.2001 - f1: 0.0701 - val_loss: 2.7067 - val_accuracy: 0.1913 - val_f1: 0.0647\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6577 - accuracy: 0.2016 - f1: 0.0707 - val_loss: 2.7394 - val_accuracy: 0.1878 - val_f1: 0.0721\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6560 - accuracy: 0.2026 - f1: 0.0705 - val_loss: 2.7155 - val_accuracy: 0.1943 - val_f1: 0.0680\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 5s 40us/step - loss: 2.6508 - accuracy: 0.2045 - f1: 0.0715 - val_loss: 2.7749 - val_accuracy: 0.1789 - val_f1: 0.0745\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6473 - accuracy: 0.2048 - f1: 0.0720 - val_loss: 2.6691 - val_accuracy: 0.1967 - val_f1: 0.0711\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6470 - accuracy: 0.2058 - f1: 0.0721 - val_loss: 2.6943 - val_accuracy: 0.1989 - val_f1: 0.0718\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6403 - accuracy: 0.2078 - f1: 0.0732 - val_loss: 2.6753 - val_accuracy: 0.1979 - val_f1: 0.0759\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6361 - accuracy: 0.2076 - f1: 0.0733 - val_loss: 2.6639 - val_accuracy: 0.2036 - val_f1: 0.0855\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.6316 - accuracy: 0.2088 - f1: 0.0741 - val_loss: 2.7006 - val_accuracy: 0.1929 - val_f1: 0.0681\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6326 - accuracy: 0.2099 - f1: 0.0744 - val_loss: 2.6913 - val_accuracy: 0.1960 - val_f1: 0.0714\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6276 - accuracy: 0.2101 - f1: 0.0762 - val_loss: 2.6919 - val_accuracy: 0.1975 - val_f1: 0.0750\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6290 - accuracy: 0.2102 - f1: 0.0757 - val_loss: 2.6462 - val_accuracy: 0.2069 - val_f1: 0.0645\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.6253 - accuracy: 0.2098 - f1: 0.0775 - val_loss: 2.8398 - val_accuracy: 0.1742 - val_f1: 0.0783\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6192 - accuracy: 0.2117 - f1: 0.0771 - val_loss: 2.6523 - val_accuracy: 0.2034 - val_f1: 0.0724\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6184 - accuracy: 0.2105 - f1: 0.0771 - val_loss: 2.7042 - val_accuracy: 0.1948 - val_f1: 0.0762\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6133 - accuracy: 0.2137 - f1: 0.0775 - val_loss: 2.6633 - val_accuracy: 0.2020 - val_f1: 0.0687\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6177 - accuracy: 0.2123 - f1: 0.0775 - val_loss: 2.7631 - val_accuracy: 0.1809 - val_f1: 0.0699\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6081 - accuracy: 0.2138 - f1: 0.0792 - val_loss: 2.6575 - val_accuracy: 0.2041 - val_f1: 0.0755\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6097 - accuracy: 0.2141 - f1: 0.0784 - val_loss: 2.6475 - val_accuracy: 0.2082 - val_f1: 0.0733\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6019 - accuracy: 0.2145 - f1: 0.0802 - val_loss: 2.6577 - val_accuracy: 0.2056 - val_f1: 0.0772\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.6076 - accuracy: 0.2145 - f1: 0.0792 - val_loss: 2.6373 - val_accuracy: 0.2112 - val_f1: 0.0867\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6001 - accuracy: 0.2162 - f1: 0.0799 - val_loss: 2.6418 - val_accuracy: 0.2079 - val_f1: 0.0830\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5999 - accuracy: 0.2144 - f1: 0.0817 - val_loss: 2.6402 - val_accuracy: 0.2091 - val_f1: 0.0675\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5979 - accuracy: 0.2161 - f1: 0.0805 - val_loss: 2.6461 - val_accuracy: 0.2079 - val_f1: 0.0759\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.5953 - accuracy: 0.2172 - f1: 0.0822 - val_loss: 2.6444 - val_accuracy: 0.2063 - val_f1: 0.0716\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5949 - accuracy: 0.2160 - f1: 0.0830 - val_loss: 2.6443 - val_accuracy: 0.2055 - val_f1: 0.0734\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5924 - accuracy: 0.2169 - f1: 0.0828 - val_loss: 2.6501 - val_accuracy: 0.2090 - val_f1: 0.0830\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5876 - accuracy: 0.2195 - f1: 0.0834 - val_loss: 2.6456 - val_accuracy: 0.2101 - val_f1: 0.0879\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.5900 - accuracy: 0.2182 - f1: 0.0836 - val_loss: 2.7207 - val_accuracy: 0.1919 - val_f1: 0.0683\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5879 - accuracy: 0.2198 - f1: 0.0848 - val_loss: 2.6617 - val_accuracy: 0.2063 - val_f1: 0.0877\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5846 - accuracy: 0.2192 - f1: 0.0842 - val_loss: 2.6626 - val_accuracy: 0.2044 - val_f1: 0.0777\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5831 - accuracy: 0.2193 - f1: 0.0853 - val_loss: 2.6558 - val_accuracy: 0.2039 - val_f1: 0.0799\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.5807 - accuracy: 0.2208 - f1: 0.0857 - val_loss: 2.6365 - val_accuracy: 0.2137 - val_f1: 0.0880\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5753 - accuracy: 0.2208 - f1: 0.0864 - val_loss: 2.6994 - val_accuracy: 0.1943 - val_f1: 0.0685\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5772 - accuracy: 0.2228 - f1: 0.0875 - val_loss: 2.6851 - val_accuracy: 0.1999 - val_f1: 0.0616\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.5739 - accuracy: 0.2211 - f1: 0.0878 - val_loss: 2.6381 - val_accuracy: 0.2118 - val_f1: 0.0813\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5726 - accuracy: 0.2219 - f1: 0.0876 - val_loss: 2.6928 - val_accuracy: 0.1957 - val_f1: 0.0755\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5673 - accuracy: 0.2245 - f1: 0.0890 - val_loss: 2.6612 - val_accuracy: 0.2042 - val_f1: 0.0781\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5682 - accuracy: 0.2233 - f1: 0.0901 - val_loss: 2.6633 - val_accuracy: 0.2040 - val_f1: 0.0792\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.5659 - accuracy: 0.2238 - f1: 0.0889 - val_loss: 2.6629 - val_accuracy: 0.2062 - val_f1: 0.0880\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5656 - accuracy: 0.2234 - f1: 0.0892 - val_loss: 2.6765 - val_accuracy: 0.2003 - val_f1: 0.0745\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5646 - accuracy: 0.2246 - f1: 0.0897 - val_loss: 2.6621 - val_accuracy: 0.2063 - val_f1: 0.0798\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5644 - accuracy: 0.2237 - f1: 0.0902 - val_loss: 2.6762 - val_accuracy: 0.2011 - val_f1: 0.0738\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5614 - accuracy: 0.2262 - f1: 0.0901 - val_loss: 2.6725 - val_accuracy: 0.1980 - val_f1: 0.0767\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5623 - accuracy: 0.2262 - f1: 0.0895 - val_loss: 2.7030 - val_accuracy: 0.1963 - val_f1: 0.0837\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.5566 - accuracy: 0.2268 - f1: 0.0921 - val_loss: 2.7319 - val_accuracy: 0.1934 - val_f1: 0.0806\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5573 - accuracy: 0.2259 - f1: 0.0911 - val_loss: 2.6531 - val_accuracy: 0.2093 - val_f1: 0.0925\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5553 - accuracy: 0.2279 - f1: 0.0917 - val_loss: 2.7075 - val_accuracy: 0.1979 - val_f1: 0.0857\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5550 - accuracy: 0.2278 - f1: 0.0919 - val_loss: 2.6557 - val_accuracy: 0.2047 - val_f1: 0.0705\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.5519 - accuracy: 0.2283 - f1: 0.0928 - val_loss: 2.6719 - val_accuracy: 0.2027 - val_f1: 0.0850\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5522 - accuracy: 0.2268 - f1: 0.0920 - val_loss: 2.6594 - val_accuracy: 0.2079 - val_f1: 0.0750\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5513 - accuracy: 0.2271 - f1: 0.0925 - val_loss: 2.6734 - val_accuracy: 0.2064 - val_f1: 0.0874\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5479 - accuracy: 0.2288 - f1: 0.0935 - val_loss: 2.6981 - val_accuracy: 0.2005 - val_f1: 0.0865\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 5s 40us/step - loss: 2.5486 - accuracy: 0.2278 - f1: 0.0934 - val_loss: 2.7242 - val_accuracy: 0.1953 - val_f1: 0.0816\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5470 - accuracy: 0.2282 - f1: 0.0950 - val_loss: 2.6822 - val_accuracy: 0.2019 - val_f1: 0.0819\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5453 - accuracy: 0.2289 - f1: 0.0938 - val_loss: 2.6537 - val_accuracy: 0.2087 - val_f1: 0.0849\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5426 - accuracy: 0.2303 - f1: 0.0950 - val_loss: 2.6519 - val_accuracy: 0.2096 - val_f1: 0.0782\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5421 - accuracy: 0.2292 - f1: 0.0951 - val_loss: 2.6708 - val_accuracy: 0.2038 - val_f1: 0.0886\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.5431 - accuracy: 0.2295 - f1: 0.0964 - val_loss: 2.6868 - val_accuracy: 0.2027 - val_f1: 0.0831\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5424 - accuracy: 0.2301 - f1: 0.0961 - val_loss: 2.6617 - val_accuracy: 0.2086 - val_f1: 0.0785\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5388 - accuracy: 0.2307 - f1: 0.0962 - val_loss: 2.6643 - val_accuracy: 0.2069 - val_f1: 0.0845\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5354 - accuracy: 0.2308 - f1: 0.0968 - val_loss: 2.6457 - val_accuracy: 0.2109 - val_f1: 0.0879\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.5357 - accuracy: 0.2313 - f1: 0.0972 - val_loss: 2.6648 - val_accuracy: 0.2052 - val_f1: 0.0833\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5390 - accuracy: 0.2325 - f1: 0.0966 - val_loss: 2.6853 - val_accuracy: 0.2016 - val_f1: 0.0854\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5333 - accuracy: 0.2334 - f1: 0.0976 - val_loss: 2.6605 - val_accuracy: 0.2072 - val_f1: 0.0813\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5306 - accuracy: 0.2326 - f1: 0.0977 - val_loss: 2.7258 - val_accuracy: 0.1892 - val_f1: 0.0820\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5351 - accuracy: 0.2329 - f1: 0.0983 - val_loss: 2.6828 - val_accuracy: 0.2045 - val_f1: 0.0907\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.5329 - accuracy: 0.2321 - f1: 0.0985 - val_loss: 2.6682 - val_accuracy: 0.2043 - val_f1: 0.0814\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5321 - accuracy: 0.2329 - f1: 0.0994 - val_loss: 2.7215 - val_accuracy: 0.1958 - val_f1: 0.0837\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5293 - accuracy: 0.2333 - f1: 0.0993 - val_loss: 2.6617 - val_accuracy: 0.2073 - val_f1: 0.0785\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5250 - accuracy: 0.2338 - f1: 0.1006 - val_loss: 2.6762 - val_accuracy: 0.2039 - val_f1: 0.0875\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5278 - accuracy: 0.2341 - f1: 0.1002 - val_loss: 2.6698 - val_accuracy: 0.2047 - val_f1: 0.0838\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5285 - accuracy: 0.2327 - f1: 0.0989 - val_loss: 2.7428 - val_accuracy: 0.1946 - val_f1: 0.0882\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5288 - accuracy: 0.2331 - f1: 0.0996 - val_loss: 2.6568 - val_accuracy: 0.2065 - val_f1: 0.0820\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.5213 - accuracy: 0.2347 - f1: 0.1020 - val_loss: 2.6634 - val_accuracy: 0.2072 - val_f1: 0.0868\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5238 - accuracy: 0.2345 - f1: 0.1001 - val_loss: 2.6660 - val_accuracy: 0.2071 - val_f1: 0.0790\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5197 - accuracy: 0.2350 - f1: 0.1026 - val_loss: 2.7027 - val_accuracy: 0.2009 - val_f1: 0.0834\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5203 - accuracy: 0.2346 - f1: 0.1018 - val_loss: 2.6859 - val_accuracy: 0.2041 - val_f1: 0.0886\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5202 - accuracy: 0.2340 - f1: 0.1016 - val_loss: 2.6735 - val_accuracy: 0.2076 - val_f1: 0.0925\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5185 - accuracy: 0.2358 - f1: 0.1029 - val_loss: 2.6700 - val_accuracy: 0.2052 - val_f1: 0.0778\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5184 - accuracy: 0.2359 - f1: 0.1038 - val_loss: 2.6829 - val_accuracy: 0.2048 - val_f1: 0.0825\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m2= CreateMultiPerceptron(4,100,100,0.0005,2,\"../music/music/tagged_feature_sets/msd-mvd_dev/msd-mvd_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6960 - accuracy: 0.1823 - f1: 0.0275 - val_loss: 2.6111 - val_accuracy: 0.2040 - val_f1: 0.0358\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5620 - accuracy: 0.2172 - f1: 0.0511 - val_loss: 2.5756 - val_accuracy: 0.2204 - val_f1: 0.0535\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5156 - accuracy: 0.2305 - f1: 0.0608 - val_loss: 2.4994 - val_accuracy: 0.2328 - val_f1: 0.0605\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4887 - accuracy: 0.2382 - f1: 0.0693 - val_loss: 2.4657 - val_accuracy: 0.2432 - val_f1: 0.0843\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4661 - accuracy: 0.2449 - f1: 0.0745 - val_loss: 2.4371 - val_accuracy: 0.2528 - val_f1: 0.0873\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4510 - accuracy: 0.2486 - f1: 0.0809 - val_loss: 2.4452 - val_accuracy: 0.2521 - val_f1: 0.0815\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4389 - accuracy: 0.2525 - f1: 0.0873 - val_loss: 2.4886 - val_accuracy: 0.2358 - val_f1: 0.0916\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4248 - accuracy: 0.2568 - f1: 0.0922 - val_loss: 2.4706 - val_accuracy: 0.2433 - val_f1: 0.0563\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4159 - accuracy: 0.2601 - f1: 0.0942 - val_loss: 2.4404 - val_accuracy: 0.2512 - val_f1: 0.1072\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4066 - accuracy: 0.2611 - f1: 0.0991 - val_loss: 2.4435 - val_accuracy: 0.2492 - val_f1: 0.0766\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3969 - accuracy: 0.2637 - f1: 0.1015 - val_loss: 2.4311 - val_accuracy: 0.2571 - val_f1: 0.1079\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3907 - accuracy: 0.2645 - f1: 0.1041 - val_loss: 2.4031 - val_accuracy: 0.2635 - val_f1: 0.0988\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.3826 - accuracy: 0.2669 - f1: 0.1058 - val_loss: 2.4072 - val_accuracy: 0.2576 - val_f1: 0.0935\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.3796 - accuracy: 0.2669 - f1: 0.1080 - val_loss: 2.4289 - val_accuracy: 0.2558 - val_f1: 0.0824\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3762 - accuracy: 0.2695 - f1: 0.1081 - val_loss: 2.4820 - val_accuracy: 0.2391 - val_f1: 0.0876\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3669 - accuracy: 0.2707 - f1: 0.1125 - val_loss: 2.4065 - val_accuracy: 0.2600 - val_f1: 0.1152\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3641 - accuracy: 0.2717 - f1: 0.1132 - val_loss: 2.4033 - val_accuracy: 0.2616 - val_f1: 0.1118\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3552 - accuracy: 0.2745 - f1: 0.1158 - val_loss: 2.4310 - val_accuracy: 0.2521 - val_f1: 0.0833\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3493 - accuracy: 0.2759 - f1: 0.1179 - val_loss: 2.3830 - val_accuracy: 0.2690 - val_f1: 0.1322\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3462 - accuracy: 0.2763 - f1: 0.1184 - val_loss: 2.3685 - val_accuracy: 0.2711 - val_f1: 0.1112\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3398 - accuracy: 0.2790 - f1: 0.1203 - val_loss: 2.3896 - val_accuracy: 0.2652 - val_f1: 0.1150\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3376 - accuracy: 0.2793 - f1: 0.1217 - val_loss: 2.4123 - val_accuracy: 0.2602 - val_f1: 0.1115\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3310 - accuracy: 0.2813 - f1: 0.1241 - val_loss: 2.3744 - val_accuracy: 0.2713 - val_f1: 0.1275\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3257 - accuracy: 0.2836 - f1: 0.1243 - val_loss: 2.3677 - val_accuracy: 0.2725 - val_f1: 0.1254\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3264 - accuracy: 0.2816 - f1: 0.1248 - val_loss: 2.3870 - val_accuracy: 0.2680 - val_f1: 0.1124\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.3190 - accuracy: 0.2838 - f1: 0.1277 - val_loss: 2.3698 - val_accuracy: 0.2719 - val_f1: 0.1204\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3144 - accuracy: 0.2858 - f1: 0.1286 - val_loss: 2.3778 - val_accuracy: 0.2673 - val_f1: 0.1262\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3122 - accuracy: 0.2859 - f1: 0.1304 - val_loss: 2.3648 - val_accuracy: 0.2714 - val_f1: 0.1372\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3082 - accuracy: 0.2868 - f1: 0.1326 - val_loss: 2.3624 - val_accuracy: 0.2732 - val_f1: 0.1175\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3013 - accuracy: 0.2872 - f1: 0.1318 - val_loss: 2.3668 - val_accuracy: 0.2724 - val_f1: 0.1257\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2979 - accuracy: 0.2899 - f1: 0.1339 - val_loss: 2.3583 - val_accuracy: 0.2763 - val_f1: 0.1276\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.2974 - accuracy: 0.2892 - f1: 0.1350 - val_loss: 2.3641 - val_accuracy: 0.2717 - val_f1: 0.1191\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2912 - accuracy: 0.2903 - f1: 0.1386 - val_loss: 2.3756 - val_accuracy: 0.2704 - val_f1: 0.1342\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2874 - accuracy: 0.2939 - f1: 0.1390 - val_loss: 2.3596 - val_accuracy: 0.2745 - val_f1: 0.1229\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2847 - accuracy: 0.2941 - f1: 0.1402 - val_loss: 2.3734 - val_accuracy: 0.2684 - val_f1: 0.1193\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.2844 - accuracy: 0.2927 - f1: 0.1408 - val_loss: 2.3826 - val_accuracy: 0.2678 - val_f1: 0.1380\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2805 - accuracy: 0.2935 - f1: 0.1418 - val_loss: 2.3856 - val_accuracy: 0.2675 - val_f1: 0.1298\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2746 - accuracy: 0.2950 - f1: 0.1437 - val_loss: 2.3783 - val_accuracy: 0.2673 - val_f1: 0.1150\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2744 - accuracy: 0.2968 - f1: 0.1448 - val_loss: 2.3714 - val_accuracy: 0.2715 - val_f1: 0.1350\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2730 - accuracy: 0.2973 - f1: 0.1445 - val_loss: 2.3706 - val_accuracy: 0.2750 - val_f1: 0.1400\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.2718 - accuracy: 0.2972 - f1: 0.1467 - val_loss: 2.4226 - val_accuracy: 0.2588 - val_f1: 0.1280\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.2661 - accuracy: 0.2983 - f1: 0.1485 - val_loss: 2.3660 - val_accuracy: 0.2734 - val_f1: 0.1255\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2618 - accuracy: 0.2992 - f1: 0.1498 - val_loss: 2.3508 - val_accuracy: 0.2780 - val_f1: 0.1400\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2605 - accuracy: 0.3001 - f1: 0.1501 - val_loss: 2.3746 - val_accuracy: 0.2730 - val_f1: 0.1500\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2595 - accuracy: 0.2988 - f1: 0.1487 - val_loss: 2.3661 - val_accuracy: 0.2745 - val_f1: 0.1470\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.2542 - accuracy: 0.3014 - f1: 0.1534 - val_loss: 2.3755 - val_accuracy: 0.2728 - val_f1: 0.1404\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2526 - accuracy: 0.3011 - f1: 0.1519 - val_loss: 2.3702 - val_accuracy: 0.2735 - val_f1: 0.1276\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.2475 - accuracy: 0.3023 - f1: 0.1537 - val_loss: 2.3582 - val_accuracy: 0.2771 - val_f1: 0.1327\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.2464 - accuracy: 0.3042 - f1: 0.1552 - val_loss: 2.3635 - val_accuracy: 0.2760 - val_f1: 0.1350\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.2452 - accuracy: 0.3043 - f1: 0.1571 - val_loss: 2.3661 - val_accuracy: 0.2746 - val_f1: 0.1448\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2437 - accuracy: 0.3038 - f1: 0.1545 - val_loss: 2.3749 - val_accuracy: 0.2751 - val_f1: 0.1589\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2385 - accuracy: 0.3055 - f1: 0.1589 - val_loss: 2.3635 - val_accuracy: 0.2755 - val_f1: 0.1479\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2364 - accuracy: 0.3071 - f1: 0.1601 - val_loss: 2.3702 - val_accuracy: 0.2746 - val_f1: 0.1476\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.2349 - accuracy: 0.3073 - f1: 0.1596 - val_loss: 2.3643 - val_accuracy: 0.2793 - val_f1: 0.1603\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2334 - accuracy: 0.3073 - f1: 0.1600 - val_loss: 2.3854 - val_accuracy: 0.2729 - val_f1: 0.1540\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2286 - accuracy: 0.3095 - f1: 0.1631 - val_loss: 2.3925 - val_accuracy: 0.2755 - val_f1: 0.1651\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2295 - accuracy: 0.3065 - f1: 0.1616 - val_loss: 2.3703 - val_accuracy: 0.2763 - val_f1: 0.1602\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2259 - accuracy: 0.3092 - f1: 0.1634 - val_loss: 2.3698 - val_accuracy: 0.2770 - val_f1: 0.1505\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2241 - accuracy: 0.3100 - f1: 0.1634 - val_loss: 2.3819 - val_accuracy: 0.2723 - val_f1: 0.1497\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2205 - accuracy: 0.3096 - f1: 0.1660 - val_loss: 2.3635 - val_accuracy: 0.2767 - val_f1: 0.1381\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2167 - accuracy: 0.3097 - f1: 0.1680 - val_loss: 2.3940 - val_accuracy: 0.2720 - val_f1: 0.1561\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.2153 - accuracy: 0.3139 - f1: 0.1674 - val_loss: 2.3801 - val_accuracy: 0.2737 - val_f1: 0.1396\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2137 - accuracy: 0.3120 - f1: 0.1688 - val_loss: 2.3681 - val_accuracy: 0.2781 - val_f1: 0.1525\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2136 - accuracy: 0.3137 - f1: 0.1708 - val_loss: 2.4129 - val_accuracy: 0.2685 - val_f1: 0.1526\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2096 - accuracy: 0.3135 - f1: 0.1704 - val_loss: 2.3869 - val_accuracy: 0.2707 - val_f1: 0.1405\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2057 - accuracy: 0.3159 - f1: 0.1720 - val_loss: 2.3870 - val_accuracy: 0.2731 - val_f1: 0.1497\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2102 - accuracy: 0.3152 - f1: 0.1701 - val_loss: 2.3867 - val_accuracy: 0.2727 - val_f1: 0.1409\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2059 - accuracy: 0.3148 - f1: 0.1717 - val_loss: 2.3911 - val_accuracy: 0.2765 - val_f1: 0.1604\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2029 - accuracy: 0.3159 - f1: 0.1737 - val_loss: 2.3688 - val_accuracy: 0.2765 - val_f1: 0.1514\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.2054 - accuracy: 0.3159 - f1: 0.1726 - val_loss: 2.3860 - val_accuracy: 0.2740 - val_f1: 0.1391\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1980 - accuracy: 0.3177 - f1: 0.1754 - val_loss: 2.3826 - val_accuracy: 0.2750 - val_f1: 0.1480\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1980 - accuracy: 0.3190 - f1: 0.1763 - val_loss: 2.3784 - val_accuracy: 0.2750 - val_f1: 0.1602\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1946 - accuracy: 0.3171 - f1: 0.1754 - val_loss: 2.4228 - val_accuracy: 0.2649 - val_f1: 0.1383\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1937 - accuracy: 0.3193 - f1: 0.1766 - val_loss: 2.3955 - val_accuracy: 0.2701 - val_f1: 0.1551\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.1892 - accuracy: 0.3202 - f1: 0.1783 - val_loss: 2.4095 - val_accuracy: 0.2705 - val_f1: 0.1655\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.1908 - accuracy: 0.3203 - f1: 0.1776 - val_loss: 2.3725 - val_accuracy: 0.2775 - val_f1: 0.1420\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.1880 - accuracy: 0.3204 - f1: 0.1787 - val_loss: 2.4244 - val_accuracy: 0.2654 - val_f1: 0.1390\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1886 - accuracy: 0.3205 - f1: 0.1802 - val_loss: 2.3851 - val_accuracy: 0.2737 - val_f1: 0.1617\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.1861 - accuracy: 0.3215 - f1: 0.1784 - val_loss: 2.3933 - val_accuracy: 0.2786 - val_f1: 0.1629\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.1859 - accuracy: 0.3222 - f1: 0.1795 - val_loss: 2.4033 - val_accuracy: 0.2690 - val_f1: 0.1562\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1854 - accuracy: 0.3221 - f1: 0.1809 - val_loss: 2.3888 - val_accuracy: 0.2743 - val_f1: 0.1451\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1831 - accuracy: 0.3211 - f1: 0.1810 - val_loss: 2.3934 - val_accuracy: 0.2763 - val_f1: 0.1541\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1799 - accuracy: 0.3230 - f1: 0.1827 - val_loss: 2.4093 - val_accuracy: 0.2722 - val_f1: 0.1584\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1796 - accuracy: 0.3228 - f1: 0.1828 - val_loss: 2.4370 - val_accuracy: 0.2653 - val_f1: 0.1418\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.1807 - accuracy: 0.3220 - f1: 0.1834 - val_loss: 2.3900 - val_accuracy: 0.2753 - val_f1: 0.1419\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.1742 - accuracy: 0.3251 - f1: 0.1851 - val_loss: 2.4131 - val_accuracy: 0.2727 - val_f1: 0.1509\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1754 - accuracy: 0.3230 - f1: 0.1869 - val_loss: 2.3991 - val_accuracy: 0.2736 - val_f1: 0.1519\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1710 - accuracy: 0.3251 - f1: 0.1873 - val_loss: 2.3976 - val_accuracy: 0.2728 - val_f1: 0.1454\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.1720 - accuracy: 0.3251 - f1: 0.1873 - val_loss: 2.4117 - val_accuracy: 0.2755 - val_f1: 0.1534\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.1710 - accuracy: 0.3264 - f1: 0.1864 - val_loss: 2.4138 - val_accuracy: 0.2715 - val_f1: 0.1436\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1703 - accuracy: 0.3239 - f1: 0.1879 - val_loss: 2.4038 - val_accuracy: 0.2709 - val_f1: 0.1625\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1658 - accuracy: 0.3262 - f1: 0.1901 - val_loss: 2.4039 - val_accuracy: 0.2728 - val_f1: 0.1484\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1659 - accuracy: 0.3256 - f1: 0.1885 - val_loss: 2.4229 - val_accuracy: 0.2684 - val_f1: 0.1454\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.1641 - accuracy: 0.3265 - f1: 0.1900 - val_loss: 2.3932 - val_accuracy: 0.2772 - val_f1: 0.1494\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1636 - accuracy: 0.3284 - f1: 0.1894 - val_loss: 2.4630 - val_accuracy: 0.2618 - val_f1: 0.1589\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1659 - accuracy: 0.3262 - f1: 0.1886 - val_loss: 2.4152 - val_accuracy: 0.2710 - val_f1: 0.1463\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1602 - accuracy: 0.3283 - f1: 0.1932 - val_loss: 2.4091 - val_accuracy: 0.2726 - val_f1: 0.1542\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1595 - accuracy: 0.3278 - f1: 0.1927 - val_loss: 2.4106 - val_accuracy: 0.2708 - val_f1: 0.1561\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1601 - accuracy: 0.3276 - f1: 0.1923 - val_loss: 2.4044 - val_accuracy: 0.2720 - val_f1: 0.1601\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1564 - accuracy: 0.3282 - f1: 0.1930 - val_loss: 2.4018 - val_accuracy: 0.2719 - val_f1: 0.1486\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m3= CreateMultiPerceptron(4,100,100,0.0005,3,\"../music/music/tagged_feature_sets/msd-ssd_dev/msd-ssd_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.8284 - accuracy: 0.1448 - f1: 0.0054 - val_loss: 2.7384 - val_accuracy: 0.1658 - val_f1: 0.0027\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7126 - accuracy: 0.1736 - f1: 0.0127 - val_loss: 2.7090 - val_accuracy: 0.1767 - val_f1: 0.0306\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6711 - accuracy: 0.1867 - f1: 0.0183 - val_loss: 2.6603 - val_accuracy: 0.1869 - val_f1: 0.0415\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6513 - accuracy: 0.1890 - f1: 0.0221 - val_loss: 2.6287 - val_accuracy: 0.1919 - val_f1: 0.0304\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6345 - accuracy: 0.1947 - f1: 0.0254 - val_loss: 2.6132 - val_accuracy: 0.2027 - val_f1: 0.0345\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6236 - accuracy: 0.1978 - f1: 0.0272 - val_loss: 2.6398 - val_accuracy: 0.1942 - val_f1: 0.0205\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6152 - accuracy: 0.1995 - f1: 0.0299 - val_loss: 2.6308 - val_accuracy: 0.2007 - val_f1: 0.0228\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6086 - accuracy: 0.2017 - f1: 0.0313 - val_loss: 2.6009 - val_accuracy: 0.2027 - val_f1: 0.0548\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6007 - accuracy: 0.2044 - f1: 0.0335 - val_loss: 2.6032 - val_accuracy: 0.2061 - val_f1: 0.0300\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5955 - accuracy: 0.2045 - f1: 0.0342 - val_loss: 2.5969 - val_accuracy: 0.2039 - val_f1: 0.0382\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5884 - accuracy: 0.2083 - f1: 0.0370 - val_loss: 2.5835 - val_accuracy: 0.2091 - val_f1: 0.0348\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5850 - accuracy: 0.2082 - f1: 0.0382 - val_loss: 2.5749 - val_accuracy: 0.2090 - val_f1: 0.0486\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5784 - accuracy: 0.2113 - f1: 0.0396 - val_loss: 2.6357 - val_accuracy: 0.1988 - val_f1: 0.0459\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5737 - accuracy: 0.2127 - f1: 0.0414 - val_loss: 2.5662 - val_accuracy: 0.2137 - val_f1: 0.0398\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5688 - accuracy: 0.2142 - f1: 0.0419 - val_loss: 2.5753 - val_accuracy: 0.2142 - val_f1: 0.0430\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5669 - accuracy: 0.2132 - f1: 0.0436 - val_loss: 2.5622 - val_accuracy: 0.2165 - val_f1: 0.0642\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5600 - accuracy: 0.2159 - f1: 0.0461 - val_loss: 2.5711 - val_accuracy: 0.2135 - val_f1: 0.0412\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5544 - accuracy: 0.2190 - f1: 0.0465 - val_loss: 2.5595 - val_accuracy: 0.2188 - val_f1: 0.0505\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5514 - accuracy: 0.2185 - f1: 0.0479 - val_loss: 2.5708 - val_accuracy: 0.2149 - val_f1: 0.0461\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5494 - accuracy: 0.2184 - f1: 0.0488 - val_loss: 2.5532 - val_accuracy: 0.2171 - val_f1: 0.0425\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5450 - accuracy: 0.2215 - f1: 0.0494 - val_loss: 2.5576 - val_accuracy: 0.2156 - val_f1: 0.0310\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5401 - accuracy: 0.2223 - f1: 0.0503 - val_loss: 2.5531 - val_accuracy: 0.2195 - val_f1: 0.0599\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5382 - accuracy: 0.2232 - f1: 0.0518 - val_loss: 2.5502 - val_accuracy: 0.2230 - val_f1: 0.0454\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5337 - accuracy: 0.2230 - f1: 0.0527 - val_loss: 2.5519 - val_accuracy: 0.2192 - val_f1: 0.0592\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5308 - accuracy: 0.2246 - f1: 0.0534 - val_loss: 2.5485 - val_accuracy: 0.2212 - val_f1: 0.0526\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5278 - accuracy: 0.2263 - f1: 0.0538 - val_loss: 2.5403 - val_accuracy: 0.2228 - val_f1: 0.0666\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5254 - accuracy: 0.2257 - f1: 0.0555 - val_loss: 2.5731 - val_accuracy: 0.2124 - val_f1: 0.0642\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5226 - accuracy: 0.2268 - f1: 0.0563 - val_loss: 2.5457 - val_accuracy: 0.2210 - val_f1: 0.0548\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5209 - accuracy: 0.2276 - f1: 0.0556 - val_loss: 2.5335 - val_accuracy: 0.2258 - val_f1: 0.0593\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5177 - accuracy: 0.2291 - f1: 0.0580 - val_loss: 2.5506 - val_accuracy: 0.2213 - val_f1: 0.0701\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5149 - accuracy: 0.2292 - f1: 0.0582 - val_loss: 2.5512 - val_accuracy: 0.2212 - val_f1: 0.0631\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5100 - accuracy: 0.2302 - f1: 0.0593 - val_loss: 2.5627 - val_accuracy: 0.2191 - val_f1: 0.0439\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5104 - accuracy: 0.2316 - f1: 0.0597 - val_loss: 2.5522 - val_accuracy: 0.2220 - val_f1: 0.0740\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5058 - accuracy: 0.2297 - f1: 0.0603 - val_loss: 2.5346 - val_accuracy: 0.2265 - val_f1: 0.0507\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5058 - accuracy: 0.2317 - f1: 0.0599 - val_loss: 2.5664 - val_accuracy: 0.2167 - val_f1: 0.0493\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5044 - accuracy: 0.2321 - f1: 0.0618 - val_loss: 2.5597 - val_accuracy: 0.2205 - val_f1: 0.0595\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5008 - accuracy: 0.2328 - f1: 0.0632 - val_loss: 2.5465 - val_accuracy: 0.2225 - val_f1: 0.0587\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4957 - accuracy: 0.2342 - f1: 0.0640 - val_loss: 2.5487 - val_accuracy: 0.2203 - val_f1: 0.0628\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4971 - accuracy: 0.2348 - f1: 0.0628 - val_loss: 2.5464 - val_accuracy: 0.2262 - val_f1: 0.0611\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4921 - accuracy: 0.2357 - f1: 0.0658 - val_loss: 2.5396 - val_accuracy: 0.2264 - val_f1: 0.0661\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4906 - accuracy: 0.2359 - f1: 0.0651 - val_loss: 2.5525 - val_accuracy: 0.2238 - val_f1: 0.0632\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4883 - accuracy: 0.2367 - f1: 0.0662 - val_loss: 2.5563 - val_accuracy: 0.2241 - val_f1: 0.0574\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4876 - accuracy: 0.2363 - f1: 0.0663 - val_loss: 2.5493 - val_accuracy: 0.2261 - val_f1: 0.0679\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4843 - accuracy: 0.2383 - f1: 0.0682 - val_loss: 2.5498 - val_accuracy: 0.2239 - val_f1: 0.0621\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4831 - accuracy: 0.2381 - f1: 0.0682 - val_loss: 2.5565 - val_accuracy: 0.2221 - val_f1: 0.0574\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4800 - accuracy: 0.2395 - f1: 0.0696 - val_loss: 2.5509 - val_accuracy: 0.2220 - val_f1: 0.0431\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4768 - accuracy: 0.2382 - f1: 0.0691 - val_loss: 2.5639 - val_accuracy: 0.2195 - val_f1: 0.0679\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4762 - accuracy: 0.2399 - f1: 0.0704 - val_loss: 2.5524 - val_accuracy: 0.2224 - val_f1: 0.0558\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4746 - accuracy: 0.2395 - f1: 0.0698 - val_loss: 2.5538 - val_accuracy: 0.2220 - val_f1: 0.0667\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4724 - accuracy: 0.2400 - f1: 0.0723 - val_loss: 2.5600 - val_accuracy: 0.2206 - val_f1: 0.0586\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4708 - accuracy: 0.2405 - f1: 0.0709 - val_loss: 2.5387 - val_accuracy: 0.2269 - val_f1: 0.0655\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4674 - accuracy: 0.2418 - f1: 0.0718 - val_loss: 2.5397 - val_accuracy: 0.2268 - val_f1: 0.0778\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4655 - accuracy: 0.2432 - f1: 0.0732 - val_loss: 2.5447 - val_accuracy: 0.2266 - val_f1: 0.0707\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4668 - accuracy: 0.2434 - f1: 0.0729 - val_loss: 2.5565 - val_accuracy: 0.2207 - val_f1: 0.0610\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4639 - accuracy: 0.2429 - f1: 0.0740 - val_loss: 2.5462 - val_accuracy: 0.2260 - val_f1: 0.0686\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4607 - accuracy: 0.2439 - f1: 0.0755 - val_loss: 2.5400 - val_accuracy: 0.2264 - val_f1: 0.0679\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4616 - accuracy: 0.2431 - f1: 0.0755 - val_loss: 2.5282 - val_accuracy: 0.2281 - val_f1: 0.0798\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4576 - accuracy: 0.2442 - f1: 0.0752 - val_loss: 2.5406 - val_accuracy: 0.2264 - val_f1: 0.0734\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4568 - accuracy: 0.2449 - f1: 0.0762 - val_loss: 2.5371 - val_accuracy: 0.2269 - val_f1: 0.0593\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4548 - accuracy: 0.2458 - f1: 0.0767 - val_loss: 2.5574 - val_accuracy: 0.2244 - val_f1: 0.0757\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4517 - accuracy: 0.2468 - f1: 0.0777 - val_loss: 2.5649 - val_accuracy: 0.2176 - val_f1: 0.0616\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4510 - accuracy: 0.2459 - f1: 0.0781 - val_loss: 2.5419 - val_accuracy: 0.2266 - val_f1: 0.0674\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4491 - accuracy: 0.2474 - f1: 0.0778 - val_loss: 2.5562 - val_accuracy: 0.2252 - val_f1: 0.0804\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4514 - accuracy: 0.2471 - f1: 0.0790 - val_loss: 2.5489 - val_accuracy: 0.2259 - val_f1: 0.0673\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4471 - accuracy: 0.2470 - f1: 0.0798 - val_loss: 2.5641 - val_accuracy: 0.2214 - val_f1: 0.0757\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4447 - accuracy: 0.2472 - f1: 0.0802 - val_loss: 2.5745 - val_accuracy: 0.2237 - val_f1: 0.0756\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4454 - accuracy: 0.2477 - f1: 0.0798 - val_loss: 2.5441 - val_accuracy: 0.2265 - val_f1: 0.0776\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4433 - accuracy: 0.2492 - f1: 0.0823 - val_loss: 2.5427 - val_accuracy: 0.2255 - val_f1: 0.0634\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4413 - accuracy: 0.2499 - f1: 0.0817 - val_loss: 2.5601 - val_accuracy: 0.2206 - val_f1: 0.0712\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4415 - accuracy: 0.2509 - f1: 0.0816 - val_loss: 2.5511 - val_accuracy: 0.2253 - val_f1: 0.0703\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4389 - accuracy: 0.2493 - f1: 0.0829 - val_loss: 2.5505 - val_accuracy: 0.2257 - val_f1: 0.0854\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4374 - accuracy: 0.2503 - f1: 0.0835 - val_loss: 2.5640 - val_accuracy: 0.2221 - val_f1: 0.0738\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4362 - accuracy: 0.2508 - f1: 0.0844 - val_loss: 2.5516 - val_accuracy: 0.2268 - val_f1: 0.0772\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4367 - accuracy: 0.2513 - f1: 0.0839 - val_loss: 2.5435 - val_accuracy: 0.2282 - val_f1: 0.0761\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4345 - accuracy: 0.2515 - f1: 0.0841 - val_loss: 2.5745 - val_accuracy: 0.2194 - val_f1: 0.0715\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4332 - accuracy: 0.2505 - f1: 0.0836 - val_loss: 2.5535 - val_accuracy: 0.2251 - val_f1: 0.0611\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4314 - accuracy: 0.2518 - f1: 0.0847 - val_loss: 2.5490 - val_accuracy: 0.2250 - val_f1: 0.0832\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4295 - accuracy: 0.2524 - f1: 0.0861 - val_loss: 2.5414 - val_accuracy: 0.2284 - val_f1: 0.0761\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4281 - accuracy: 0.2539 - f1: 0.0875 - val_loss: 2.5525 - val_accuracy: 0.2257 - val_f1: 0.0779\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4277 - accuracy: 0.2541 - f1: 0.0869 - val_loss: 2.5523 - val_accuracy: 0.2221 - val_f1: 0.0744\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4256 - accuracy: 0.2523 - f1: 0.0883 - val_loss: 2.5760 - val_accuracy: 0.2212 - val_f1: 0.0750\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4249 - accuracy: 0.2544 - f1: 0.0869 - val_loss: 2.5613 - val_accuracy: 0.2242 - val_f1: 0.0665\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4236 - accuracy: 0.2558 - f1: 0.0885 - val_loss: 2.5497 - val_accuracy: 0.2281 - val_f1: 0.0698\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4217 - accuracy: 0.2550 - f1: 0.0887 - val_loss: 2.5648 - val_accuracy: 0.2221 - val_f1: 0.0835\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4200 - accuracy: 0.2552 - f1: 0.0888 - val_loss: 2.5418 - val_accuracy: 0.2312 - val_f1: 0.0791\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4188 - accuracy: 0.2556 - f1: 0.0885 - val_loss: 2.5530 - val_accuracy: 0.2277 - val_f1: 0.0816\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4170 - accuracy: 0.2561 - f1: 0.0905 - val_loss: 2.5574 - val_accuracy: 0.2279 - val_f1: 0.0798\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4170 - accuracy: 0.2554 - f1: 0.0906 - val_loss: 2.5556 - val_accuracy: 0.2232 - val_f1: 0.0771\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.4136 - accuracy: 0.2568 - f1: 0.0904 - val_loss: 2.5542 - val_accuracy: 0.2257 - val_f1: 0.0764\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4152 - accuracy: 0.2567 - f1: 0.0902 - val_loss: 2.5416 - val_accuracy: 0.2299 - val_f1: 0.0840\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4143 - accuracy: 0.2575 - f1: 0.0912 - val_loss: 2.5667 - val_accuracy: 0.2244 - val_f1: 0.0841\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4128 - accuracy: 0.2567 - f1: 0.0916 - val_loss: 2.5478 - val_accuracy: 0.2280 - val_f1: 0.0895\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4114 - accuracy: 0.2566 - f1: 0.0927 - val_loss: 2.5539 - val_accuracy: 0.2230 - val_f1: 0.0812\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4081 - accuracy: 0.2584 - f1: 0.0931 - val_loss: 2.5875 - val_accuracy: 0.2174 - val_f1: 0.0865\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4084 - accuracy: 0.2579 - f1: 0.0934 - val_loss: 2.5745 - val_accuracy: 0.2221 - val_f1: 0.0716\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4069 - accuracy: 0.2585 - f1: 0.0949 - val_loss: 2.5651 - val_accuracy: 0.2260 - val_f1: 0.0868\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4067 - accuracy: 0.2579 - f1: 0.0944 - val_loss: 2.5556 - val_accuracy: 0.2270 - val_f1: 0.0784\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4059 - accuracy: 0.2599 - f1: 0.0963 - val_loss: 2.6138 - val_accuracy: 0.2140 - val_f1: 0.0925\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4033 - accuracy: 0.2593 - f1: 0.0957 - val_loss: 2.5688 - val_accuracy: 0.2232 - val_f1: 0.0889\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4016 - accuracy: 0.2618 - f1: 0.0954 - val_loss: 2.5918 - val_accuracy: 0.2197 - val_f1: 0.0746\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m4= CreateMultiPerceptron(4,100,100,0.0005,4,\"../music/music/tagged_feature_sets/msd-jmirspectral_dev/msd-jmirspectral_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.8630 - accuracy: 0.1360 - f1: 8.1387e-04 - val_loss: 2.7971 - val_accuracy: 0.1548 - val_f1: 8.9249e-04\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.7140 - accuracy: 0.1767 - f1: 0.0068 - val_loss: 2.7871 - val_accuracy: 0.1667 - val_f1: 0.0211\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.6722 - accuracy: 0.1904 - f1: 0.0154 - val_loss: 2.6372 - val_accuracy: 0.2027 - val_f1: 0.0364\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6417 - accuracy: 0.1991 - f1: 0.0270 - val_loss: 2.6293 - val_accuracy: 0.2019 - val_f1: 0.0232\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6164 - accuracy: 0.2067 - f1: 0.0359 - val_loss: 2.6486 - val_accuracy: 0.1989 - val_f1: 0.0465\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6034 - accuracy: 0.2085 - f1: 0.0383 - val_loss: 2.5932 - val_accuracy: 0.2147 - val_f1: 0.0322\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5940 - accuracy: 0.2130 - f1: 0.0411 - val_loss: 2.5877 - val_accuracy: 0.2117 - val_f1: 0.0634\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5854 - accuracy: 0.2154 - f1: 0.0430 - val_loss: 2.6229 - val_accuracy: 0.2072 - val_f1: 0.0477\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5746 - accuracy: 0.2181 - f1: 0.0461 - val_loss: 2.5922 - val_accuracy: 0.2156 - val_f1: 0.0346\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5698 - accuracy: 0.2184 - f1: 0.0458 - val_loss: 2.5815 - val_accuracy: 0.2213 - val_f1: 0.0316\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5632 - accuracy: 0.2217 - f1: 0.0476 - val_loss: 2.5578 - val_accuracy: 0.2228 - val_f1: 0.0524\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5559 - accuracy: 0.2219 - f1: 0.0506 - val_loss: 2.5670 - val_accuracy: 0.2184 - val_f1: 0.0360\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5497 - accuracy: 0.2240 - f1: 0.0525 - val_loss: 2.5559 - val_accuracy: 0.2259 - val_f1: 0.0711\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5459 - accuracy: 0.2248 - f1: 0.0515 - val_loss: 2.5365 - val_accuracy: 0.2287 - val_f1: 0.0499\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5389 - accuracy: 0.2274 - f1: 0.0540 - val_loss: 2.5791 - val_accuracy: 0.2153 - val_f1: 0.0277\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5343 - accuracy: 0.2287 - f1: 0.0553 - val_loss: 2.5711 - val_accuracy: 0.2189 - val_f1: 0.0648\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5293 - accuracy: 0.2300 - f1: 0.0571 - val_loss: 2.5798 - val_accuracy: 0.2172 - val_f1: 0.0517\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5264 - accuracy: 0.2315 - f1: 0.0576 - val_loss: 2.5510 - val_accuracy: 0.2248 - val_f1: 0.0584\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5220 - accuracy: 0.2307 - f1: 0.0589 - val_loss: 2.5349 - val_accuracy: 0.2297 - val_f1: 0.0534\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5193 - accuracy: 0.2313 - f1: 0.0591 - val_loss: 2.5381 - val_accuracy: 0.2276 - val_f1: 0.0623\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5112 - accuracy: 0.2338 - f1: 0.0620 - val_loss: 2.5226 - val_accuracy: 0.2314 - val_f1: 0.0622\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5057 - accuracy: 0.2351 - f1: 0.0633 - val_loss: 2.5248 - val_accuracy: 0.2308 - val_f1: 0.0633\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5070 - accuracy: 0.2348 - f1: 0.0637 - val_loss: 2.5617 - val_accuracy: 0.2229 - val_f1: 0.0813\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5034 - accuracy: 0.2366 - f1: 0.0644 - val_loss: 2.5371 - val_accuracy: 0.2296 - val_f1: 0.0660\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4988 - accuracy: 0.2365 - f1: 0.0647 - val_loss: 2.5273 - val_accuracy: 0.2290 - val_f1: 0.0469\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4920 - accuracy: 0.2393 - f1: 0.0667 - val_loss: 2.5196 - val_accuracy: 0.2343 - val_f1: 0.0711\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4913 - accuracy: 0.2385 - f1: 0.0670 - val_loss: 2.5540 - val_accuracy: 0.2271 - val_f1: 0.0866\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4876 - accuracy: 0.2405 - f1: 0.0676 - val_loss: 2.5192 - val_accuracy: 0.2336 - val_f1: 0.0588\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4859 - accuracy: 0.2407 - f1: 0.0692 - val_loss: 2.5336 - val_accuracy: 0.2320 - val_f1: 0.0709\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4825 - accuracy: 0.2420 - f1: 0.0688 - val_loss: 2.5379 - val_accuracy: 0.2240 - val_f1: 0.0571\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4759 - accuracy: 0.2452 - f1: 0.0713 - val_loss: 2.5114 - val_accuracy: 0.2367 - val_f1: 0.0607\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4760 - accuracy: 0.2439 - f1: 0.0718 - val_loss: 2.5127 - val_accuracy: 0.2335 - val_f1: 0.0754\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4713 - accuracy: 0.2444 - f1: 0.0724 - val_loss: 2.5076 - val_accuracy: 0.2353 - val_f1: 0.0669\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4705 - accuracy: 0.2432 - f1: 0.0723 - val_loss: 2.5041 - val_accuracy: 0.2402 - val_f1: 0.0775\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4640 - accuracy: 0.2469 - f1: 0.0750 - val_loss: 2.5223 - val_accuracy: 0.2311 - val_f1: 0.0428\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4643 - accuracy: 0.2464 - f1: 0.0752 - val_loss: 2.5163 - val_accuracy: 0.2365 - val_f1: 0.0881\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4585 - accuracy: 0.2494 - f1: 0.0765 - val_loss: 2.4858 - val_accuracy: 0.2439 - val_f1: 0.0727\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4574 - accuracy: 0.2483 - f1: 0.0771 - val_loss: 2.5061 - val_accuracy: 0.2392 - val_f1: 0.0874\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4534 - accuracy: 0.2500 - f1: 0.0780 - val_loss: 2.5079 - val_accuracy: 0.2359 - val_f1: 0.0708\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4515 - accuracy: 0.2514 - f1: 0.0800 - val_loss: 2.5121 - val_accuracy: 0.2338 - val_f1: 0.0832\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4490 - accuracy: 0.2516 - f1: 0.0797 - val_loss: 2.5045 - val_accuracy: 0.2340 - val_f1: 0.0826\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4492 - accuracy: 0.2501 - f1: 0.0801 - val_loss: 2.5136 - val_accuracy: 0.2344 - val_f1: 0.0749\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4460 - accuracy: 0.2517 - f1: 0.0811 - val_loss: 2.5084 - val_accuracy: 0.2396 - val_f1: 0.0756\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4413 - accuracy: 0.2530 - f1: 0.0829 - val_loss: 2.5139 - val_accuracy: 0.2371 - val_f1: 0.0600\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4380 - accuracy: 0.2539 - f1: 0.0839 - val_loss: 2.5162 - val_accuracy: 0.2371 - val_f1: 0.0734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4362 - accuracy: 0.2541 - f1: 0.0834 - val_loss: 2.5287 - val_accuracy: 0.2293 - val_f1: 0.0588\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4349 - accuracy: 0.2542 - f1: 0.0842 - val_loss: 2.5066 - val_accuracy: 0.2407 - val_f1: 0.0926\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4339 - accuracy: 0.2541 - f1: 0.0861 - val_loss: 2.5403 - val_accuracy: 0.2318 - val_f1: 0.0804\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4319 - accuracy: 0.2565 - f1: 0.0879 - val_loss: 2.5123 - val_accuracy: 0.2338 - val_f1: 0.0477\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4299 - accuracy: 0.2557 - f1: 0.0867 - val_loss: 2.5218 - val_accuracy: 0.2335 - val_f1: 0.0608\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4253 - accuracy: 0.2580 - f1: 0.0877 - val_loss: 2.5046 - val_accuracy: 0.2394 - val_f1: 0.1033\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4220 - accuracy: 0.2591 - f1: 0.0890 - val_loss: 2.5197 - val_accuracy: 0.2353 - val_f1: 0.0680\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4222 - accuracy: 0.2577 - f1: 0.0892 - val_loss: 2.5312 - val_accuracy: 0.2284 - val_f1: 0.0751\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4197 - accuracy: 0.2585 - f1: 0.0909 - val_loss: 2.5028 - val_accuracy: 0.2374 - val_f1: 0.0648\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4157 - accuracy: 0.2609 - f1: 0.0902 - val_loss: 2.4945 - val_accuracy: 0.2429 - val_f1: 0.0892\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4174 - accuracy: 0.2581 - f1: 0.0911 - val_loss: 2.4855 - val_accuracy: 0.2459 - val_f1: 0.0932\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4138 - accuracy: 0.2612 - f1: 0.0913 - val_loss: 2.5044 - val_accuracy: 0.2419 - val_f1: 0.0879\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4125 - accuracy: 0.2617 - f1: 0.0923 - val_loss: 2.5115 - val_accuracy: 0.2360 - val_f1: 0.0855\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4115 - accuracy: 0.2612 - f1: 0.0924 - val_loss: 2.5274 - val_accuracy: 0.2385 - val_f1: 0.0885\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4090 - accuracy: 0.2619 - f1: 0.0942 - val_loss: 2.4972 - val_accuracy: 0.2430 - val_f1: 0.0988\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.4046 - accuracy: 0.2630 - f1: 0.0959 - val_loss: 2.5099 - val_accuracy: 0.2413 - val_f1: 0.0910\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4030 - accuracy: 0.2639 - f1: 0.0957 - val_loss: 2.5133 - val_accuracy: 0.2343 - val_f1: 0.0813\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4003 - accuracy: 0.2645 - f1: 0.0967 - val_loss: 2.5246 - val_accuracy: 0.2331 - val_f1: 0.0717\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3994 - accuracy: 0.2639 - f1: 0.0965 - val_loss: 2.5460 - val_accuracy: 0.2289 - val_f1: 0.0824\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3970 - accuracy: 0.2651 - f1: 0.0978 - val_loss: 2.4934 - val_accuracy: 0.2471 - val_f1: 0.0855\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3971 - accuracy: 0.2650 - f1: 0.0972 - val_loss: 2.5273 - val_accuracy: 0.2405 - val_f1: 0.1068\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3941 - accuracy: 0.2655 - f1: 0.0992 - val_loss: 2.5118 - val_accuracy: 0.2373 - val_f1: 0.0755\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3945 - accuracy: 0.2658 - f1: 0.0987 - val_loss: 2.5220 - val_accuracy: 0.2384 - val_f1: 0.0796\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3916 - accuracy: 0.2670 - f1: 0.1008 - val_loss: 2.5147 - val_accuracy: 0.2408 - val_f1: 0.0925\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3896 - accuracy: 0.2668 - f1: 0.1000 - val_loss: 2.4986 - val_accuracy: 0.2415 - val_f1: 0.0867\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3872 - accuracy: 0.2665 - f1: 0.1011 - val_loss: 2.5053 - val_accuracy: 0.2423 - val_f1: 0.0953\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3892 - accuracy: 0.2665 - f1: 0.1026 - val_loss: 2.5258 - val_accuracy: 0.2374 - val_f1: 0.0848\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3870 - accuracy: 0.2679 - f1: 0.1010 - val_loss: 2.4974 - val_accuracy: 0.2438 - val_f1: 0.0862\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3811 - accuracy: 0.2705 - f1: 0.1033 - val_loss: 2.5287 - val_accuracy: 0.2395 - val_f1: 0.1063\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3821 - accuracy: 0.2699 - f1: 0.1042 - val_loss: 2.4963 - val_accuracy: 0.2485 - val_f1: 0.0919\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3783 - accuracy: 0.2701 - f1: 0.1045 - val_loss: 2.4952 - val_accuracy: 0.2466 - val_f1: 0.0981\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3797 - accuracy: 0.2703 - f1: 0.1035 - val_loss: 2.5099 - val_accuracy: 0.2435 - val_f1: 0.0937\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3805 - accuracy: 0.2695 - f1: 0.1047 - val_loss: 2.5320 - val_accuracy: 0.2396 - val_f1: 0.0847\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3800 - accuracy: 0.2705 - f1: 0.1043 - val_loss: 2.5137 - val_accuracy: 0.2449 - val_f1: 0.0943\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3746 - accuracy: 0.2714 - f1: 0.1060 - val_loss: 2.5531 - val_accuracy: 0.2314 - val_f1: 0.0792\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3771 - accuracy: 0.2702 - f1: 0.1052 - val_loss: 2.5051 - val_accuracy: 0.2428 - val_f1: 0.0863\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3717 - accuracy: 0.2735 - f1: 0.1073 - val_loss: 2.5196 - val_accuracy: 0.2433 - val_f1: 0.0953\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3707 - accuracy: 0.2728 - f1: 0.1086 - val_loss: 2.5223 - val_accuracy: 0.2389 - val_f1: 0.0829\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3725 - accuracy: 0.2729 - f1: 0.1077 - val_loss: 2.5262 - val_accuracy: 0.2399 - val_f1: 0.0838\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3708 - accuracy: 0.2725 - f1: 0.1090 - val_loss: 2.5048 - val_accuracy: 0.2406 - val_f1: 0.0834\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3694 - accuracy: 0.2744 - f1: 0.1096 - val_loss: 2.5152 - val_accuracy: 0.2421 - val_f1: 0.0813\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3662 - accuracy: 0.2744 - f1: 0.1081 - val_loss: 2.5218 - val_accuracy: 0.2407 - val_f1: 0.0825\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3653 - accuracy: 0.2735 - f1: 0.1102 - val_loss: 2.5254 - val_accuracy: 0.2432 - val_f1: 0.1051\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3644 - accuracy: 0.2742 - f1: 0.1105 - val_loss: 2.5111 - val_accuracy: 0.2463 - val_f1: 0.0911\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3614 - accuracy: 0.2748 - f1: 0.1109 - val_loss: 2.5305 - val_accuracy: 0.2385 - val_f1: 0.0883\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3622 - accuracy: 0.2742 - f1: 0.1117 - val_loss: 2.5276 - val_accuracy: 0.2376 - val_f1: 0.0857\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3586 - accuracy: 0.2775 - f1: 0.1128 - val_loss: 2.5118 - val_accuracy: 0.2427 - val_f1: 0.0942\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3596 - accuracy: 0.2748 - f1: 0.1134 - val_loss: 2.5278 - val_accuracy: 0.2391 - val_f1: 0.1080\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3589 - accuracy: 0.2763 - f1: 0.1134 - val_loss: 2.5175 - val_accuracy: 0.2429 - val_f1: 0.1049\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3555 - accuracy: 0.2759 - f1: 0.1137 - val_loss: 2.5152 - val_accuracy: 0.2449 - val_f1: 0.0941\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3538 - accuracy: 0.2768 - f1: 0.1129 - val_loss: 2.5054 - val_accuracy: 0.2447 - val_f1: 0.0867\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3517 - accuracy: 0.2763 - f1: 0.1139 - val_loss: 2.5231 - val_accuracy: 0.2415 - val_f1: 0.0951\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3570 - accuracy: 0.2774 - f1: 0.1137 - val_loss: 2.5014 - val_accuracy: 0.2464 - val_f1: 0.1025\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3531 - accuracy: 0.2778 - f1: 0.1154 - val_loss: 2.5073 - val_accuracy: 0.2454 - val_f1: 0.0996\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3489 - accuracy: 0.2793 - f1: 0.1162 - val_loss: 2.5102 - val_accuracy: 0.2452 - val_f1: 0.0922\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m5= CreateMultiPerceptron(4,100,100,0.0005,5,\"../music/music/tagged_feature_sets/msd-jmirmfccs_dev/msd-jmirmfccs_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 3.0154 - accuracy: 0.1152 - f1: 0.0227 - val_loss: 2.9392 - val_accuracy: 0.1358 - val_f1: 0.0479\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.9049 - accuracy: 0.1436 - f1: 0.0404 - val_loss: 2.9847 - val_accuracy: 0.1238 - val_f1: 0.0322\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.8508 - accuracy: 0.1553 - f1: 0.0450 - val_loss: 2.8397 - val_accuracy: 0.1571 - val_f1: 0.0498\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.8234 - accuracy: 0.1621 - f1: 0.0486 - val_loss: 2.8538 - val_accuracy: 0.1545 - val_f1: 0.0509\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.8125 - accuracy: 0.1630 - f1: 0.0490 - val_loss: 2.8797 - val_accuracy: 0.1441 - val_f1: 0.0487\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7991 - accuracy: 0.1673 - f1: 0.0506 - val_loss: 2.7983 - val_accuracy: 0.1713 - val_f1: 0.0548\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7915 - accuracy: 0.1694 - f1: 0.0512 - val_loss: 2.7770 - val_accuracy: 0.1725 - val_f1: 0.0505\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7855 - accuracy: 0.1696 - f1: 0.0525 - val_loss: 2.7761 - val_accuracy: 0.1745 - val_f1: 0.0455\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7815 - accuracy: 0.1713 - f1: 0.0513 - val_loss: 2.7680 - val_accuracy: 0.1760 - val_f1: 0.0508\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7722 - accuracy: 0.1720 - f1: 0.0541 - val_loss: 2.7859 - val_accuracy: 0.1718 - val_f1: 0.0601\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7714 - accuracy: 0.1716 - f1: 0.0537 - val_loss: 2.7987 - val_accuracy: 0.1693 - val_f1: 0.0463\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7652 - accuracy: 0.1744 - f1: 0.0539 - val_loss: 2.7698 - val_accuracy: 0.1714 - val_f1: 0.0474\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7602 - accuracy: 0.1752 - f1: 0.0554 - val_loss: 2.8205 - val_accuracy: 0.1631 - val_f1: 0.0442\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7562 - accuracy: 0.1760 - f1: 0.0554 - val_loss: 2.7729 - val_accuracy: 0.1734 - val_f1: 0.0625\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.7559 - accuracy: 0.1747 - f1: 0.0554 - val_loss: 2.8790 - val_accuracy: 0.1516 - val_f1: 0.0573\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7487 - accuracy: 0.1777 - f1: 0.0565 - val_loss: 2.7844 - val_accuracy: 0.1676 - val_f1: 0.0414\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.7438 - accuracy: 0.1784 - f1: 0.0570 - val_loss: 2.8196 - val_accuracy: 0.1594 - val_f1: 0.0340\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7406 - accuracy: 0.1797 - f1: 0.0584 - val_loss: 2.7520 - val_accuracy: 0.1755 - val_f1: 0.0497\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7364 - accuracy: 0.1803 - f1: 0.0587 - val_loss: 2.7262 - val_accuracy: 0.1844 - val_f1: 0.0605\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7341 - accuracy: 0.1808 - f1: 0.0600 - val_loss: 2.7501 - val_accuracy: 0.1781 - val_f1: 0.0496\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7296 - accuracy: 0.1823 - f1: 0.0595 - val_loss: 2.7501 - val_accuracy: 0.1777 - val_f1: 0.0550\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7248 - accuracy: 0.1831 - f1: 0.0604 - val_loss: 2.8072 - val_accuracy: 0.1648 - val_f1: 0.0636\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7235 - accuracy: 0.1837 - f1: 0.0614 - val_loss: 2.7293 - val_accuracy: 0.1841 - val_f1: 0.0619\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7193 - accuracy: 0.1837 - f1: 0.0615 - val_loss: 2.8295 - val_accuracy: 0.1675 - val_f1: 0.0622\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7136 - accuracy: 0.1857 - f1: 0.0628 - val_loss: 2.7392 - val_accuracy: 0.1816 - val_f1: 0.0480\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7148 - accuracy: 0.1849 - f1: 0.0607 - val_loss: 2.7149 - val_accuracy: 0.1841 - val_f1: 0.0482\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7117 - accuracy: 0.1859 - f1: 0.0629 - val_loss: 2.7849 - val_accuracy: 0.1719 - val_f1: 0.0523\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7071 - accuracy: 0.1875 - f1: 0.0628 - val_loss: 2.7264 - val_accuracy: 0.1834 - val_f1: 0.0524\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7065 - accuracy: 0.1877 - f1: 0.0622 - val_loss: 2.7402 - val_accuracy: 0.1849 - val_f1: 0.0701\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7019 - accuracy: 0.1887 - f1: 0.0631 - val_loss: 2.7129 - val_accuracy: 0.1864 - val_f1: 0.0567\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7019 - accuracy: 0.1875 - f1: 0.0641 - val_loss: 2.7019 - val_accuracy: 0.1911 - val_f1: 0.0671\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6983 - accuracy: 0.1889 - f1: 0.0635 - val_loss: 2.7187 - val_accuracy: 0.1860 - val_f1: 0.0637\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6989 - accuracy: 0.1897 - f1: 0.0639 - val_loss: 2.7348 - val_accuracy: 0.1845 - val_f1: 0.0584\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6930 - accuracy: 0.1903 - f1: 0.0648 - val_loss: 2.7098 - val_accuracy: 0.1879 - val_f1: 0.0599\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6932 - accuracy: 0.1908 - f1: 0.0642 - val_loss: 2.7296 - val_accuracy: 0.1834 - val_f1: 0.0568\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 4s 30us/step - loss: 2.6912 - accuracy: 0.1907 - f1: 0.0647 - val_loss: 2.7124 - val_accuracy: 0.1858 - val_f1: 0.0593\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6864 - accuracy: 0.1921 - f1: 0.0652 - val_loss: 2.7071 - val_accuracy: 0.1886 - val_f1: 0.0614\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6882 - accuracy: 0.1913 - f1: 0.0642 - val_loss: 2.7019 - val_accuracy: 0.1894 - val_f1: 0.0547\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6862 - accuracy: 0.1918 - f1: 0.0650 - val_loss: 2.7028 - val_accuracy: 0.1890 - val_f1: 0.0768\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6841 - accuracy: 0.1911 - f1: 0.0657 - val_loss: 2.7146 - val_accuracy: 0.1876 - val_f1: 0.0721\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6853 - accuracy: 0.1933 - f1: 0.0655 - val_loss: 2.7616 - val_accuracy: 0.1776 - val_f1: 0.0575\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6856 - accuracy: 0.1913 - f1: 0.0658 - val_loss: 2.7443 - val_accuracy: 0.1825 - val_f1: 0.0666\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6777 - accuracy: 0.1941 - f1: 0.0660 - val_loss: 2.7171 - val_accuracy: 0.1835 - val_f1: 0.0604\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6813 - accuracy: 0.1926 - f1: 0.0662 - val_loss: 2.6915 - val_accuracy: 0.1943 - val_f1: 0.0721\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 4s 30us/step - loss: 2.6760 - accuracy: 0.1933 - f1: 0.0661 - val_loss: 2.7213 - val_accuracy: 0.1838 - val_f1: 0.0761\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6763 - accuracy: 0.1939 - f1: 0.0674 - val_loss: 2.6992 - val_accuracy: 0.1923 - val_f1: 0.0679\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6747 - accuracy: 0.1939 - f1: 0.0672 - val_loss: 2.7093 - val_accuracy: 0.1893 - val_f1: 0.0615\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6710 - accuracy: 0.1945 - f1: 0.0675 - val_loss: 2.7673 - val_accuracy: 0.1772 - val_f1: 0.0667\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6728 - accuracy: 0.1959 - f1: 0.0675 - val_loss: 2.7128 - val_accuracy: 0.1898 - val_f1: 0.0735\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6691 - accuracy: 0.1949 - f1: 0.0673 - val_loss: 2.7019 - val_accuracy: 0.1929 - val_f1: 0.0730\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6668 - accuracy: 0.1973 - f1: 0.0677 - val_loss: 2.7115 - val_accuracy: 0.1894 - val_f1: 0.0643\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6665 - accuracy: 0.1970 - f1: 0.0672 - val_loss: 2.6923 - val_accuracy: 0.1927 - val_f1: 0.0668\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6645 - accuracy: 0.1961 - f1: 0.0693 - val_loss: 2.6997 - val_accuracy: 0.1891 - val_f1: 0.0728\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6623 - accuracy: 0.1972 - f1: 0.0694 - val_loss: 2.7197 - val_accuracy: 0.1855 - val_f1: 0.0656\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6653 - accuracy: 0.1965 - f1: 0.0689 - val_loss: 2.7371 - val_accuracy: 0.1856 - val_f1: 0.0641\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6625 - accuracy: 0.1963 - f1: 0.0684 - val_loss: 2.7029 - val_accuracy: 0.1902 - val_f1: 0.0644\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6638 - accuracy: 0.1958 - f1: 0.0687 - val_loss: 2.6957 - val_accuracy: 0.1953 - val_f1: 0.0668\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6573 - accuracy: 0.1973 - f1: 0.0697 - val_loss: 2.7246 - val_accuracy: 0.1869 - val_f1: 0.0795\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6598 - accuracy: 0.1977 - f1: 0.0690 - val_loss: 2.7016 - val_accuracy: 0.1928 - val_f1: 0.0693\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6566 - accuracy: 0.1988 - f1: 0.0696 - val_loss: 2.7252 - val_accuracy: 0.1871 - val_f1: 0.0751\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6553 - accuracy: 0.1984 - f1: 0.0696 - val_loss: 2.7395 - val_accuracy: 0.1831 - val_f1: 0.0617\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6553 - accuracy: 0.1998 - f1: 0.0702 - val_loss: 2.7018 - val_accuracy: 0.1917 - val_f1: 0.0724\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6545 - accuracy: 0.1988 - f1: 0.0699 - val_loss: 2.6977 - val_accuracy: 0.1942 - val_f1: 0.0619\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6528 - accuracy: 0.1996 - f1: 0.0701 - val_loss: 2.7535 - val_accuracy: 0.1821 - val_f1: 0.0675\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6469 - accuracy: 0.2007 - f1: 0.0702 - val_loss: 2.7094 - val_accuracy: 0.1921 - val_f1: 0.0767\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6506 - accuracy: 0.1996 - f1: 0.0708 - val_loss: 2.6908 - val_accuracy: 0.1946 - val_f1: 0.0639\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6473 - accuracy: 0.1990 - f1: 0.0717 - val_loss: 2.7259 - val_accuracy: 0.1880 - val_f1: 0.0676\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6510 - accuracy: 0.1996 - f1: 0.0712 - val_loss: 2.7665 - val_accuracy: 0.1751 - val_f1: 0.0491\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6448 - accuracy: 0.2013 - f1: 0.0704 - val_loss: 2.8173 - val_accuracy: 0.1723 - val_f1: 0.0697\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6458 - accuracy: 0.2013 - f1: 0.0708 - val_loss: 2.7100 - val_accuracy: 0.1920 - val_f1: 0.0651\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 4s 30us/step - loss: 2.6441 - accuracy: 0.2013 - f1: 0.0719 - val_loss: 2.7167 - val_accuracy: 0.1895 - val_f1: 0.0585\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6425 - accuracy: 0.2008 - f1: 0.0722 - val_loss: 2.7434 - val_accuracy: 0.1822 - val_f1: 0.0727\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 4s 30us/step - loss: 2.6395 - accuracy: 0.2013 - f1: 0.0730 - val_loss: 2.7184 - val_accuracy: 0.1895 - val_f1: 0.0609\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6395 - accuracy: 0.2028 - f1: 0.0728 - val_loss: 2.7081 - val_accuracy: 0.1914 - val_f1: 0.0724\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6382 - accuracy: 0.2031 - f1: 0.0730 - val_loss: 2.6920 - val_accuracy: 0.1928 - val_f1: 0.0662\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6413 - accuracy: 0.2015 - f1: 0.0724 - val_loss: 2.7260 - val_accuracy: 0.1843 - val_f1: 0.0610\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6418 - accuracy: 0.2017 - f1: 0.0715 - val_loss: 2.7244 - val_accuracy: 0.1874 - val_f1: 0.0730\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6366 - accuracy: 0.2039 - f1: 0.0724 - val_loss: 2.6881 - val_accuracy: 0.1933 - val_f1: 0.0729\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6358 - accuracy: 0.2039 - f1: 0.0727 - val_loss: 2.6937 - val_accuracy: 0.1936 - val_f1: 0.0701\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6338 - accuracy: 0.2037 - f1: 0.0728 - val_loss: 2.7076 - val_accuracy: 0.1888 - val_f1: 0.0628\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6345 - accuracy: 0.2037 - f1: 0.0731 - val_loss: 2.6941 - val_accuracy: 0.1918 - val_f1: 0.0687\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6316 - accuracy: 0.2036 - f1: 0.0744 - val_loss: 2.7233 - val_accuracy: 0.1891 - val_f1: 0.0788\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6310 - accuracy: 0.2050 - f1: 0.0745 - val_loss: 2.6915 - val_accuracy: 0.1943 - val_f1: 0.0706\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6279 - accuracy: 0.2048 - f1: 0.0738 - val_loss: 2.7005 - val_accuracy: 0.1918 - val_f1: 0.0716\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6282 - accuracy: 0.2043 - f1: 0.0751 - val_loss: 2.6882 - val_accuracy: 0.1937 - val_f1: 0.0644\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6276 - accuracy: 0.2036 - f1: 0.0745 - val_loss: 2.7208 - val_accuracy: 0.1894 - val_f1: 0.0597\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6279 - accuracy: 0.2040 - f1: 0.0740 - val_loss: 2.7369 - val_accuracy: 0.1866 - val_f1: 0.0753\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6258 - accuracy: 0.2056 - f1: 0.0746 - val_loss: 2.6867 - val_accuracy: 0.1953 - val_f1: 0.0755\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6219 - accuracy: 0.2054 - f1: 0.0749 - val_loss: 2.6879 - val_accuracy: 0.1942 - val_f1: 0.0728\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6234 - accuracy: 0.2056 - f1: 0.0758 - val_loss: 2.7043 - val_accuracy: 0.1907 - val_f1: 0.0689\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6211 - accuracy: 0.2062 - f1: 0.0757 - val_loss: 2.7122 - val_accuracy: 0.1895 - val_f1: 0.0625\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6235 - accuracy: 0.2071 - f1: 0.0746 - val_loss: 2.6944 - val_accuracy: 0.1953 - val_f1: 0.0680\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6215 - accuracy: 0.2064 - f1: 0.0755 - val_loss: 2.7441 - val_accuracy: 0.1858 - val_f1: 0.0677\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6191 - accuracy: 0.2082 - f1: 0.0765 - val_loss: 2.7538 - val_accuracy: 0.1827 - val_f1: 0.0659\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6208 - accuracy: 0.2071 - f1: 0.0763 - val_loss: 2.7028 - val_accuracy: 0.1948 - val_f1: 0.0662\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6171 - accuracy: 0.2076 - f1: 0.0762 - val_loss: 2.7165 - val_accuracy: 0.1925 - val_f1: 0.0698\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6170 - accuracy: 0.2076 - f1: 0.0765 - val_loss: 2.6942 - val_accuracy: 0.1945 - val_f1: 0.0557\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6146 - accuracy: 0.2078 - f1: 0.0765 - val_loss: 2.7443 - val_accuracy: 0.1840 - val_f1: 0.0687\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6165 - accuracy: 0.2092 - f1: 0.0771 - val_loss: 2.7108 - val_accuracy: 0.1913 - val_f1: 0.0759\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6182 - accuracy: 0.2073 - f1: 0.0752 - val_loss: 2.7050 - val_accuracy: 0.1906 - val_f1: 0.0705\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m6= CreateMultiPerceptron(4,100,100,0.0005,6,\"../music/music/tagged_feature_sets/msd-trh_dev/msd-trh_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.8048 - accuracy: 0.1575 - f1: 0.0018 - val_loss: 2.7273 - val_accuracy: 0.1803 - val_f1: 0.0040\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.7039 - accuracy: 0.1830 - f1: 0.0101 - val_loss: 2.6944 - val_accuracy: 0.1854 - val_f1: 0.0108\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6744 - accuracy: 0.1918 - f1: 0.0186 - val_loss: 2.6619 - val_accuracy: 0.1936 - val_f1: 0.0166\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6542 - accuracy: 0.1972 - f1: 0.0233 - val_loss: 2.6492 - val_accuracy: 0.1981 - val_f1: 0.0321\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6414 - accuracy: 0.2003 - f1: 0.0276 - val_loss: 2.6445 - val_accuracy: 0.2018 - val_f1: 0.0185\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6317 - accuracy: 0.2033 - f1: 0.0306 - val_loss: 2.6352 - val_accuracy: 0.2029 - val_f1: 0.0356\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6221 - accuracy: 0.2067 - f1: 0.0327 - val_loss: 2.6517 - val_accuracy: 0.2025 - val_f1: 0.0345\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6149 - accuracy: 0.2078 - f1: 0.0346 - val_loss: 2.6357 - val_accuracy: 0.2051 - val_f1: 0.0445\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6096 - accuracy: 0.2087 - f1: 0.0374 - val_loss: 2.6222 - val_accuracy: 0.2072 - val_f1: 0.0327\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.6026 - accuracy: 0.2111 - f1: 0.0382 - val_loss: 2.6184 - val_accuracy: 0.2089 - val_f1: 0.0394\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5945 - accuracy: 0.2130 - f1: 0.0400 - val_loss: 2.6085 - val_accuracy: 0.2107 - val_f1: 0.0377\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5909 - accuracy: 0.2131 - f1: 0.0407 - val_loss: 2.6165 - val_accuracy: 0.2069 - val_f1: 0.0440\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5849 - accuracy: 0.2151 - f1: 0.0407 - val_loss: 2.6207 - val_accuracy: 0.2068 - val_f1: 0.0230\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5789 - accuracy: 0.2168 - f1: 0.0433 - val_loss: 2.6248 - val_accuracy: 0.2086 - val_f1: 0.0369\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5733 - accuracy: 0.2180 - f1: 0.0440 - val_loss: 2.6115 - val_accuracy: 0.2101 - val_f1: 0.0402\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5691 - accuracy: 0.2200 - f1: 0.0452 - val_loss: 2.6111 - val_accuracy: 0.2106 - val_f1: 0.0611\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5650 - accuracy: 0.2197 - f1: 0.0457 - val_loss: 2.6079 - val_accuracy: 0.2130 - val_f1: 0.0502\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5608 - accuracy: 0.2209 - f1: 0.0472 - val_loss: 2.6042 - val_accuracy: 0.2115 - val_f1: 0.0402\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5562 - accuracy: 0.2231 - f1: 0.0484 - val_loss: 2.6095 - val_accuracy: 0.2121 - val_f1: 0.0467\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5512 - accuracy: 0.2241 - f1: 0.0496 - val_loss: 2.6134 - val_accuracy: 0.2088 - val_f1: 0.0382\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5483 - accuracy: 0.2253 - f1: 0.0503 - val_loss: 2.6152 - val_accuracy: 0.2088 - val_f1: 0.0515\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5426 - accuracy: 0.2276 - f1: 0.0527 - val_loss: 2.6034 - val_accuracy: 0.2141 - val_f1: 0.0410\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5388 - accuracy: 0.2276 - f1: 0.0536 - val_loss: 2.6240 - val_accuracy: 0.2107 - val_f1: 0.0456\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5340 - accuracy: 0.2269 - f1: 0.0533 - val_loss: 2.6056 - val_accuracy: 0.2148 - val_f1: 0.0611\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5315 - accuracy: 0.2288 - f1: 0.0547 - val_loss: 2.6060 - val_accuracy: 0.2129 - val_f1: 0.0519\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5259 - accuracy: 0.2301 - f1: 0.0553 - val_loss: 2.6152 - val_accuracy: 0.2125 - val_f1: 0.0464\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5228 - accuracy: 0.2308 - f1: 0.0570 - val_loss: 2.6069 - val_accuracy: 0.2129 - val_f1: 0.0462\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5191 - accuracy: 0.2316 - f1: 0.0589 - val_loss: 2.6082 - val_accuracy: 0.2116 - val_f1: 0.0576\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5155 - accuracy: 0.2329 - f1: 0.0585 - val_loss: 2.6108 - val_accuracy: 0.2118 - val_f1: 0.0586\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.5131 - accuracy: 0.2344 - f1: 0.0584 - val_loss: 2.6045 - val_accuracy: 0.2141 - val_f1: 0.0468\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5087 - accuracy: 0.2329 - f1: 0.0595 - val_loss: 2.6127 - val_accuracy: 0.2111 - val_f1: 0.0501\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5062 - accuracy: 0.2359 - f1: 0.0600 - val_loss: 2.6148 - val_accuracy: 0.2106 - val_f1: 0.0518\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5016 - accuracy: 0.2357 - f1: 0.0626 - val_loss: 2.6186 - val_accuracy: 0.2094 - val_f1: 0.0435\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4981 - accuracy: 0.2385 - f1: 0.0624 - val_loss: 2.6151 - val_accuracy: 0.2096 - val_f1: 0.0596\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4934 - accuracy: 0.2387 - f1: 0.0642 - val_loss: 2.6194 - val_accuracy: 0.2112 - val_f1: 0.0569\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4914 - accuracy: 0.2387 - f1: 0.0645 - val_loss: 2.6290 - val_accuracy: 0.2133 - val_f1: 0.0674\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4889 - accuracy: 0.2387 - f1: 0.0656 - val_loss: 2.6206 - val_accuracy: 0.2130 - val_f1: 0.0717\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4854 - accuracy: 0.2404 - f1: 0.0656 - val_loss: 2.6179 - val_accuracy: 0.2126 - val_f1: 0.0527\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4808 - accuracy: 0.2412 - f1: 0.0671 - val_loss: 2.6217 - val_accuracy: 0.2131 - val_f1: 0.0512\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4785 - accuracy: 0.2415 - f1: 0.0680 - val_loss: 2.6222 - val_accuracy: 0.2106 - val_f1: 0.0608\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4756 - accuracy: 0.2429 - f1: 0.0688 - val_loss: 2.6255 - val_accuracy: 0.2115 - val_f1: 0.0563\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4721 - accuracy: 0.2430 - f1: 0.0702 - val_loss: 2.6231 - val_accuracy: 0.2132 - val_f1: 0.0662\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4706 - accuracy: 0.2435 - f1: 0.0715 - val_loss: 2.6333 - val_accuracy: 0.2103 - val_f1: 0.0687\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4661 - accuracy: 0.2451 - f1: 0.0714 - val_loss: 2.6396 - val_accuracy: 0.2111 - val_f1: 0.0733\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4651 - accuracy: 0.2463 - f1: 0.0714 - val_loss: 2.6313 - val_accuracy: 0.2080 - val_f1: 0.0547\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4629 - accuracy: 0.2473 - f1: 0.0732 - val_loss: 2.6262 - val_accuracy: 0.2126 - val_f1: 0.0567\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4592 - accuracy: 0.2473 - f1: 0.0749 - val_loss: 2.6301 - val_accuracy: 0.2132 - val_f1: 0.0567\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4580 - accuracy: 0.2478 - f1: 0.0754 - val_loss: 2.6302 - val_accuracy: 0.2103 - val_f1: 0.0573\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4546 - accuracy: 0.2494 - f1: 0.0744 - val_loss: 2.6312 - val_accuracy: 0.2134 - val_f1: 0.0543\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4504 - accuracy: 0.2490 - f1: 0.0770 - val_loss: 2.6303 - val_accuracy: 0.2177 - val_f1: 0.0638\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4482 - accuracy: 0.2508 - f1: 0.0773 - val_loss: 2.6417 - val_accuracy: 0.2087 - val_f1: 0.0563\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4473 - accuracy: 0.2499 - f1: 0.0776 - val_loss: 2.6563 - val_accuracy: 0.2056 - val_f1: 0.0620\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4432 - accuracy: 0.2507 - f1: 0.0789 - val_loss: 2.6422 - val_accuracy: 0.2091 - val_f1: 0.0628\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4410 - accuracy: 0.2524 - f1: 0.0800 - val_loss: 2.6435 - val_accuracy: 0.2117 - val_f1: 0.0708\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4400 - accuracy: 0.2518 - f1: 0.0803 - val_loss: 2.6398 - val_accuracy: 0.2138 - val_f1: 0.0598\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4377 - accuracy: 0.2525 - f1: 0.0814 - val_loss: 2.6592 - val_accuracy: 0.2052 - val_f1: 0.0629\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4350 - accuracy: 0.2536 - f1: 0.0821 - val_loss: 2.6553 - val_accuracy: 0.2081 - val_f1: 0.0594\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4328 - accuracy: 0.2538 - f1: 0.0833 - val_loss: 2.6589 - val_accuracy: 0.2053 - val_f1: 0.0565\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4315 - accuracy: 0.2553 - f1: 0.0841 - val_loss: 2.6516 - val_accuracy: 0.2106 - val_f1: 0.0663\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4283 - accuracy: 0.2549 - f1: 0.0846 - val_loss: 2.6613 - val_accuracy: 0.2078 - val_f1: 0.0604\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4267 - accuracy: 0.2555 - f1: 0.0846 - val_loss: 2.6547 - val_accuracy: 0.2110 - val_f1: 0.0620\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4233 - accuracy: 0.2564 - f1: 0.0859 - val_loss: 2.6573 - val_accuracy: 0.2086 - val_f1: 0.0626\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4225 - accuracy: 0.2552 - f1: 0.0871 - val_loss: 2.6509 - val_accuracy: 0.2120 - val_f1: 0.0639\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4206 - accuracy: 0.2572 - f1: 0.0873 - val_loss: 2.6680 - val_accuracy: 0.2096 - val_f1: 0.0649\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4188 - accuracy: 0.2579 - f1: 0.0873 - val_loss: 2.6706 - val_accuracy: 0.2098 - val_f1: 0.0694\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4173 - accuracy: 0.2595 - f1: 0.0899 - val_loss: 2.6546 - val_accuracy: 0.2095 - val_f1: 0.0648\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4122 - accuracy: 0.2607 - f1: 0.0902 - val_loss: 2.6642 - val_accuracy: 0.2099 - val_f1: 0.0654\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4116 - accuracy: 0.2597 - f1: 0.0902 - val_loss: 2.6786 - val_accuracy: 0.2072 - val_f1: 0.0813\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4109 - accuracy: 0.2605 - f1: 0.0917 - val_loss: 2.6681 - val_accuracy: 0.2095 - val_f1: 0.0671\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4105 - accuracy: 0.2601 - f1: 0.0915 - val_loss: 2.6794 - val_accuracy: 0.2087 - val_f1: 0.0635\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4079 - accuracy: 0.2622 - f1: 0.0915 - val_loss: 2.6691 - val_accuracy: 0.2100 - val_f1: 0.0703\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4055 - accuracy: 0.2611 - f1: 0.0940 - val_loss: 2.6697 - val_accuracy: 0.2103 - val_f1: 0.0690\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4052 - accuracy: 0.2620 - f1: 0.0929 - val_loss: 2.6741 - val_accuracy: 0.2107 - val_f1: 0.0665\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.4013 - accuracy: 0.2631 - f1: 0.0941 - val_loss: 2.6791 - val_accuracy: 0.2134 - val_f1: 0.0718\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4000 - accuracy: 0.2629 - f1: 0.0945 - val_loss: 2.6827 - val_accuracy: 0.2095 - val_f1: 0.0716\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3986 - accuracy: 0.2617 - f1: 0.0952 - val_loss: 2.6815 - val_accuracy: 0.2087 - val_f1: 0.0713\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3955 - accuracy: 0.2638 - f1: 0.0967 - val_loss: 2.6823 - val_accuracy: 0.2105 - val_f1: 0.0768\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3939 - accuracy: 0.2637 - f1: 0.0965 - val_loss: 2.6860 - val_accuracy: 0.2080 - val_f1: 0.0709\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3934 - accuracy: 0.2654 - f1: 0.0976 - val_loss: 2.6887 - val_accuracy: 0.2116 - val_f1: 0.0698\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3911 - accuracy: 0.2651 - f1: 0.0986 - val_loss: 2.6909 - val_accuracy: 0.2086 - val_f1: 0.0751\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3901 - accuracy: 0.2674 - f1: 0.0993 - val_loss: 2.6853 - val_accuracy: 0.2090 - val_f1: 0.0680\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3893 - accuracy: 0.2664 - f1: 0.0984 - val_loss: 2.6826 - val_accuracy: 0.2106 - val_f1: 0.0682\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3867 - accuracy: 0.2665 - f1: 0.1006 - val_loss: 2.6954 - val_accuracy: 0.2116 - val_f1: 0.0727\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3855 - accuracy: 0.2674 - f1: 0.1010 - val_loss: 2.6964 - val_accuracy: 0.2102 - val_f1: 0.0716\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3845 - accuracy: 0.2670 - f1: 0.1012 - val_loss: 2.7029 - val_accuracy: 0.2068 - val_f1: 0.0688\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3826 - accuracy: 0.2681 - f1: 0.1021 - val_loss: 2.6910 - val_accuracy: 0.2104 - val_f1: 0.0693\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3798 - accuracy: 0.2687 - f1: 0.1031 - val_loss: 2.6994 - val_accuracy: 0.2084 - val_f1: 0.0684\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3793 - accuracy: 0.2680 - f1: 0.1027 - val_loss: 2.6980 - val_accuracy: 0.2080 - val_f1: 0.0778\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3787 - accuracy: 0.2685 - f1: 0.1030 - val_loss: 2.6994 - val_accuracy: 0.2071 - val_f1: 0.0698\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3767 - accuracy: 0.2692 - f1: 0.1052 - val_loss: 2.7036 - val_accuracy: 0.2070 - val_f1: 0.0744\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3765 - accuracy: 0.2709 - f1: 0.1049 - val_loss: 2.7069 - val_accuracy: 0.2051 - val_f1: 0.0808\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3739 - accuracy: 0.2713 - f1: 0.1045 - val_loss: 2.7134 - val_accuracy: 0.2032 - val_f1: 0.0722\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3718 - accuracy: 0.2694 - f1: 0.1074 - val_loss: 2.7079 - val_accuracy: 0.2073 - val_f1: 0.0719\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3724 - accuracy: 0.2697 - f1: 0.1056 - val_loss: 2.7125 - val_accuracy: 0.2066 - val_f1: 0.0718\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3721 - accuracy: 0.2720 - f1: 0.1058 - val_loss: 2.7094 - val_accuracy: 0.2082 - val_f1: 0.0726\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3694 - accuracy: 0.2711 - f1: 0.1064 - val_loss: 2.7303 - val_accuracy: 0.2051 - val_f1: 0.0822\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3680 - accuracy: 0.2709 - f1: 0.1079 - val_loss: 2.7129 - val_accuracy: 0.2083 - val_f1: 0.0824\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3668 - accuracy: 0.2718 - f1: 0.1080 - val_loss: 2.7192 - val_accuracy: 0.2076 - val_f1: 0.0833\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3648 - accuracy: 0.2735 - f1: 0.1093 - val_loss: 2.7302 - val_accuracy: 0.2038 - val_f1: 0.0770\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 2s 20us/step - loss: 2.3637 - accuracy: 0.2731 - f1: 0.1076 - val_loss: 2.7222 - val_accuracy: 0.2046 - val_f1: 0.0707\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m7= CreateMultiPerceptron(4,100,100,0.0005,7,\"../music/music/tagged_feature_sets/msd-jmirlpc_dev/msd-jmirlpc_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.9929 - accuracy: 0.1237 - f1: 0.0275 - val_loss: 2.9539 - val_accuracy: 0.1314 - val_f1: 0.0348\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.8805 - accuracy: 0.1529 - f1: 0.0435 - val_loss: 2.8354 - val_accuracy: 0.1594 - val_f1: 0.0299\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.8170 - accuracy: 0.1650 - f1: 0.0483 - val_loss: 2.8744 - val_accuracy: 0.1513 - val_f1: 0.0492\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7850 - accuracy: 0.1718 - f1: 0.0517 - val_loss: 2.7834 - val_accuracy: 0.1719 - val_f1: 0.0506\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7690 - accuracy: 0.1755 - f1: 0.0535 - val_loss: 2.7676 - val_accuracy: 0.1753 - val_f1: 0.0633\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7652 - accuracy: 0.1749 - f1: 0.0548 - val_loss: 2.8149 - val_accuracy: 0.1648 - val_f1: 0.0465\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7521 - accuracy: 0.1790 - f1: 0.0568 - val_loss: 2.7313 - val_accuracy: 0.1810 - val_f1: 0.0595\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7433 - accuracy: 0.1804 - f1: 0.0574 - val_loss: 2.7372 - val_accuracy: 0.1786 - val_f1: 0.0596\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7367 - accuracy: 0.1811 - f1: 0.0589 - val_loss: 2.7228 - val_accuracy: 0.1805 - val_f1: 0.0613\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7346 - accuracy: 0.1812 - f1: 0.0594 - val_loss: 2.7555 - val_accuracy: 0.1784 - val_f1: 0.0567\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7272 - accuracy: 0.1829 - f1: 0.0615 - val_loss: 2.7204 - val_accuracy: 0.1821 - val_f1: 0.0734\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7260 - accuracy: 0.1840 - f1: 0.0608 - val_loss: 2.7307 - val_accuracy: 0.1809 - val_f1: 0.0680\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7188 - accuracy: 0.1837 - f1: 0.0621 - val_loss: 2.7293 - val_accuracy: 0.1816 - val_f1: 0.0651\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7147 - accuracy: 0.1858 - f1: 0.0635 - val_loss: 2.7714 - val_accuracy: 0.1737 - val_f1: 0.0662\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7097 - accuracy: 0.1873 - f1: 0.0647 - val_loss: 2.7203 - val_accuracy: 0.1844 - val_f1: 0.0711\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7058 - accuracy: 0.1887 - f1: 0.0648 - val_loss: 2.7151 - val_accuracy: 0.1872 - val_f1: 0.0687\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.7044 - accuracy: 0.1893 - f1: 0.0656 - val_loss: 2.7076 - val_accuracy: 0.1858 - val_f1: 0.0566\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6995 - accuracy: 0.1893 - f1: 0.0650 - val_loss: 2.7015 - val_accuracy: 0.1858 - val_f1: 0.0532\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6988 - accuracy: 0.1902 - f1: 0.0667 - val_loss: 2.7278 - val_accuracy: 0.1816 - val_f1: 0.0669\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6938 - accuracy: 0.1919 - f1: 0.0675 - val_loss: 2.7180 - val_accuracy: 0.1820 - val_f1: 0.0617\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6907 - accuracy: 0.1915 - f1: 0.0677 - val_loss: 2.7110 - val_accuracy: 0.1840 - val_f1: 0.0747\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6889 - accuracy: 0.1923 - f1: 0.0683 - val_loss: 2.7086 - val_accuracy: 0.1870 - val_f1: 0.0689\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6874 - accuracy: 0.1912 - f1: 0.0686 - val_loss: 2.6914 - val_accuracy: 0.1902 - val_f1: 0.0693\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6785 - accuracy: 0.1947 - f1: 0.0700 - val_loss: 2.6930 - val_accuracy: 0.1905 - val_f1: 0.0601\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6799 - accuracy: 0.1941 - f1: 0.0690 - val_loss: 2.7059 - val_accuracy: 0.1859 - val_f1: 0.0658\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6784 - accuracy: 0.1946 - f1: 0.0693 - val_loss: 2.7337 - val_accuracy: 0.1780 - val_f1: 0.0641\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6718 - accuracy: 0.1951 - f1: 0.0705 - val_loss: 2.7086 - val_accuracy: 0.1877 - val_f1: 0.0616\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6705 - accuracy: 0.1976 - f1: 0.0710 - val_loss: 2.6851 - val_accuracy: 0.1918 - val_f1: 0.0745\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6691 - accuracy: 0.1971 - f1: 0.0714 - val_loss: 2.6825 - val_accuracy: 0.1928 - val_f1: 0.0733\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6672 - accuracy: 0.1974 - f1: 0.0707 - val_loss: 2.6871 - val_accuracy: 0.1921 - val_f1: 0.0652\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6637 - accuracy: 0.1988 - f1: 0.0715 - val_loss: 2.7205 - val_accuracy: 0.1859 - val_f1: 0.0811\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6640 - accuracy: 0.1987 - f1: 0.0724 - val_loss: 2.7542 - val_accuracy: 0.1744 - val_f1: 0.0697\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6582 - accuracy: 0.1999 - f1: 0.0731 - val_loss: 2.7504 - val_accuracy: 0.1788 - val_f1: 0.0598\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6587 - accuracy: 0.2005 - f1: 0.0736 - val_loss: 2.6898 - val_accuracy: 0.1933 - val_f1: 0.0666\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6563 - accuracy: 0.1999 - f1: 0.0725 - val_loss: 2.6875 - val_accuracy: 0.1916 - val_f1: 0.0710\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6554 - accuracy: 0.2001 - f1: 0.0738 - val_loss: 2.6997 - val_accuracy: 0.1900 - val_f1: 0.0694\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6496 - accuracy: 0.2017 - f1: 0.0749 - val_loss: 2.6818 - val_accuracy: 0.1904 - val_f1: 0.0694\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.6511 - accuracy: 0.2017 - f1: 0.0748 - val_loss: 2.6882 - val_accuracy: 0.1929 - val_f1: 0.0721\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6488 - accuracy: 0.2019 - f1: 0.0746 - val_loss: 2.6870 - val_accuracy: 0.1885 - val_f1: 0.0668\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6454 - accuracy: 0.2019 - f1: 0.0757 - val_loss: 2.6968 - val_accuracy: 0.1923 - val_f1: 0.0665\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6423 - accuracy: 0.2040 - f1: 0.0761 - val_loss: 2.7139 - val_accuracy: 0.1832 - val_f1: 0.0492\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6434 - accuracy: 0.2040 - f1: 0.0755 - val_loss: 2.7235 - val_accuracy: 0.1789 - val_f1: 0.0683\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6397 - accuracy: 0.2037 - f1: 0.0769 - val_loss: 2.6900 - val_accuracy: 0.1921 - val_f1: 0.0710\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6367 - accuracy: 0.2051 - f1: 0.0769 - val_loss: 2.6972 - val_accuracy: 0.1891 - val_f1: 0.0652\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6393 - accuracy: 0.2041 - f1: 0.0769 - val_loss: 2.7491 - val_accuracy: 0.1804 - val_f1: 0.0692\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6359 - accuracy: 0.2052 - f1: 0.0777 - val_loss: 2.7090 - val_accuracy: 0.1860 - val_f1: 0.0610\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6320 - accuracy: 0.2060 - f1: 0.0778 - val_loss: 2.7086 - val_accuracy: 0.1903 - val_f1: 0.0818\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6305 - accuracy: 0.2057 - f1: 0.0786 - val_loss: 2.7012 - val_accuracy: 0.1868 - val_f1: 0.0645\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6275 - accuracy: 0.2059 - f1: 0.0786 - val_loss: 2.7065 - val_accuracy: 0.1871 - val_f1: 0.0763\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6284 - accuracy: 0.2076 - f1: 0.0786 - val_loss: 2.6945 - val_accuracy: 0.1905 - val_f1: 0.0697\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6275 - accuracy: 0.2068 - f1: 0.0790 - val_loss: 2.6918 - val_accuracy: 0.1934 - val_f1: 0.0674\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6249 - accuracy: 0.2085 - f1: 0.0797 - val_loss: 2.7020 - val_accuracy: 0.1872 - val_f1: 0.0695\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6189 - accuracy: 0.2092 - f1: 0.0805 - val_loss: 2.7009 - val_accuracy: 0.1910 - val_f1: 0.0699\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6214 - accuracy: 0.2095 - f1: 0.0804 - val_loss: 2.6941 - val_accuracy: 0.1932 - val_f1: 0.0786\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6179 - accuracy: 0.2082 - f1: 0.0810 - val_loss: 2.6987 - val_accuracy: 0.1872 - val_f1: 0.0744\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6179 - accuracy: 0.2099 - f1: 0.0811 - val_loss: 2.7522 - val_accuracy: 0.1795 - val_f1: 0.0704\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6179 - accuracy: 0.2084 - f1: 0.0810 - val_loss: 2.6912 - val_accuracy: 0.1935 - val_f1: 0.0787\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6146 - accuracy: 0.2102 - f1: 0.0821 - val_loss: 2.6938 - val_accuracy: 0.1923 - val_f1: 0.0689\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6114 - accuracy: 0.2113 - f1: 0.0824 - val_loss: 2.7335 - val_accuracy: 0.1828 - val_f1: 0.0697\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6114 - accuracy: 0.2104 - f1: 0.0815 - val_loss: 2.7162 - val_accuracy: 0.1841 - val_f1: 0.0698\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6108 - accuracy: 0.2098 - f1: 0.0827 - val_loss: 2.7074 - val_accuracy: 0.1880 - val_f1: 0.0801\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6064 - accuracy: 0.2131 - f1: 0.0843 - val_loss: 2.6883 - val_accuracy: 0.1924 - val_f1: 0.0746\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6079 - accuracy: 0.2124 - f1: 0.0840 - val_loss: 2.6904 - val_accuracy: 0.1934 - val_f1: 0.0779\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6051 - accuracy: 0.2130 - f1: 0.0835 - val_loss: 2.6924 - val_accuracy: 0.1910 - val_f1: 0.0718\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6049 - accuracy: 0.2129 - f1: 0.0845 - val_loss: 2.6913 - val_accuracy: 0.1951 - val_f1: 0.0715\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6003 - accuracy: 0.2141 - f1: 0.0852 - val_loss: 2.6978 - val_accuracy: 0.1905 - val_f1: 0.0677\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.6012 - accuracy: 0.2131 - f1: 0.0846 - val_loss: 2.7215 - val_accuracy: 0.1850 - val_f1: 0.0749\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5996 - accuracy: 0.2127 - f1: 0.0859 - val_loss: 2.7156 - val_accuracy: 0.1892 - val_f1: 0.0797\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5987 - accuracy: 0.2131 - f1: 0.0867 - val_loss: 2.7023 - val_accuracy: 0.1897 - val_f1: 0.0668\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5929 - accuracy: 0.2146 - f1: 0.0858 - val_loss: 2.6918 - val_accuracy: 0.1930 - val_f1: 0.0771\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5919 - accuracy: 0.2166 - f1: 0.0869 - val_loss: 2.7186 - val_accuracy: 0.1845 - val_f1: 0.0647\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5944 - accuracy: 0.2137 - f1: 0.0867 - val_loss: 2.7024 - val_accuracy: 0.1892 - val_f1: 0.0681\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5948 - accuracy: 0.2139 - f1: 0.0871 - val_loss: 2.6921 - val_accuracy: 0.1934 - val_f1: 0.0751\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5905 - accuracy: 0.2158 - f1: 0.0869 - val_loss: 2.7069 - val_accuracy: 0.1917 - val_f1: 0.0831\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5920 - accuracy: 0.2150 - f1: 0.0873 - val_loss: 2.6998 - val_accuracy: 0.1895 - val_f1: 0.0707\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5873 - accuracy: 0.2159 - f1: 0.0891 - val_loss: 2.7096 - val_accuracy: 0.1895 - val_f1: 0.0691\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5832 - accuracy: 0.2184 - f1: 0.0892 - val_loss: 2.7026 - val_accuracy: 0.1925 - val_f1: 0.0674\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5875 - accuracy: 0.2156 - f1: 0.0888 - val_loss: 2.7029 - val_accuracy: 0.1920 - val_f1: 0.0729\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5821 - accuracy: 0.2171 - f1: 0.0896 - val_loss: 2.7158 - val_accuracy: 0.1868 - val_f1: 0.0678\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5834 - accuracy: 0.2163 - f1: 0.0893 - val_loss: 2.7064 - val_accuracy: 0.1941 - val_f1: 0.0797\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5809 - accuracy: 0.2166 - f1: 0.0901 - val_loss: 2.6938 - val_accuracy: 0.1933 - val_f1: 0.0753\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5807 - accuracy: 0.2196 - f1: 0.0911 - val_loss: 2.7076 - val_accuracy: 0.1913 - val_f1: 0.0750\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5768 - accuracy: 0.2201 - f1: 0.0917 - val_loss: 2.6969 - val_accuracy: 0.1943 - val_f1: 0.0756\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5763 - accuracy: 0.2192 - f1: 0.0902 - val_loss: 2.7141 - val_accuracy: 0.1898 - val_f1: 0.0655\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5744 - accuracy: 0.2199 - f1: 0.0911 - val_loss: 2.7050 - val_accuracy: 0.1896 - val_f1: 0.0690\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5750 - accuracy: 0.2201 - f1: 0.0908 - val_loss: 2.7135 - val_accuracy: 0.1915 - val_f1: 0.0774\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5743 - accuracy: 0.2195 - f1: 0.0911 - val_loss: 2.7018 - val_accuracy: 0.1905 - val_f1: 0.0635\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5717 - accuracy: 0.2208 - f1: 0.0917 - val_loss: 2.7331 - val_accuracy: 0.1858 - val_f1: 0.0770\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5686 - accuracy: 0.2215 - f1: 0.0935 - val_loss: 2.7186 - val_accuracy: 0.1909 - val_f1: 0.0692\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5688 - accuracy: 0.2216 - f1: 0.0929 - val_loss: 2.7024 - val_accuracy: 0.1925 - val_f1: 0.0766\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5652 - accuracy: 0.2217 - f1: 0.0940 - val_loss: 2.7094 - val_accuracy: 0.1880 - val_f1: 0.0718\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5672 - accuracy: 0.2215 - f1: 0.0930 - val_loss: 2.7460 - val_accuracy: 0.1848 - val_f1: 0.0779\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5654 - accuracy: 0.2223 - f1: 0.0936 - val_loss: 2.7282 - val_accuracy: 0.1866 - val_f1: 0.0751\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5643 - accuracy: 0.2222 - f1: 0.0938 - val_loss: 2.7331 - val_accuracy: 0.1846 - val_f1: 0.0738\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5649 - accuracy: 0.2215 - f1: 0.0949 - val_loss: 2.7146 - val_accuracy: 0.1913 - val_f1: 0.0776\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5643 - accuracy: 0.2225 - f1: 0.0949 - val_loss: 2.7406 - val_accuracy: 0.1840 - val_f1: 0.0672\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5614 - accuracy: 0.2226 - f1: 0.0951 - val_loss: 2.7062 - val_accuracy: 0.1944 - val_f1: 0.0787\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5601 - accuracy: 0.2237 - f1: 0.0957 - val_loss: 2.7842 - val_accuracy: 0.1809 - val_f1: 0.0748\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5579 - accuracy: 0.2235 - f1: 0.0961 - val_loss: 2.7592 - val_accuracy: 0.1790 - val_f1: 0.0706\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5567 - accuracy: 0.2233 - f1: 0.0963 - val_loss: 2.7387 - val_accuracy: 0.1874 - val_f1: 0.0833\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m8= CreateMultiPerceptron(4,100,100,0.0005,8,\"../music/music/tagged_feature_sets/msd-rh_dev_new/msd-rh_dev_new.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.8157 - accuracy: 0.1482 - f1: 0.0053 - val_loss: 2.7060 - val_accuracy: 0.1719 - val_f1: 6.1881e-04\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.6710 - accuracy: 0.1826 - f1: 0.0200 - val_loss: 2.6323 - val_accuracy: 0.1949 - val_f1: 0.0200\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.6214 - accuracy: 0.1940 - f1: 0.0294 - val_loss: 2.5913 - val_accuracy: 0.2012 - val_f1: 0.0454\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5985 - accuracy: 0.2015 - f1: 0.0333 - val_loss: 2.5826 - val_accuracy: 0.2022 - val_f1: 0.0392\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5833 - accuracy: 0.2055 - f1: 0.0371 - val_loss: 2.5513 - val_accuracy: 0.2106 - val_f1: 0.0498\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5630 - accuracy: 0.2111 - f1: 0.0395 - val_loss: 2.6176 - val_accuracy: 0.1925 - val_f1: 0.0561\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5582 - accuracy: 0.2126 - f1: 0.0413 - val_loss: 2.5421 - val_accuracy: 0.2123 - val_f1: 0.0497\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5469 - accuracy: 0.2161 - f1: 0.0439 - val_loss: 2.5581 - val_accuracy: 0.2088 - val_f1: 0.0317\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5379 - accuracy: 0.2190 - f1: 0.0452 - val_loss: 2.5291 - val_accuracy: 0.2218 - val_f1: 0.0437\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5245 - accuracy: 0.2227 - f1: 0.0473 - val_loss: 2.5427 - val_accuracy: 0.2153 - val_f1: 0.0460\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5195 - accuracy: 0.2238 - f1: 0.0501 - val_loss: 2.5304 - val_accuracy: 0.2216 - val_f1: 0.0430\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5096 - accuracy: 0.2268 - f1: 0.0520 - val_loss: 2.5015 - val_accuracy: 0.2235 - val_f1: 0.0514\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5017 - accuracy: 0.2289 - f1: 0.0546 - val_loss: 2.5024 - val_accuracy: 0.2279 - val_f1: 0.0632\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4970 - accuracy: 0.2306 - f1: 0.0554 - val_loss: 2.4861 - val_accuracy: 0.2309 - val_f1: 0.0600\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4902 - accuracy: 0.2315 - f1: 0.0592 - val_loss: 2.5706 - val_accuracy: 0.2078 - val_f1: 0.0413\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4859 - accuracy: 0.2332 - f1: 0.0598 - val_loss: 2.5071 - val_accuracy: 0.2256 - val_f1: 0.0661\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4821 - accuracy: 0.2343 - f1: 0.0628 - val_loss: 2.5413 - val_accuracy: 0.2212 - val_f1: 0.0378\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4783 - accuracy: 0.2355 - f1: 0.0628 - val_loss: 2.4905 - val_accuracy: 0.2286 - val_f1: 0.0448\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4711 - accuracy: 0.2384 - f1: 0.0639 - val_loss: 2.4800 - val_accuracy: 0.2341 - val_f1: 0.0642\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4685 - accuracy: 0.2383 - f1: 0.0653 - val_loss: 2.4958 - val_accuracy: 0.2300 - val_f1: 0.0678\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4628 - accuracy: 0.2390 - f1: 0.0676 - val_loss: 2.5929 - val_accuracy: 0.2062 - val_f1: 0.0803\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4549 - accuracy: 0.2423 - f1: 0.0699 - val_loss: 2.5369 - val_accuracy: 0.2238 - val_f1: 0.0767\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4564 - accuracy: 0.2423 - f1: 0.0702 - val_loss: 2.4862 - val_accuracy: 0.2368 - val_f1: 0.0853\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4501 - accuracy: 0.2440 - f1: 0.0724 - val_loss: 2.4679 - val_accuracy: 0.2359 - val_f1: 0.0713\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4448 - accuracy: 0.2457 - f1: 0.0732 - val_loss: 2.4809 - val_accuracy: 0.2358 - val_f1: 0.0598\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4447 - accuracy: 0.2462 - f1: 0.0742 - val_loss: 2.5024 - val_accuracy: 0.2295 - val_f1: 0.0787\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4383 - accuracy: 0.2460 - f1: 0.0768 - val_loss: 2.5041 - val_accuracy: 0.2322 - val_f1: 0.0819\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4384 - accuracy: 0.2465 - f1: 0.0762 - val_loss: 2.4724 - val_accuracy: 0.2365 - val_f1: 0.0880\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4360 - accuracy: 0.2468 - f1: 0.0786 - val_loss: 2.4843 - val_accuracy: 0.2307 - val_f1: 0.0719\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4276 - accuracy: 0.2503 - f1: 0.0781 - val_loss: 2.4554 - val_accuracy: 0.2437 - val_f1: 0.0721\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4276 - accuracy: 0.2504 - f1: 0.0798 - val_loss: 2.4698 - val_accuracy: 0.2402 - val_f1: 0.0798\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4260 - accuracy: 0.2491 - f1: 0.0818 - val_loss: 2.4716 - val_accuracy: 0.2363 - val_f1: 0.0915\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4197 - accuracy: 0.2533 - f1: 0.0833 - val_loss: 2.5085 - val_accuracy: 0.2268 - val_f1: 0.0602\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4169 - accuracy: 0.2530 - f1: 0.0826 - val_loss: 2.4730 - val_accuracy: 0.2365 - val_f1: 0.0819\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4157 - accuracy: 0.2521 - f1: 0.0835 - val_loss: 2.4771 - val_accuracy: 0.2391 - val_f1: 0.0792\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4135 - accuracy: 0.2546 - f1: 0.0852 - val_loss: 2.5096 - val_accuracy: 0.2310 - val_f1: 0.0792\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4090 - accuracy: 0.2546 - f1: 0.0866 - val_loss: 2.4772 - val_accuracy: 0.2348 - val_f1: 0.0825\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4104 - accuracy: 0.2554 - f1: 0.0872 - val_loss: 2.4821 - val_accuracy: 0.2350 - val_f1: 0.0809\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4068 - accuracy: 0.2553 - f1: 0.0874 - val_loss: 2.4554 - val_accuracy: 0.2430 - val_f1: 0.0931\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4010 - accuracy: 0.2580 - f1: 0.0893 - val_loss: 2.4685 - val_accuracy: 0.2386 - val_f1: 0.0763\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3997 - accuracy: 0.2572 - f1: 0.0904 - val_loss: 2.4587 - val_accuracy: 0.2423 - val_f1: 0.0845\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3974 - accuracy: 0.2577 - f1: 0.0900 - val_loss: 2.4563 - val_accuracy: 0.2472 - val_f1: 0.0885\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3913 - accuracy: 0.2597 - f1: 0.0927 - val_loss: 2.4593 - val_accuracy: 0.2458 - val_f1: 0.0937\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3908 - accuracy: 0.2601 - f1: 0.0929 - val_loss: 2.4535 - val_accuracy: 0.2478 - val_f1: 0.0881\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3942 - accuracy: 0.2592 - f1: 0.0925 - val_loss: 2.4703 - val_accuracy: 0.2414 - val_f1: 0.0765\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3878 - accuracy: 0.2607 - f1: 0.0945 - val_loss: 2.4714 - val_accuracy: 0.2433 - val_f1: 0.0978\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3848 - accuracy: 0.2611 - f1: 0.0961 - val_loss: 2.5413 - val_accuracy: 0.2289 - val_f1: 0.0983\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3817 - accuracy: 0.2618 - f1: 0.0975 - val_loss: 2.4890 - val_accuracy: 0.2417 - val_f1: 0.0763\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3811 - accuracy: 0.2629 - f1: 0.0975 - val_loss: 2.4792 - val_accuracy: 0.2395 - val_f1: 0.0955\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3801 - accuracy: 0.2640 - f1: 0.0979 - val_loss: 2.4615 - val_accuracy: 0.2431 - val_f1: 0.1032\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3788 - accuracy: 0.2641 - f1: 0.0986 - val_loss: 2.5038 - val_accuracy: 0.2336 - val_f1: 0.0970\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3754 - accuracy: 0.2640 - f1: 0.1008 - val_loss: 2.4763 - val_accuracy: 0.2416 - val_f1: 0.0870\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3750 - accuracy: 0.2636 - f1: 0.0989 - val_loss: 2.4831 - val_accuracy: 0.2377 - val_f1: 0.0892\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3749 - accuracy: 0.2643 - f1: 0.0991 - val_loss: 2.4800 - val_accuracy: 0.2420 - val_f1: 0.0915\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3718 - accuracy: 0.2657 - f1: 0.0998 - val_loss: 2.5100 - val_accuracy: 0.2360 - val_f1: 0.0887\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3650 - accuracy: 0.2679 - f1: 0.1021 - val_loss: 2.5192 - val_accuracy: 0.2318 - val_f1: 0.0994\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3687 - accuracy: 0.2660 - f1: 0.1024 - val_loss: 2.4689 - val_accuracy: 0.2435 - val_f1: 0.0917\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3689 - accuracy: 0.2660 - f1: 0.1022 - val_loss: 2.4671 - val_accuracy: 0.2460 - val_f1: 0.1050\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3619 - accuracy: 0.2685 - f1: 0.1038 - val_loss: 2.4979 - val_accuracy: 0.2406 - val_f1: 0.0897\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3595 - accuracy: 0.2676 - f1: 0.1066 - val_loss: 2.4726 - val_accuracy: 0.2456 - val_f1: 0.1056\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3554 - accuracy: 0.2700 - f1: 0.1077 - val_loss: 2.4739 - val_accuracy: 0.2447 - val_f1: 0.0839\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3579 - accuracy: 0.2683 - f1: 0.1073 - val_loss: 2.4985 - val_accuracy: 0.2380 - val_f1: 0.1088\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3558 - accuracy: 0.2698 - f1: 0.1070 - val_loss: 2.4644 - val_accuracy: 0.2456 - val_f1: 0.0776\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3541 - accuracy: 0.2707 - f1: 0.1073 - val_loss: 2.4662 - val_accuracy: 0.2468 - val_f1: 0.0823\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3532 - accuracy: 0.2694 - f1: 0.1084 - val_loss: 2.5093 - val_accuracy: 0.2344 - val_f1: 0.0656\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3507 - accuracy: 0.2715 - f1: 0.1081 - val_loss: 2.4801 - val_accuracy: 0.2470 - val_f1: 0.0902\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3454 - accuracy: 0.2714 - f1: 0.1105 - val_loss: 2.4699 - val_accuracy: 0.2449 - val_f1: 0.0864\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3433 - accuracy: 0.2732 - f1: 0.1110 - val_loss: 2.4677 - val_accuracy: 0.2460 - val_f1: 0.1108\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3479 - accuracy: 0.2718 - f1: 0.1095 - val_loss: 2.4787 - val_accuracy: 0.2436 - val_f1: 0.0762\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3435 - accuracy: 0.2727 - f1: 0.1123 - val_loss: 2.4893 - val_accuracy: 0.2412 - val_f1: 0.0705\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3418 - accuracy: 0.2730 - f1: 0.1128 - val_loss: 2.4903 - val_accuracy: 0.2431 - val_f1: 0.1037\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3404 - accuracy: 0.2724 - f1: 0.1119 - val_loss: 2.4808 - val_accuracy: 0.2412 - val_f1: 0.0962\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3374 - accuracy: 0.2744 - f1: 0.1137 - val_loss: 2.4995 - val_accuracy: 0.2385 - val_f1: 0.0798\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3391 - accuracy: 0.2738 - f1: 0.1131 - val_loss: 2.4998 - val_accuracy: 0.2378 - val_f1: 0.1058\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3357 - accuracy: 0.2762 - f1: 0.1140 - val_loss: 2.4743 - val_accuracy: 0.2460 - val_f1: 0.1016\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3353 - accuracy: 0.2736 - f1: 0.1139 - val_loss: 2.5124 - val_accuracy: 0.2330 - val_f1: 0.0699\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3325 - accuracy: 0.2749 - f1: 0.1165 - val_loss: 2.4812 - val_accuracy: 0.2460 - val_f1: 0.0986\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3326 - accuracy: 0.2743 - f1: 0.1168 - val_loss: 2.4777 - val_accuracy: 0.2478 - val_f1: 0.0877\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3309 - accuracy: 0.2756 - f1: 0.1157 - val_loss: 2.5010 - val_accuracy: 0.2377 - val_f1: 0.0968\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3281 - accuracy: 0.2770 - f1: 0.1174 - val_loss: 2.4677 - val_accuracy: 0.2479 - val_f1: 0.0880\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3268 - accuracy: 0.2769 - f1: 0.1183 - val_loss: 2.5039 - val_accuracy: 0.2430 - val_f1: 0.1089\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3254 - accuracy: 0.2771 - f1: 0.1183 - val_loss: 2.4854 - val_accuracy: 0.2424 - val_f1: 0.0875\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3256 - accuracy: 0.2778 - f1: 0.1192 - val_loss: 2.4799 - val_accuracy: 0.2463 - val_f1: 0.0974\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3205 - accuracy: 0.2783 - f1: 0.1202 - val_loss: 2.4794 - val_accuracy: 0.2418 - val_f1: 0.0842\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3204 - accuracy: 0.2788 - f1: 0.1194 - val_loss: 2.4787 - val_accuracy: 0.2439 - val_f1: 0.0957\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3194 - accuracy: 0.2780 - f1: 0.1213 - val_loss: 2.5286 - val_accuracy: 0.2355 - val_f1: 0.0740\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3182 - accuracy: 0.2796 - f1: 0.1216 - val_loss: 2.4828 - val_accuracy: 0.2460 - val_f1: 0.0919\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3185 - accuracy: 0.2801 - f1: 0.1200 - val_loss: 2.4837 - val_accuracy: 0.2441 - val_f1: 0.1002\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3150 - accuracy: 0.2797 - f1: 0.1220 - val_loss: 2.4786 - val_accuracy: 0.2441 - val_f1: 0.0855\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3150 - accuracy: 0.2821 - f1: 0.1220 - val_loss: 2.4827 - val_accuracy: 0.2452 - val_f1: 0.1067\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3145 - accuracy: 0.2809 - f1: 0.1222 - val_loss: 2.4858 - val_accuracy: 0.2485 - val_f1: 0.1044\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3107 - accuracy: 0.2810 - f1: 0.1236 - val_loss: 2.5285 - val_accuracy: 0.2372 - val_f1: 0.0934\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3118 - accuracy: 0.2807 - f1: 0.1240 - val_loss: 2.4825 - val_accuracy: 0.2461 - val_f1: 0.1130\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3134 - accuracy: 0.2808 - f1: 0.1234 - val_loss: 2.4894 - val_accuracy: 0.2432 - val_f1: 0.0948\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3131 - accuracy: 0.2806 - f1: 0.1233 - val_loss: 2.5182 - val_accuracy: 0.2368 - val_f1: 0.0897\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3088 - accuracy: 0.2831 - f1: 0.1270 - val_loss: 2.5135 - val_accuracy: 0.2392 - val_f1: 0.0989\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3073 - accuracy: 0.2836 - f1: 0.1267 - val_loss: 2.5300 - val_accuracy: 0.2373 - val_f1: 0.1211\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3097 - accuracy: 0.2812 - f1: 0.1242 - val_loss: 2.4938 - val_accuracy: 0.2460 - val_f1: 0.1151\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3051 - accuracy: 0.2841 - f1: 0.1269 - val_loss: 2.4822 - val_accuracy: 0.2474 - val_f1: 0.0928\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3022 - accuracy: 0.2848 - f1: 0.1282 - val_loss: 2.5116 - val_accuracy: 0.2440 - val_f1: 0.1056\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m9= CreateMultiPerceptron(4,100,100,0.0005,9,\"../music/music/tagged_feature_sets/msd-jmirderivatives_dev/msd-jmirderivatives_dev.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.6797 - accuracy: 0.1939 - f1: 0.0510 - val_loss: 2.6051 - val_accuracy: 0.2139 - val_f1: 0.0897\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5423 - accuracy: 0.2272 - f1: 0.0773 - val_loss: 2.5063 - val_accuracy: 0.2369 - val_f1: 0.1004\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4886 - accuracy: 0.2413 - f1: 0.0904 - val_loss: 2.4977 - val_accuracy: 0.2405 - val_f1: 0.0911\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4584 - accuracy: 0.2471 - f1: 0.0957 - val_loss: 2.4380 - val_accuracy: 0.2564 - val_f1: 0.1070\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4364 - accuracy: 0.2542 - f1: 0.1005 - val_loss: 2.4173 - val_accuracy: 0.2619 - val_f1: 0.0973\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4194 - accuracy: 0.2589 - f1: 0.1044 - val_loss: 2.4396 - val_accuracy: 0.2540 - val_f1: 0.0943\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4086 - accuracy: 0.2629 - f1: 0.1072 - val_loss: 2.4428 - val_accuracy: 0.2554 - val_f1: 0.1174\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3978 - accuracy: 0.2646 - f1: 0.1108 - val_loss: 2.4513 - val_accuracy: 0.2541 - val_f1: 0.0919\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3861 - accuracy: 0.2681 - f1: 0.1128 - val_loss: 2.3994 - val_accuracy: 0.2649 - val_f1: 0.1103\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3760 - accuracy: 0.2702 - f1: 0.1162 - val_loss: 2.3819 - val_accuracy: 0.2676 - val_f1: 0.1089\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3662 - accuracy: 0.2718 - f1: 0.1189 - val_loss: 2.3953 - val_accuracy: 0.2675 - val_f1: 0.1138\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3601 - accuracy: 0.2746 - f1: 0.1213 - val_loss: 2.4577 - val_accuracy: 0.2527 - val_f1: 0.1178\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3545 - accuracy: 0.2758 - f1: 0.1238 - val_loss: 2.3874 - val_accuracy: 0.2697 - val_f1: 0.1224\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3474 - accuracy: 0.2773 - f1: 0.1271 - val_loss: 2.3898 - val_accuracy: 0.2705 - val_f1: 0.1546\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3434 - accuracy: 0.2786 - f1: 0.1277 - val_loss: 2.3836 - val_accuracy: 0.2704 - val_f1: 0.1290\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3340 - accuracy: 0.2821 - f1: 0.1305 - val_loss: 2.3722 - val_accuracy: 0.2742 - val_f1: 0.1363\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3257 - accuracy: 0.2842 - f1: 0.1323 - val_loss: 2.3836 - val_accuracy: 0.2701 - val_f1: 0.1234\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3199 - accuracy: 0.2858 - f1: 0.1371 - val_loss: 2.4094 - val_accuracy: 0.2630 - val_f1: 0.1327\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3155 - accuracy: 0.2863 - f1: 0.1374 - val_loss: 2.3726 - val_accuracy: 0.2746 - val_f1: 0.1245\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3114 - accuracy: 0.2882 - f1: 0.1392 - val_loss: 2.3519 - val_accuracy: 0.2819 - val_f1: 0.1369\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3061 - accuracy: 0.2893 - f1: 0.1409 - val_loss: 2.3666 - val_accuracy: 0.2748 - val_f1: 0.1369\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3009 - accuracy: 0.2899 - f1: 0.1433 - val_loss: 2.3563 - val_accuracy: 0.2784 - val_f1: 0.1443\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2980 - accuracy: 0.2903 - f1: 0.1444 - val_loss: 2.3543 - val_accuracy: 0.2790 - val_f1: 0.1560\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2918 - accuracy: 0.2941 - f1: 0.1452 - val_loss: 2.3425 - val_accuracy: 0.2814 - val_f1: 0.1321\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2871 - accuracy: 0.2942 - f1: 0.1476 - val_loss: 2.3538 - val_accuracy: 0.2814 - val_f1: 0.1485\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2854 - accuracy: 0.2942 - f1: 0.1480 - val_loss: 2.3768 - val_accuracy: 0.2751 - val_f1: 0.1457\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2784 - accuracy: 0.2960 - f1: 0.1516 - val_loss: 2.3431 - val_accuracy: 0.2814 - val_f1: 0.1414\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2759 - accuracy: 0.2972 - f1: 0.1518 - val_loss: 2.3637 - val_accuracy: 0.2764 - val_f1: 0.1414\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2714 - accuracy: 0.2984 - f1: 0.1533 - val_loss: 2.3339 - val_accuracy: 0.2878 - val_f1: 0.1545\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2669 - accuracy: 0.2991 - f1: 0.1550 - val_loss: 2.3486 - val_accuracy: 0.2838 - val_f1: 0.1409\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2623 - accuracy: 0.3010 - f1: 0.1563 - val_loss: 2.3494 - val_accuracy: 0.2812 - val_f1: 0.1518\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2602 - accuracy: 0.3006 - f1: 0.1576 - val_loss: 2.3399 - val_accuracy: 0.2857 - val_f1: 0.1313\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2553 - accuracy: 0.3016 - f1: 0.1570 - val_loss: 2.3412 - val_accuracy: 0.2862 - val_f1: 0.1568\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2491 - accuracy: 0.3031 - f1: 0.1608 - val_loss: 2.3530 - val_accuracy: 0.2827 - val_f1: 0.1415\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2473 - accuracy: 0.3046 - f1: 0.1610 - val_loss: 2.3919 - val_accuracy: 0.2758 - val_f1: 0.1431\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2458 - accuracy: 0.3051 - f1: 0.1620 - val_loss: 2.3492 - val_accuracy: 0.2828 - val_f1: 0.1461\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2401 - accuracy: 0.3063 - f1: 0.1656 - val_loss: 2.3370 - val_accuracy: 0.2848 - val_f1: 0.1376\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2359 - accuracy: 0.3070 - f1: 0.1653 - val_loss: 2.3468 - val_accuracy: 0.2856 - val_f1: 0.1417\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2314 - accuracy: 0.3092 - f1: 0.1668 - val_loss: 2.3588 - val_accuracy: 0.2803 - val_f1: 0.1447\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2308 - accuracy: 0.3085 - f1: 0.1675 - val_loss: 2.3445 - val_accuracy: 0.2804 - val_f1: 0.1419\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2265 - accuracy: 0.3100 - f1: 0.1693 - val_loss: 2.3359 - val_accuracy: 0.2858 - val_f1: 0.1489\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2225 - accuracy: 0.3111 - f1: 0.1710 - val_loss: 2.3498 - val_accuracy: 0.2799 - val_f1: 0.1476\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2213 - accuracy: 0.3124 - f1: 0.1710 - val_loss: 2.3552 - val_accuracy: 0.2835 - val_f1: 0.1432\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2163 - accuracy: 0.3137 - f1: 0.1728 - val_loss: 2.3429 - val_accuracy: 0.2883 - val_f1: 0.1551\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2108 - accuracy: 0.3146 - f1: 0.1742 - val_loss: 2.3647 - val_accuracy: 0.2843 - val_f1: 0.1636\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2130 - accuracy: 0.3138 - f1: 0.1748 - val_loss: 2.3469 - val_accuracy: 0.2847 - val_f1: 0.1448\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2099 - accuracy: 0.3136 - f1: 0.1758 - val_loss: 2.3470 - val_accuracy: 0.2863 - val_f1: 0.1634\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2068 - accuracy: 0.3157 - f1: 0.1765 - val_loss: 2.3481 - val_accuracy: 0.2904 - val_f1: 0.1776\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.2039 - accuracy: 0.3166 - f1: 0.1782 - val_loss: 2.3732 - val_accuracy: 0.2797 - val_f1: 0.1592\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1993 - accuracy: 0.3168 - f1: 0.1785 - val_loss: 2.3595 - val_accuracy: 0.2829 - val_f1: 0.1597\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1971 - accuracy: 0.3186 - f1: 0.1802 - val_loss: 2.3410 - val_accuracy: 0.2858 - val_f1: 0.1650\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1925 - accuracy: 0.3203 - f1: 0.1812 - val_loss: 2.3474 - val_accuracy: 0.2880 - val_f1: 0.1700\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1929 - accuracy: 0.3200 - f1: 0.1824 - val_loss: 2.3465 - val_accuracy: 0.2865 - val_f1: 0.1587\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1895 - accuracy: 0.3203 - f1: 0.1842 - val_loss: 2.3830 - val_accuracy: 0.2822 - val_f1: 0.1588\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1888 - accuracy: 0.3216 - f1: 0.1822 - val_loss: 2.3983 - val_accuracy: 0.2765 - val_f1: 0.1715\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1833 - accuracy: 0.3221 - f1: 0.1865 - val_loss: 2.3689 - val_accuracy: 0.2854 - val_f1: 0.1626\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1820 - accuracy: 0.3217 - f1: 0.1861 - val_loss: 2.3794 - val_accuracy: 0.2809 - val_f1: 0.1713\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1772 - accuracy: 0.3228 - f1: 0.1866 - val_loss: 2.3592 - val_accuracy: 0.2818 - val_f1: 0.1546\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1776 - accuracy: 0.3240 - f1: 0.1868 - val_loss: 2.3588 - val_accuracy: 0.2884 - val_f1: 0.1765\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1725 - accuracy: 0.3250 - f1: 0.1899 - val_loss: 2.3734 - val_accuracy: 0.2839 - val_f1: 0.1512\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1707 - accuracy: 0.3249 - f1: 0.1902 - val_loss: 2.3612 - val_accuracy: 0.2866 - val_f1: 0.1606\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1705 - accuracy: 0.3251 - f1: 0.1907 - val_loss: 2.3668 - val_accuracy: 0.2836 - val_f1: 0.1693\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1654 - accuracy: 0.3270 - f1: 0.1922 - val_loss: 2.3763 - val_accuracy: 0.2861 - val_f1: 0.1747\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1671 - accuracy: 0.3255 - f1: 0.1930 - val_loss: 2.3571 - val_accuracy: 0.2905 - val_f1: 0.1698\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1663 - accuracy: 0.3257 - f1: 0.1915 - val_loss: 2.3606 - val_accuracy: 0.2874 - val_f1: 0.1775\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1607 - accuracy: 0.3261 - f1: 0.1949 - val_loss: 2.3715 - val_accuracy: 0.2858 - val_f1: 0.1687\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1626 - accuracy: 0.3276 - f1: 0.1947 - val_loss: 2.3821 - val_accuracy: 0.2832 - val_f1: 0.1760\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1561 - accuracy: 0.3283 - f1: 0.1973 - val_loss: 2.3711 - val_accuracy: 0.2833 - val_f1: 0.1617\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1568 - accuracy: 0.3295 - f1: 0.1979 - val_loss: 2.3651 - val_accuracy: 0.2830 - val_f1: 0.1577\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1553 - accuracy: 0.3293 - f1: 0.1976 - val_loss: 2.3631 - val_accuracy: 0.2885 - val_f1: 0.1676\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1515 - accuracy: 0.3310 - f1: 0.1982 - val_loss: 2.3803 - val_accuracy: 0.2849 - val_f1: 0.1731\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1501 - accuracy: 0.3305 - f1: 0.1991 - val_loss: 2.3728 - val_accuracy: 0.2838 - val_f1: 0.1606\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1481 - accuracy: 0.3330 - f1: 0.2000 - val_loss: 2.3919 - val_accuracy: 0.2803 - val_f1: 0.1593\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1487 - accuracy: 0.3314 - f1: 0.2002 - val_loss: 2.3778 - val_accuracy: 0.2830 - val_f1: 0.1634\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1429 - accuracy: 0.3329 - f1: 0.2028 - val_loss: 2.3735 - val_accuracy: 0.2881 - val_f1: 0.1694\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1434 - accuracy: 0.3319 - f1: 0.2010 - val_loss: 2.3985 - val_accuracy: 0.2771 - val_f1: 0.1634\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1432 - accuracy: 0.3324 - f1: 0.2028 - val_loss: 2.3647 - val_accuracy: 0.2865 - val_f1: 0.1685\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1407 - accuracy: 0.3327 - f1: 0.2036 - val_loss: 2.3774 - val_accuracy: 0.2802 - val_f1: 0.1616\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1370 - accuracy: 0.3334 - f1: 0.2047 - val_loss: 2.3691 - val_accuracy: 0.2886 - val_f1: 0.1658\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1384 - accuracy: 0.3344 - f1: 0.2048 - val_loss: 2.3782 - val_accuracy: 0.2849 - val_f1: 0.1731\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1360 - accuracy: 0.3340 - f1: 0.2056 - val_loss: 2.3826 - val_accuracy: 0.2809 - val_f1: 0.1632\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1372 - accuracy: 0.3344 - f1: 0.2056 - val_loss: 2.3824 - val_accuracy: 0.2845 - val_f1: 0.1661\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1324 - accuracy: 0.3350 - f1: 0.2063 - val_loss: 2.3908 - val_accuracy: 0.2829 - val_f1: 0.1720\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1275 - accuracy: 0.3352 - f1: 0.2077 - val_loss: 2.4144 - val_accuracy: 0.2834 - val_f1: 0.1919\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1275 - accuracy: 0.3370 - f1: 0.2103 - val_loss: 2.3966 - val_accuracy: 0.2810 - val_f1: 0.1629\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1251 - accuracy: 0.3372 - f1: 0.2101 - val_loss: 2.3841 - val_accuracy: 0.2856 - val_f1: 0.1773\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1259 - accuracy: 0.3363 - f1: 0.2098 - val_loss: 2.4034 - val_accuracy: 0.2800 - val_f1: 0.1604\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1235 - accuracy: 0.3376 - f1: 0.2111 - val_loss: 2.3872 - val_accuracy: 0.2866 - val_f1: 0.1848\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1218 - accuracy: 0.3381 - f1: 0.2117 - val_loss: 2.3895 - val_accuracy: 0.2848 - val_f1: 0.1777\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1201 - accuracy: 0.3394 - f1: 0.2120 - val_loss: 2.3949 - val_accuracy: 0.2813 - val_f1: 0.1677\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1215 - accuracy: 0.3385 - f1: 0.2108 - val_loss: 2.3922 - val_accuracy: 0.2826 - val_f1: 0.1709\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1197 - accuracy: 0.3397 - f1: 0.2119 - val_loss: 2.4049 - val_accuracy: 0.2845 - val_f1: 0.1869\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1160 - accuracy: 0.3394 - f1: 0.2141 - val_loss: 2.4064 - val_accuracy: 0.2849 - val_f1: 0.1779\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1117 - accuracy: 0.3415 - f1: 0.2159 - val_loss: 2.4021 - val_accuracy: 0.2833 - val_f1: 0.1796\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1124 - accuracy: 0.3419 - f1: 0.2159 - val_loss: 2.4006 - val_accuracy: 0.2856 - val_f1: 0.1782\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1114 - accuracy: 0.3417 - f1: 0.2157 - val_loss: 2.4193 - val_accuracy: 0.2798 - val_f1: 0.1735\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1132 - accuracy: 0.3399 - f1: 0.2164 - val_loss: 2.4106 - val_accuracy: 0.2841 - val_f1: 0.1757\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1108 - accuracy: 0.3407 - f1: 0.2170 - val_loss: 2.4088 - val_accuracy: 0.2861 - val_f1: 0.1788\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.1120 - accuracy: 0.3414 - f1: 0.2168 - val_loss: 2.3916 - val_accuracy: 0.2856 - val_f1: 0.1740\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.1084 - accuracy: 0.3425 - f1: 0.2176 - val_loss: 2.4112 - val_accuracy: 0.2792 - val_f1: 0.1658\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut donnés dans l'ennoncé\n",
    "m10= CreateMultiPerceptron(4,100,100,0.0005,10,\"../music/music/tagged_feature_sets/msd-marsyas_dev_new/msd-marsyas_dev_new.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSet(path):\n",
    "    #Extraire les données des ensembles \n",
    "    dataset = read_csv(path)\n",
    "   \n",
    "    labels = dataset.loc[:,dataset.columns == (dataset.shape[1]-1)]\n",
    "    labels = labels.to_numpy()\n",
    "    y = []\n",
    "    for e in labels:\n",
    "        y.append(music_class[e[0]])\n",
    "    \n",
    "    dataset = dataset.drop([0,1,(dataset.shape[1]-1)],axis=1)\n",
    "    \n",
    "    X = dataset.to_numpy()\n",
    "    print(X.shape)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X = X[0-100:]\n",
    "    y = y[0-100:]\n",
    "    \n",
    "    y_binary = []\n",
    "    for e in y:\n",
    "        y_binary.append(music_class_discrete_to_binary[e])\n",
    "    \n",
    "    y = np.array(y_binary)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179555, 10)\n",
      "(179555, 420)\n",
      "(179555, 168)\n",
      "(179555, 16)\n",
      "(179555, 26)\n",
      "(179555, 420)\n",
      "(179555, 20)\n",
      "(179555, 60)\n",
      "(179555, 96)\n",
      "(179555, 124)\n"
     ]
    }
   ],
   "source": [
    "# Pour tous les jeux de données, prendre les 100 dernières entrées\n",
    "X1, y1 = DataSet(\"../music/music/tagged_feature_sets/msd-jmirmoments_dev/msd-jmirmoments_dev.csv\")\n",
    "X2, y2 = DataSet(\"../music/music/tagged_feature_sets/msd-mvd_dev/msd-mvd_dev.csv\")\n",
    "X3, y3 = DataSet(\"../music/music/tagged_feature_sets/msd-ssd_dev/msd-ssd_dev.csv\")\n",
    "X4, y4 = DataSet(\"../music/music/tagged_feature_sets/msd-jmirspectral_dev/msd-jmirspectral_dev.csv\")\n",
    "X5, y5 = DataSet(\"../music/music/tagged_feature_sets/msd-jmirmfccs_dev/msd-jmirmfccs_dev.csv\")\n",
    "X6, y6 = DataSet(\"../music/music/tagged_feature_sets/msd-trh_dev/msd-trh_dev.csv\")\n",
    "X7, y7 = DataSet(\"../music/music/tagged_feature_sets/msd-jmirlpc_dev/msd-jmirlpc_dev.csv\")\n",
    "X8, y8 = DataSet(\"../music/music/tagged_feature_sets/msd-rh_dev_new/msd-rh_dev_new.csv\")\n",
    "X9, y9 = DataSet(\"../music/music/tagged_feature_sets/msd-jmirderivatives_dev/msd-jmirderivatives_dev.csv\")\n",
    "X10, y10 = DataSet(\"../music/music/tagged_feature_sets/msd-marsyas_dev_new/msd-marsyas_dev_new.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor Tensor(\"dense_5/Softmax:0\", shape=(?, 25), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3152f14cf7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         return training_arrays.predict_loop(self, f, ins,\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m                                                \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                                                \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                                                **kwargs)\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   3007\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[1;32m   3008\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3009\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   3199\u001b[0m                'backend') % key\n\u001b[1;32m   3200\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3201\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mGraphExecutionFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m       \u001b[0mupdates_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   5026\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5027\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5028\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(self, control_inputs)\u001b[0m\n\u001b[1;32m   4526\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4528\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4529\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4530\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3555\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"dense_5/Softmax:0\", shape=(?, 25), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "# Sur ces mêmes 100 données, obtenir les prédictions des 10 différents modèles\n",
    "print(X1.shape)\n",
    "res  =[]\n",
    "res.append(tf.keras.backend.argmax(m1.predict(X1), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m2.predict(X2), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m3.predict(X3), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m4.predict(X4), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m5.predict(X5), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m6.predict(X6), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m7.predict(X7), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m8.predict(X8), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m9.predict(X9), axis=1))\n",
    "res.append(tf.keras.backend.argmax(m10.predict(X10), axis=1))\n",
    "\n",
    "for i in res:\n",
    "    print(i)\n",
    "    \n",
    "print(y)\n",
    "\n",
    "for elem in range(0,100):\n",
    "    predict = []\n",
    "    for e in range(0,10):\n",
    "        predic.append(res[e][elem])\n",
    "    print(elem + \":\")\n",
    "    print(statistics.median(predic))\n",
    "    print(\"y : \")\n",
    "    print(y1[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
