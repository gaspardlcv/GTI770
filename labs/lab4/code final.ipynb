{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import statistics\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "import tensorboard\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(url):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        url (string): the url of the file\n",
    "    Returns:\n",
    "        df: the dataframe filled\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "def KnnAddedFeatures(X,Y):\n",
    "    \"\"\"\n",
    "    Args :\n",
    "        X, features, Y labels \n",
    "    Returns :\n",
    "        tuples corresponding to new features\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    knn = RadiusNeighborsClassifier(radius=0.5, weights = 'distance')\n",
    "    knn.fit(X,Y)\n",
    "    a = knn.predict(X)\n",
    "    print(\"coucou\",a)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def NaiveAddedFeatures(X,y):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(abs(X), y)\n",
    "    res = clf.predict_proba(X)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_class_binary = {'BIG_BAND':[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'BLUES_CONTEMPORARY':  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'COUNTRY_TRADITIONAL': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'DANCE':               [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'ELECTRONICA':         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'EXPERIMENTAL':        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'FOLK_INTERNATIONAL':  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'GOSPEL':              [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'GRUNGE_EMO':          [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'HIP_HOP_RAP':         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'JAZZ_CLASSIC':        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'METAL_ALTERNATIVE':   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'METAL_DEATH':         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'METAL_HEAVY':         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'POP_CONTEMPORARY':    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'POP_INDIE':           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'POP_LATIN':           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'PUNK':                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "          'REGGAE':              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "          'RNB_SOUL':            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "          'ROCK_ALTERNATIVE':    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "          'ROCK_COLLEGE':        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "          'ROCK_CONTEMPORARY':   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "          'ROCK_HARD':           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "          'ROCK_NEO_PSYCHEDELIA':[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_class_discrete_to_binary = {1:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  2:[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  3:[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  4:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  5:[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  6:[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  7:[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  8:[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                  9:[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 10:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 11:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 12:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 13:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 14:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 15:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 16:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 17:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 18:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                 19:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                                 20:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                                 21:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                                 22:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                                 23:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                                 24:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                                 25:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_class = {'BIG_BAND':1,\n",
    "          'BLUES_CONTEMPORARY':2,\n",
    "          'COUNTRY_TRADITIONAL':3,\n",
    "          'DANCE':4,\n",
    "          'ELECTRONICA':5,\n",
    "          'EXPERIMENTAL':6,\n",
    "          'FOLK_INTERNATIONAL':7,\n",
    "          'GOSPEL':8,\n",
    "          'GRUNGE_EMO':9,\n",
    "          'HIP_HOP_RAP':10,\n",
    "          'JAZZ_CLASSIC':11,\n",
    "          'METAL_ALTERNATIVE':12,\n",
    "          'METAL_DEATH':13,\n",
    "          'METAL_HEAVY':14,\n",
    "          'POP_CONTEMPORARY':15,\n",
    "          'POP_INDIE':16,\n",
    "          'POP_LATIN':17,\n",
    "          'PUNK':18,\n",
    "          'REGGAE':19,\n",
    "          'RNB_SOUL':20,\n",
    "          'ROCK_ALTERNATIVE':21,\n",
    "          'ROCK_COLLEGE':22,\n",
    "          'ROCK_CONTEMPORARY':23,\n",
    "          'ROCK_HARD':24,\n",
    "          'ROCK_NEO_PSYCHEDELIA':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_class_number_to_text = {1:'BIG_BAND',\n",
    "          2:'BLUES_CONTEMPORARY',\n",
    "          3:'COUNTRY_TRADITIONAL',\n",
    "          4:'DANCE',\n",
    "          5:'ELECTRONICA',\n",
    "          6:'EXPERIMENTAL',\n",
    "          7:'FOLK_INTERNATIONAL',\n",
    "          8:'GOSPEL',\n",
    "          9:'GRUNGE_EMO',\n",
    "          10:'HIP_HOP_RAP',\n",
    "          11:'JAZZ_CLASSIC',\n",
    "          12:'METAL_ALTERNATIVE',\n",
    "          13:'METAL_DEATH',\n",
    "          14:'METAL_HEAVY',\n",
    "          15:'POP_CONTEMPORARY',\n",
    "          16:'POP_INDIE',\n",
    "          17:'POP_LATIN',\n",
    "          18:'PUNK',\n",
    "          19:'REGGAE',\n",
    "          20:'RNB_SOUL',\n",
    "          21:'ROCK_ALTERNATIVE',\n",
    "          22:'ROCK_COLLEGE',\n",
    "          23:'ROCK_CONTEMPORARY',\n",
    "          24:'ROCK_HARD',\n",
    "          25:'ROCK_NEO_PSYCHEDELIA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom metrics function to calculate the F1 score\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMultiPerceptron(nb_layers,nb_perceptron,nb_iteration,learning_rate,nb_essai,path):\n",
    "    \n",
    "    \n",
    "    #Extraire les données des ensembles \n",
    "    dataset = read_csv(path)\n",
    "    dataset.head()\n",
    "    #print(dataset.shape[1])\n",
    "    labels = dataset.loc[:,dataset.columns == (dataset.shape[1]-1)]\n",
    "    labels = labels.to_numpy()\n",
    "    y = []\n",
    "    y_u = []\n",
    "    for e in labels:\n",
    "        y.append(music_class[e[0]])\n",
    "    \n",
    "    dataset = dataset.drop([0,1,(dataset.shape[1]-1)],axis=1)\n",
    "    \n",
    "    X = dataset.to_numpy()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    #Create a Multinomial Classifier\n",
    "    #mlt = MultinomialNB()\n",
    "    \n",
    "    #Train the classifier over all the samples\n",
    "    #mlt.fit(abs(X),y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "    #Predict probabilities which will become new features over each data set\n",
    "    #nf_train = mlt.predict_proba(X_train)\n",
    "    #nf_test = mlt.predict_proba(X_test)\n",
    "    \n",
    "    # scale the data : réduire le execution time\n",
    "    scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    X_train = scaling.transform(X_train)\n",
    "    X_test = scaling.transform(X_test)\n",
    "    \n",
    "    #Add of new features \n",
    "    #X_train = np.concatenate((X_train,nf_train),axis=1)\n",
    "    #X_test = np.concatenate((X_test,nf_test),axis=1)\n",
    "    \n",
    "    y_train_binary = []\n",
    "    for e in y_train:\n",
    "        y_train_binary.append(music_class_discrete_to_binary[e])\n",
    "    \n",
    "    y_train_binary = np.array(y_train_binary)\n",
    "    \n",
    "\n",
    "        \n",
    "    y_test_binary = []\n",
    "    for e in y_test:\n",
    "        y_test_binary.append(music_class_discrete_to_binary[e])\n",
    "        \n",
    "    y_test_binary = np.array(y_test_binary)\n",
    "    y_test = y_test_binary\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_binary, test_size=0.20)\n",
    "    #X_val = scaling.transform(X_val)\n",
    "    \n",
    "    \n",
    "    #Create the model \n",
    "    model = Sequential()\n",
    "    #First hidden layer with specified number of percpetrons \n",
    "    model.add(Dense(units=nb_perceptron, activation='relu', input_dim = X_train.shape[1]))\n",
    "    \n",
    "    for i in range(nb_layers-1):\n",
    "        #Next hidden layers with specified number of percpetrons \n",
    "        model.add(Dense(units=nb_perceptron, activation='relu'))\n",
    "    \n",
    "    #Last layer, the activation layer with 25 outputs\n",
    "    model.add(Dense(units = 25, activation='softmax'))\n",
    "    \n",
    "    #Compile the model\n",
    "    sgd = SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy',f1])\n",
    "    \n",
    "    #3. Entraîner \n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              epochs=nb_iteration, batch_size=100)\n",
    "  \n",
    "    \"\"\"\n",
    "    # Plot training & validation accuracy values\n",
    "    accuracy = pd.DataFrame(history.history['accuracy'])\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"Accuracy\")\n",
    "    print(accuracy.head(nb_iteration))\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    f1score = pd.DataFrame(history.history['f1'])\n",
    "    plt.plot(history.history['f1'])\n",
    "    plt.plot(history.history['val_f1'])\n",
    "    plt.title('Model F1 score')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"F1 score\")\n",
    "    print(f1score.head(nb_iteration))\n",
    "    \n",
    "    \n",
    "    #4 Evaluer le modèle\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print(\"---TEST---\")\n",
    "    print(score)\n",
    "    \"\"\"\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/adrien/anaconda3/envs/GPI770/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.8615 - accuracy: 0.1431 - f1: 2.9256e-04 - val_loss: 2.8125 - val_accuracy: 0.1525 - val_f1: 0.0013\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 4s 37us/step - loss: 2.7792 - accuracy: 0.1638 - f1: 0.0014 - val_loss: 2.7779 - val_accuracy: 0.1667 - val_f1: 0.0166\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.7466 - accuracy: 0.1731 - f1: 0.0041 - val_loss: 2.7350 - val_accuracy: 0.1733 - val_f1: 0.0247\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.7229 - accuracy: 0.1796 - f1: 0.0097 - val_loss: 2.7106 - val_accuracy: 0.1848 - val_f1: 0.0138\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.7072 - accuracy: 0.1838 - f1: 0.0147 - val_loss: 2.7313 - val_accuracy: 0.1783 - val_f1: 0.0336\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6960 - accuracy: 0.1862 - f1: 0.0158 - val_loss: 2.7031 - val_accuracy: 0.1839 - val_f1: 0.0230\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6872 - accuracy: 0.1888 - f1: 0.0184 - val_loss: 2.7027 - val_accuracy: 0.1800 - val_f1: 0.0248\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6794 - accuracy: 0.1903 - f1: 0.0205 - val_loss: 2.6864 - val_accuracy: 0.1895 - val_f1: 0.0191\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6738 - accuracy: 0.1924 - f1: 0.0212 - val_loss: 2.6925 - val_accuracy: 0.1845 - val_f1: 0.0167\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6683 - accuracy: 0.1937 - f1: 0.0233 - val_loss: 2.6760 - val_accuracy: 0.1899 - val_f1: 0.0298\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6630 - accuracy: 0.1942 - f1: 0.0225 - val_loss: 2.6670 - val_accuracy: 0.1922 - val_f1: 0.0238\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6584 - accuracy: 0.1953 - f1: 0.0252 - val_loss: 2.6569 - val_accuracy: 0.1960 - val_f1: 0.0246\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6526 - accuracy: 0.1961 - f1: 0.0253 - val_loss: 2.6624 - val_accuracy: 0.1936 - val_f1: 0.0249\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6484 - accuracy: 0.1969 - f1: 0.0263 - val_loss: 2.6700 - val_accuracy: 0.1931 - val_f1: 0.0290\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.6445 - accuracy: 0.1985 - f1: 0.0274 - val_loss: 2.6519 - val_accuracy: 0.1981 - val_f1: 0.0411\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6415 - accuracy: 0.1995 - f1: 0.0283 - val_loss: 2.6523 - val_accuracy: 0.1982 - val_f1: 0.0279\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6364 - accuracy: 0.2012 - f1: 0.0273 - val_loss: 2.6462 - val_accuracy: 0.1988 - val_f1: 0.0296\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6343 - accuracy: 0.2003 - f1: 0.0292 - val_loss: 2.6496 - val_accuracy: 0.1971 - val_f1: 0.0328\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6318 - accuracy: 0.2016 - f1: 0.0308 - val_loss: 2.6455 - val_accuracy: 0.1992 - val_f1: 0.0145\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6278 - accuracy: 0.2020 - f1: 0.0300 - val_loss: 2.6520 - val_accuracy: 0.1976 - val_f1: 0.0334\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6233 - accuracy: 0.2042 - f1: 0.0318 - val_loss: 2.6453 - val_accuracy: 0.1967 - val_f1: 0.0259\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6207 - accuracy: 0.2054 - f1: 0.0328 - val_loss: 2.6361 - val_accuracy: 0.2020 - val_f1: 0.0331\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6183 - accuracy: 0.2050 - f1: 0.0317 - val_loss: 2.6438 - val_accuracy: 0.2019 - val_f1: 0.0347\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6149 - accuracy: 0.2058 - f1: 0.0338 - val_loss: 2.6422 - val_accuracy: 0.2004 - val_f1: 0.0281\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6119 - accuracy: 0.2069 - f1: 0.0335 - val_loss: 2.6626 - val_accuracy: 0.1948 - val_f1: 0.0244\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6124 - accuracy: 0.2081 - f1: 0.0345 - val_loss: 2.6488 - val_accuracy: 0.1959 - val_f1: 0.0236\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6080 - accuracy: 0.2076 - f1: 0.0348 - val_loss: 2.6781 - val_accuracy: 0.1912 - val_f1: 0.0358\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6047 - accuracy: 0.2075 - f1: 0.0357 - val_loss: 2.6346 - val_accuracy: 0.2009 - val_f1: 0.0297\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.6034 - accuracy: 0.2083 - f1: 0.0365 - val_loss: 2.6325 - val_accuracy: 0.2017 - val_f1: 0.0256\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.6001 - accuracy: 0.2096 - f1: 0.0366 - val_loss: 2.6486 - val_accuracy: 0.1976 - val_f1: 0.0376\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5971 - accuracy: 0.2101 - f1: 0.0365 - val_loss: 2.6368 - val_accuracy: 0.2007 - val_f1: 0.0307\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5979 - accuracy: 0.2094 - f1: 0.0375 - val_loss: 2.6477 - val_accuracy: 0.2003 - val_f1: 0.0294\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5939 - accuracy: 0.2117 - f1: 0.0377 - val_loss: 2.6381 - val_accuracy: 0.2020 - val_f1: 0.0341\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5911 - accuracy: 0.2121 - f1: 0.0377 - val_loss: 2.6343 - val_accuracy: 0.2023 - val_f1: 0.0401\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5893 - accuracy: 0.2123 - f1: 0.0385 - val_loss: 2.6544 - val_accuracy: 0.1967 - val_f1: 0.0318\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5861 - accuracy: 0.2142 - f1: 0.0395 - val_loss: 2.6310 - val_accuracy: 0.2022 - val_f1: 0.0345\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5833 - accuracy: 0.2145 - f1: 0.0394 - val_loss: 2.6533 - val_accuracy: 0.1995 - val_f1: 0.0443\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5828 - accuracy: 0.2151 - f1: 0.0411 - val_loss: 2.6362 - val_accuracy: 0.2031 - val_f1: 0.0324\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5794 - accuracy: 0.2144 - f1: 0.0409 - val_loss: 2.6412 - val_accuracy: 0.2024 - val_f1: 0.0383\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5782 - accuracy: 0.2149 - f1: 0.0421 - val_loss: 2.6460 - val_accuracy: 0.2001 - val_f1: 0.0334\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5747 - accuracy: 0.2159 - f1: 0.0429 - val_loss: 2.6586 - val_accuracy: 0.1973 - val_f1: 0.0502\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5737 - accuracy: 0.2164 - f1: 0.0430 - val_loss: 2.6328 - val_accuracy: 0.2041 - val_f1: 0.0424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5712 - accuracy: 0.2169 - f1: 0.0435 - val_loss: 2.6406 - val_accuracy: 0.2021 - val_f1: 0.0410\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5690 - accuracy: 0.2173 - f1: 0.0439 - val_loss: 2.6405 - val_accuracy: 0.2011 - val_f1: 0.0366\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5682 - accuracy: 0.2198 - f1: 0.0444 - val_loss: 2.6515 - val_accuracy: 0.2022 - val_f1: 0.0384\n",
      "Epoch 46/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5649 - accuracy: 0.2198 - f1: 0.0467 - val_loss: 2.6375 - val_accuracy: 0.2038 - val_f1: 0.0376\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5644 - accuracy: 0.2190 - f1: 0.0456 - val_loss: 2.6451 - val_accuracy: 0.2030 - val_f1: 0.0494\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5621 - accuracy: 0.2202 - f1: 0.0463 - val_loss: 2.6395 - val_accuracy: 0.2051 - val_f1: 0.0368\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5591 - accuracy: 0.2202 - f1: 0.0469 - val_loss: 2.6554 - val_accuracy: 0.2017 - val_f1: 0.0527\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5598 - accuracy: 0.2215 - f1: 0.0472 - val_loss: 2.6479 - val_accuracy: 0.2050 - val_f1: 0.0489\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5567 - accuracy: 0.2217 - f1: 0.0482 - val_loss: 2.6448 - val_accuracy: 0.2017 - val_f1: 0.0332\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5559 - accuracy: 0.2210 - f1: 0.0479 - val_loss: 2.6431 - val_accuracy: 0.2045 - val_f1: 0.0312\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5531 - accuracy: 0.2214 - f1: 0.0489 - val_loss: 2.6454 - val_accuracy: 0.2041 - val_f1: 0.0366\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5513 - accuracy: 0.2218 - f1: 0.0499 - val_loss: 2.6367 - val_accuracy: 0.2048 - val_f1: 0.0359\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5503 - accuracy: 0.2229 - f1: 0.0487 - val_loss: 2.6600 - val_accuracy: 0.1992 - val_f1: 0.0577\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5484 - accuracy: 0.2239 - f1: 0.0510 - val_loss: 2.6508 - val_accuracy: 0.1999 - val_f1: 0.0448\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5469 - accuracy: 0.2236 - f1: 0.0508 - val_loss: 2.6538 - val_accuracy: 0.2048 - val_f1: 0.0442\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5446 - accuracy: 0.2243 - f1: 0.0516 - val_loss: 2.6551 - val_accuracy: 0.2046 - val_f1: 0.0418\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5432 - accuracy: 0.2241 - f1: 0.0517 - val_loss: 2.6515 - val_accuracy: 0.2056 - val_f1: 0.0594\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5412 - accuracy: 0.2235 - f1: 0.0527 - val_loss: 2.6563 - val_accuracy: 0.2002 - val_f1: 0.0552\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5424 - accuracy: 0.2254 - f1: 0.0527 - val_loss: 2.6486 - val_accuracy: 0.2067 - val_f1: 0.0389\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5403 - accuracy: 0.2252 - f1: 0.0541 - val_loss: 2.6440 - val_accuracy: 0.2062 - val_f1: 0.0499\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5364 - accuracy: 0.2265 - f1: 0.0539 - val_loss: 2.6471 - val_accuracy: 0.2037 - val_f1: 0.0462\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5375 - accuracy: 0.2272 - f1: 0.0538 - val_loss: 2.6514 - val_accuracy: 0.2045 - val_f1: 0.0417\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5353 - accuracy: 0.2269 - f1: 0.0541 - val_loss: 2.6586 - val_accuracy: 0.1998 - val_f1: 0.0368\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5348 - accuracy: 0.2263 - f1: 0.0552 - val_loss: 2.6529 - val_accuracy: 0.2037 - val_f1: 0.0582\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5331 - accuracy: 0.2272 - f1: 0.0551 - val_loss: 2.6489 - val_accuracy: 0.2061 - val_f1: 0.0466\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5305 - accuracy: 0.2277 - f1: 0.0567 - val_loss: 2.6523 - val_accuracy: 0.1984 - val_f1: 0.0408\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5279 - accuracy: 0.2292 - f1: 0.0565 - val_loss: 2.6556 - val_accuracy: 0.2061 - val_f1: 0.0455\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5281 - accuracy: 0.2288 - f1: 0.0571 - val_loss: 2.6508 - val_accuracy: 0.2061 - val_f1: 0.0499\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5268 - accuracy: 0.2292 - f1: 0.0562 - val_loss: 2.6483 - val_accuracy: 0.2031 - val_f1: 0.0469\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5247 - accuracy: 0.2297 - f1: 0.0585 - val_loss: 2.6564 - val_accuracy: 0.2006 - val_f1: 0.0384\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5242 - accuracy: 0.2285 - f1: 0.0591 - val_loss: 2.6546 - val_accuracy: 0.2039 - val_f1: 0.0498\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5230 - accuracy: 0.2294 - f1: 0.0589 - val_loss: 2.6694 - val_accuracy: 0.1988 - val_f1: 0.0373\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5212 - accuracy: 0.2302 - f1: 0.0591 - val_loss: 2.6712 - val_accuracy: 0.1988 - val_f1: 0.0556\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5210 - accuracy: 0.2302 - f1: 0.0589 - val_loss: 2.6596 - val_accuracy: 0.2055 - val_f1: 0.0526\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5200 - accuracy: 0.2302 - f1: 0.0605 - val_loss: 2.6594 - val_accuracy: 0.2040 - val_f1: 0.0496\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5189 - accuracy: 0.2311 - f1: 0.0599 - val_loss: 2.6673 - val_accuracy: 0.2032 - val_f1: 0.0562\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5162 - accuracy: 0.2312 - f1: 0.0610 - val_loss: 2.6636 - val_accuracy: 0.2022 - val_f1: 0.0531\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5155 - accuracy: 0.2328 - f1: 0.0610 - val_loss: 2.6674 - val_accuracy: 0.2035 - val_f1: 0.0527\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5149 - accuracy: 0.2331 - f1: 0.0613 - val_loss: 2.6584 - val_accuracy: 0.2049 - val_f1: 0.0472\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5133 - accuracy: 0.2317 - f1: 0.0619 - val_loss: 2.6630 - val_accuracy: 0.2032 - val_f1: 0.0490\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5119 - accuracy: 0.2326 - f1: 0.0626 - val_loss: 2.6695 - val_accuracy: 0.2034 - val_f1: 0.0384\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5097 - accuracy: 0.2329 - f1: 0.0630 - val_loss: 2.6775 - val_accuracy: 0.1993 - val_f1: 0.0397\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5109 - accuracy: 0.2322 - f1: 0.0624 - val_loss: 2.6591 - val_accuracy: 0.2046 - val_f1: 0.0535\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5097 - accuracy: 0.2338 - f1: 0.0630 - val_loss: 2.6805 - val_accuracy: 0.2024 - val_f1: 0.0573\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.5069 - accuracy: 0.2347 - f1: 0.0640 - val_loss: 2.6707 - val_accuracy: 0.2025 - val_f1: 0.0407\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5079 - accuracy: 0.2331 - f1: 0.0636 - val_loss: 2.6766 - val_accuracy: 0.2019 - val_f1: 0.0420\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5061 - accuracy: 0.2344 - f1: 0.0643 - val_loss: 2.6739 - val_accuracy: 0.2019 - val_f1: 0.0545\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 5s 42us/step - loss: 2.5049 - accuracy: 0.2338 - f1: 0.0649 - val_loss: 2.6681 - val_accuracy: 0.2046 - val_f1: 0.0532\n",
      "Epoch 91/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5029 - accuracy: 0.2353 - f1: 0.0647 - val_loss: 2.6866 - val_accuracy: 0.1991 - val_f1: 0.0500\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5041 - accuracy: 0.2351 - f1: 0.0645 - val_loss: 2.6729 - val_accuracy: 0.2008 - val_f1: 0.0520\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5024 - accuracy: 0.2346 - f1: 0.0648 - val_loss: 2.6769 - val_accuracy: 0.1987 - val_f1: 0.0456\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5017 - accuracy: 0.2360 - f1: 0.0659 - val_loss: 2.6797 - val_accuracy: 0.2001 - val_f1: 0.0456\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5002 - accuracy: 0.2356 - f1: 0.0664 - val_loss: 2.6805 - val_accuracy: 0.1980 - val_f1: 0.0471\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4998 - accuracy: 0.2356 - f1: 0.0657 - val_loss: 2.6841 - val_accuracy: 0.1997 - val_f1: 0.0431\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4969 - accuracy: 0.2373 - f1: 0.0669 - val_loss: 2.6809 - val_accuracy: 0.2008 - val_f1: 0.0454\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.4978 - accuracy: 0.2359 - f1: 0.0670 - val_loss: 2.6708 - val_accuracy: 0.2009 - val_f1: 0.0405\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4955 - accuracy: 0.2374 - f1: 0.0683 - val_loss: 2.6702 - val_accuracy: 0.2041 - val_f1: 0.0534\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4943 - accuracy: 0.2373 - f1: 0.0694 - val_loss: 2.6868 - val_accuracy: 0.1999 - val_f1: 0.0494\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m1= CreateMultiPerceptron(4,100,100,0.0005,1,\"../music/music/tagged_feature_sets/msd-jmirmoments_dev/msd-jmirmoments_dev.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m1.to_json()\n",
    "with open(\"m1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m1.save_weights(\"m1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.9927 - accuracy: 0.1214 - f1: 0.0269 - val_loss: 2.9091 - val_accuracy: 0.1472 - val_f1: 0.0445\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.8678 - accuracy: 0.1547 - f1: 0.0479 - val_loss: 2.9101 - val_accuracy: 0.1437 - val_f1: 0.0551\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.8127 - accuracy: 0.1665 - f1: 0.0526 - val_loss: 2.7906 - val_accuracy: 0.1689 - val_f1: 0.0701\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7866 - accuracy: 0.1721 - f1: 0.0563 - val_loss: 2.7650 - val_accuracy: 0.1754 - val_f1: 0.0624\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7734 - accuracy: 0.1755 - f1: 0.0560 - val_loss: 2.9115 - val_accuracy: 0.1508 - val_f1: 0.0638\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7619 - accuracy: 0.1769 - f1: 0.0571 - val_loss: 2.7669 - val_accuracy: 0.1774 - val_f1: 0.0552\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7474 - accuracy: 0.1802 - f1: 0.0583 - val_loss: 2.7223 - val_accuracy: 0.1873 - val_f1: 0.0588\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7421 - accuracy: 0.1813 - f1: 0.0597 - val_loss: 2.7755 - val_accuracy: 0.1721 - val_f1: 0.0422\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7290 - accuracy: 0.1843 - f1: 0.0609 - val_loss: 2.7247 - val_accuracy: 0.1842 - val_f1: 0.0694\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7214 - accuracy: 0.1860 - f1: 0.0626 - val_loss: 2.7223 - val_accuracy: 0.1879 - val_f1: 0.0544\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.7078 - accuracy: 0.1890 - f1: 0.0639 - val_loss: 2.7400 - val_accuracy: 0.1750 - val_f1: 0.0541\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7058 - accuracy: 0.1909 - f1: 0.0643 - val_loss: 2.6851 - val_accuracy: 0.1985 - val_f1: 0.0742\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6961 - accuracy: 0.1947 - f1: 0.0653 - val_loss: 2.7023 - val_accuracy: 0.1930 - val_f1: 0.0565\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6918 - accuracy: 0.1942 - f1: 0.0652 - val_loss: 2.7159 - val_accuracy: 0.1889 - val_f1: 0.0709\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6896 - accuracy: 0.1940 - f1: 0.0661 - val_loss: 2.6823 - val_accuracy: 0.1998 - val_f1: 0.0705\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6821 - accuracy: 0.1956 - f1: 0.0676 - val_loss: 2.6938 - val_accuracy: 0.1941 - val_f1: 0.0692\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6750 - accuracy: 0.1987 - f1: 0.0696 - val_loss: 2.7419 - val_accuracy: 0.1867 - val_f1: 0.0867\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6714 - accuracy: 0.1993 - f1: 0.0693 - val_loss: 2.7209 - val_accuracy: 0.1879 - val_f1: 0.0730\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6683 - accuracy: 0.1997 - f1: 0.0701 - val_loss: 2.6797 - val_accuracy: 0.1974 - val_f1: 0.0684\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6600 - accuracy: 0.2021 - f1: 0.0702 - val_loss: 2.6986 - val_accuracy: 0.1964 - val_f1: 0.0579\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6568 - accuracy: 0.2034 - f1: 0.0710 - val_loss: 2.7001 - val_accuracy: 0.1968 - val_f1: 0.0617\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.6578 - accuracy: 0.2035 - f1: 0.0711 - val_loss: 2.6844 - val_accuracy: 0.1970 - val_f1: 0.0746\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6494 - accuracy: 0.2051 - f1: 0.0724 - val_loss: 2.6627 - val_accuracy: 0.2050 - val_f1: 0.0636\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6467 - accuracy: 0.2058 - f1: 0.0732 - val_loss: 2.6724 - val_accuracy: 0.2046 - val_f1: 0.0735\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6438 - accuracy: 0.2061 - f1: 0.0726 - val_loss: 2.7339 - val_accuracy: 0.1866 - val_f1: 0.0846\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6400 - accuracy: 0.2063 - f1: 0.0736 - val_loss: 2.6668 - val_accuracy: 0.1992 - val_f1: 0.0766\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6384 - accuracy: 0.2075 - f1: 0.0746 - val_loss: 2.6648 - val_accuracy: 0.2004 - val_f1: 0.0779\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6336 - accuracy: 0.2075 - f1: 0.0741 - val_loss: 2.6364 - val_accuracy: 0.2117 - val_f1: 0.0729\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6325 - accuracy: 0.2086 - f1: 0.0756 - val_loss: 2.6611 - val_accuracy: 0.2066 - val_f1: 0.0947\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6316 - accuracy: 0.2084 - f1: 0.0754 - val_loss: 2.6590 - val_accuracy: 0.2069 - val_f1: 0.0686\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6266 - accuracy: 0.2113 - f1: 0.0762 - val_loss: 2.6495 - val_accuracy: 0.2067 - val_f1: 0.0707\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6211 - accuracy: 0.2114 - f1: 0.0771 - val_loss: 2.6782 - val_accuracy: 0.1965 - val_f1: 0.0691\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6219 - accuracy: 0.2107 - f1: 0.0766 - val_loss: 2.6391 - val_accuracy: 0.2100 - val_f1: 0.0637\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6180 - accuracy: 0.2121 - f1: 0.0775 - val_loss: 2.6886 - val_accuracy: 0.2036 - val_f1: 0.0668\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6103 - accuracy: 0.2128 - f1: 0.0789 - val_loss: 2.6371 - val_accuracy: 0.2127 - val_f1: 0.0840\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6142 - accuracy: 0.2123 - f1: 0.0775 - val_loss: 2.6363 - val_accuracy: 0.2100 - val_f1: 0.0753\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6120 - accuracy: 0.2143 - f1: 0.0789 - val_loss: 2.6449 - val_accuracy: 0.2088 - val_f1: 0.0680\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6068 - accuracy: 0.2146 - f1: 0.0793 - val_loss: 2.6354 - val_accuracy: 0.2121 - val_f1: 0.0813\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6099 - accuracy: 0.2149 - f1: 0.0790 - val_loss: 2.6551 - val_accuracy: 0.2058 - val_f1: 0.0649\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6036 - accuracy: 0.2148 - f1: 0.0799 - val_loss: 2.6460 - val_accuracy: 0.2107 - val_f1: 0.0810\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6018 - accuracy: 0.2146 - f1: 0.0802 - val_loss: 2.6590 - val_accuracy: 0.2083 - val_f1: 0.0874\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5993 - accuracy: 0.2160 - f1: 0.0821 - val_loss: 2.6575 - val_accuracy: 0.2064 - val_f1: 0.0685\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5989 - accuracy: 0.2158 - f1: 0.0814 - val_loss: 2.6700 - val_accuracy: 0.2051 - val_f1: 0.0678\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5941 - accuracy: 0.2167 - f1: 0.0819 - val_loss: 2.6809 - val_accuracy: 0.2007 - val_f1: 0.0845\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5917 - accuracy: 0.2176 - f1: 0.0830 - val_loss: 2.6498 - val_accuracy: 0.2084 - val_f1: 0.0855\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5928 - accuracy: 0.2177 - f1: 0.0826 - val_loss: 2.6239 - val_accuracy: 0.2152 - val_f1: 0.0794\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5897 - accuracy: 0.2190 - f1: 0.0828 - val_loss: 2.6574 - val_accuracy: 0.2070 - val_f1: 0.0832\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5886 - accuracy: 0.2181 - f1: 0.0830 - val_loss: 2.6560 - val_accuracy: 0.2055 - val_f1: 0.0813\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5894 - accuracy: 0.2179 - f1: 0.0834 - val_loss: 2.6314 - val_accuracy: 0.2146 - val_f1: 0.0844\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5849 - accuracy: 0.2196 - f1: 0.0852 - val_loss: 2.6708 - val_accuracy: 0.2074 - val_f1: 0.0732\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5864 - accuracy: 0.2201 - f1: 0.0842 - val_loss: 2.6401 - val_accuracy: 0.2109 - val_f1: 0.0830\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5784 - accuracy: 0.2209 - f1: 0.0851 - val_loss: 2.6766 - val_accuracy: 0.2068 - val_f1: 0.0626\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5781 - accuracy: 0.2202 - f1: 0.0843 - val_loss: 2.6337 - val_accuracy: 0.2094 - val_f1: 0.0757\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.5795 - accuracy: 0.2219 - f1: 0.0855 - val_loss: 2.6677 - val_accuracy: 0.2037 - val_f1: 0.0943\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5781 - accuracy: 0.2214 - f1: 0.0859 - val_loss: 2.6371 - val_accuracy: 0.2106 - val_f1: 0.0670\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5789 - accuracy: 0.2207 - f1: 0.0850 - val_loss: 2.6477 - val_accuracy: 0.2094 - val_f1: 0.0859\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5748 - accuracy: 0.2218 - f1: 0.0866 - val_loss: 2.6917 - val_accuracy: 0.2042 - val_f1: 0.0868\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5713 - accuracy: 0.2211 - f1: 0.0853 - val_loss: 2.6391 - val_accuracy: 0.2141 - val_f1: 0.0863\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5734 - accuracy: 0.2220 - f1: 0.0865 - val_loss: 2.6565 - val_accuracy: 0.2076 - val_f1: 0.0744\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5735 - accuracy: 0.2213 - f1: 0.0862 - val_loss: 2.6486 - val_accuracy: 0.2091 - val_f1: 0.0898\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5685 - accuracy: 0.2244 - f1: 0.0873 - val_loss: 2.6763 - val_accuracy: 0.2045 - val_f1: 0.0973\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5666 - accuracy: 0.2245 - f1: 0.0888 - val_loss: 2.6441 - val_accuracy: 0.2071 - val_f1: 0.0711\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5680 - accuracy: 0.2227 - f1: 0.0873 - val_loss: 2.6464 - val_accuracy: 0.2092 - val_f1: 0.0900\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5600 - accuracy: 0.2233 - f1: 0.0897 - val_loss: 2.6590 - val_accuracy: 0.2095 - val_f1: 0.0750\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5630 - accuracy: 0.2246 - f1: 0.0890 - val_loss: 2.6449 - val_accuracy: 0.2111 - val_f1: 0.0888\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5612 - accuracy: 0.2256 - f1: 0.0900 - val_loss: 2.6336 - val_accuracy: 0.2138 - val_f1: 0.0805\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5567 - accuracy: 0.2256 - f1: 0.0910 - val_loss: 2.6542 - val_accuracy: 0.2083 - val_f1: 0.0814\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5594 - accuracy: 0.2251 - f1: 0.0898 - val_loss: 2.6701 - val_accuracy: 0.2093 - val_f1: 0.0892\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5575 - accuracy: 0.2262 - f1: 0.0918 - val_loss: 2.7064 - val_accuracy: 0.1978 - val_f1: 0.0995\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5525 - accuracy: 0.2263 - f1: 0.0916 - val_loss: 2.7000 - val_accuracy: 0.2032 - val_f1: 0.0865\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5509 - accuracy: 0.2279 - f1: 0.0919 - val_loss: 2.6959 - val_accuracy: 0.2016 - val_f1: 0.0705\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.5558 - accuracy: 0.2254 - f1: 0.0911 - val_loss: 2.6456 - val_accuracy: 0.2106 - val_f1: 0.0774\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5509 - accuracy: 0.2275 - f1: 0.0926 - val_loss: 2.6534 - val_accuracy: 0.2100 - val_f1: 0.0855\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5517 - accuracy: 0.2284 - f1: 0.0915 - val_loss: 2.6257 - val_accuracy: 0.2164 - val_f1: 0.0822\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5460 - accuracy: 0.2281 - f1: 0.0932 - val_loss: 2.6401 - val_accuracy: 0.2093 - val_f1: 0.0757\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5474 - accuracy: 0.2286 - f1: 0.0924 - val_loss: 2.6757 - val_accuracy: 0.2071 - val_f1: 0.0934\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5482 - accuracy: 0.2275 - f1: 0.0932 - val_loss: 2.6827 - val_accuracy: 0.2052 - val_f1: 0.0725\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5446 - accuracy: 0.2285 - f1: 0.0947 - val_loss: 2.7005 - val_accuracy: 0.1934 - val_f1: 0.0738\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5440 - accuracy: 0.2296 - f1: 0.0929 - val_loss: 2.6561 - val_accuracy: 0.2072 - val_f1: 0.0770\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5408 - accuracy: 0.2308 - f1: 0.0941 - val_loss: 2.6388 - val_accuracy: 0.2139 - val_f1: 0.1019\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5427 - accuracy: 0.2298 - f1: 0.0946 - val_loss: 2.6547 - val_accuracy: 0.2067 - val_f1: 0.0773\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5397 - accuracy: 0.2305 - f1: 0.0954 - val_loss: 2.6564 - val_accuracy: 0.2114 - val_f1: 0.0873\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5399 - accuracy: 0.2293 - f1: 0.0953 - val_loss: 2.6628 - val_accuracy: 0.2069 - val_f1: 0.0757\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5382 - accuracy: 0.2305 - f1: 0.0955 - val_loss: 2.6535 - val_accuracy: 0.2152 - val_f1: 0.0876\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5343 - accuracy: 0.2313 - f1: 0.0960 - val_loss: 2.6490 - val_accuracy: 0.2143 - val_f1: 0.0839\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.5349 - accuracy: 0.2321 - f1: 0.0959 - val_loss: 2.6930 - val_accuracy: 0.1977 - val_f1: 0.0684\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5375 - accuracy: 0.2297 - f1: 0.0967 - val_loss: 2.6687 - val_accuracy: 0.2055 - val_f1: 0.0850\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5324 - accuracy: 0.2319 - f1: 0.0971 - val_loss: 2.6579 - val_accuracy: 0.2118 - val_f1: 0.0858\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5291 - accuracy: 0.2319 - f1: 0.0980 - val_loss: 2.6509 - val_accuracy: 0.2123 - val_f1: 0.0905\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5284 - accuracy: 0.2327 - f1: 0.0976 - val_loss: 2.6531 - val_accuracy: 0.2101 - val_f1: 0.0869\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5294 - accuracy: 0.2331 - f1: 0.0979 - val_loss: 2.6562 - val_accuracy: 0.2095 - val_f1: 0.0791\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5289 - accuracy: 0.2327 - f1: 0.0984 - val_loss: 2.6647 - val_accuracy: 0.2093 - val_f1: 0.0889\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5284 - accuracy: 0.2336 - f1: 0.0979 - val_loss: 2.6778 - val_accuracy: 0.2093 - val_f1: 0.0843\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5310 - accuracy: 0.2311 - f1: 0.0976 - val_loss: 2.6397 - val_accuracy: 0.2147 - val_f1: 0.0839\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5241 - accuracy: 0.2340 - f1: 0.1000 - val_loss: 2.6680 - val_accuracy: 0.2069 - val_f1: 0.0722\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5276 - accuracy: 0.2325 - f1: 0.0988 - val_loss: 2.6957 - val_accuracy: 0.2011 - val_f1: 0.0887\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5236 - accuracy: 0.2333 - f1: 0.0989 - val_loss: 2.6472 - val_accuracy: 0.2123 - val_f1: 0.0903\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5243 - accuracy: 0.2335 - f1: 0.0984 - val_loss: 2.6370 - val_accuracy: 0.2163 - val_f1: 0.0888\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5231 - accuracy: 0.2348 - f1: 0.0995 - val_loss: 2.6470 - val_accuracy: 0.2130 - val_f1: 0.0878\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.5170 - accuracy: 0.2360 - f1: 0.1011 - val_loss: 2.6471 - val_accuracy: 0.2135 - val_f1: 0.0895\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m2= CreateMultiPerceptron(4,100,100,0.0005,2,\"../music/music/tagged_feature_sets/msd-mvd_dev/msd-mvd_dev.csv\") \n",
    "# serialize model to JSON\n",
    "model_json = m2.to_json()\n",
    "with open(\"m2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m2.save_weights(\"m2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.7070 - accuracy: 0.1775 - f1: 0.0242 - val_loss: 2.6016 - val_accuracy: 0.2044 - val_f1: 0.0396\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5710 - accuracy: 0.2141 - f1: 0.0460 - val_loss: 2.5483 - val_accuracy: 0.2197 - val_f1: 0.0255\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.5230 - accuracy: 0.2260 - f1: 0.0585 - val_loss: 2.5126 - val_accuracy: 0.2308 - val_f1: 0.0527\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4968 - accuracy: 0.2358 - f1: 0.0661 - val_loss: 2.4683 - val_accuracy: 0.2438 - val_f1: 0.0661\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4757 - accuracy: 0.2408 - f1: 0.0723 - val_loss: 2.5069 - val_accuracy: 0.2310 - val_f1: 0.0738\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4614 - accuracy: 0.2467 - f1: 0.0778 - val_loss: 2.4770 - val_accuracy: 0.2453 - val_f1: 0.0785\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4422 - accuracy: 0.2519 - f1: 0.0853 - val_loss: 2.4404 - val_accuracy: 0.2505 - val_f1: 0.0932\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4302 - accuracy: 0.2541 - f1: 0.0891 - val_loss: 2.4220 - val_accuracy: 0.2576 - val_f1: 0.0889\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4220 - accuracy: 0.2561 - f1: 0.0925 - val_loss: 2.4856 - val_accuracy: 0.2405 - val_f1: 0.0854\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4171 - accuracy: 0.2569 - f1: 0.0949 - val_loss: 2.4679 - val_accuracy: 0.2468 - val_f1: 0.0938\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.4020 - accuracy: 0.2617 - f1: 0.0992 - val_loss: 2.4546 - val_accuracy: 0.2482 - val_f1: 0.0754\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3966 - accuracy: 0.2627 - f1: 0.1006 - val_loss: 2.4079 - val_accuracy: 0.2603 - val_f1: 0.1179\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3880 - accuracy: 0.2655 - f1: 0.1043 - val_loss: 2.4098 - val_accuracy: 0.2650 - val_f1: 0.1114\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.3836 - accuracy: 0.2646 - f1: 0.1041 - val_loss: 2.4731 - val_accuracy: 0.2474 - val_f1: 0.1139\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.3753 - accuracy: 0.2667 - f1: 0.1084 - val_loss: 2.4290 - val_accuracy: 0.2547 - val_f1: 0.1184\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3690 - accuracy: 0.2714 - f1: 0.1118 - val_loss: 2.4128 - val_accuracy: 0.2627 - val_f1: 0.1200\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3626 - accuracy: 0.2726 - f1: 0.1124 - val_loss: 2.4057 - val_accuracy: 0.2650 - val_f1: 0.1056\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.3591 - accuracy: 0.2723 - f1: 0.1136 - val_loss: 2.4523 - val_accuracy: 0.2502 - val_f1: 0.0968\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3524 - accuracy: 0.2759 - f1: 0.1163 - val_loss: 2.3922 - val_accuracy: 0.2716 - val_f1: 0.1252\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3464 - accuracy: 0.2766 - f1: 0.1192 - val_loss: 2.4302 - val_accuracy: 0.2591 - val_f1: 0.1228\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.3437 - accuracy: 0.2767 - f1: 0.1173 - val_loss: 2.3975 - val_accuracy: 0.2680 - val_f1: 0.1234\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3402 - accuracy: 0.2783 - f1: 0.1213 - val_loss: 2.4077 - val_accuracy: 0.2643 - val_f1: 0.1293\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.3299 - accuracy: 0.2813 - f1: 0.1228 - val_loss: 2.3854 - val_accuracy: 0.2688 - val_f1: 0.1206\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3295 - accuracy: 0.2811 - f1: 0.1238 - val_loss: 2.4290 - val_accuracy: 0.2620 - val_f1: 0.0992\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3258 - accuracy: 0.2825 - f1: 0.1229 - val_loss: 2.4436 - val_accuracy: 0.2568 - val_f1: 0.1285\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3204 - accuracy: 0.2838 - f1: 0.1261 - val_loss: 2.3948 - val_accuracy: 0.2693 - val_f1: 0.1317\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3216 - accuracy: 0.2837 - f1: 0.1248 - val_loss: 2.3708 - val_accuracy: 0.2737 - val_f1: 0.1215\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.3141 - accuracy: 0.2854 - f1: 0.1278 - val_loss: 2.4026 - val_accuracy: 0.2659 - val_f1: 0.1064\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3092 - accuracy: 0.2853 - f1: 0.1305 - val_loss: 2.4063 - val_accuracy: 0.2667 - val_f1: 0.1279\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.3051 - accuracy: 0.2889 - f1: 0.1307 - val_loss: 2.3746 - val_accuracy: 0.2772 - val_f1: 0.1338\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3031 - accuracy: 0.2860 - f1: 0.1329 - val_loss: 2.3742 - val_accuracy: 0.2679 - val_f1: 0.1229\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2975 - accuracy: 0.2903 - f1: 0.1346 - val_loss: 2.4087 - val_accuracy: 0.2672 - val_f1: 0.1226\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2950 - accuracy: 0.2898 - f1: 0.1351 - val_loss: 2.3722 - val_accuracy: 0.2727 - val_f1: 0.1239\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.2905 - accuracy: 0.2913 - f1: 0.1359 - val_loss: 2.4106 - val_accuracy: 0.2677 - val_f1: 0.1353\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2862 - accuracy: 0.2927 - f1: 0.1379 - val_loss: 2.3685 - val_accuracy: 0.2779 - val_f1: 0.1226\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2838 - accuracy: 0.2936 - f1: 0.1398 - val_loss: 2.3826 - val_accuracy: 0.2710 - val_f1: 0.1153\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2805 - accuracy: 0.2937 - f1: 0.1401 - val_loss: 2.4396 - val_accuracy: 0.2633 - val_f1: 0.1425\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2767 - accuracy: 0.2955 - f1: 0.1417 - val_loss: 2.4037 - val_accuracy: 0.2664 - val_f1: 0.1375\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2730 - accuracy: 0.2963 - f1: 0.1429 - val_loss: 2.3958 - val_accuracy: 0.2694 - val_f1: 0.1336\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.2720 - accuracy: 0.2969 - f1: 0.1423 - val_loss: 2.3718 - val_accuracy: 0.2748 - val_f1: 0.1424\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2648 - accuracy: 0.2985 - f1: 0.1449 - val_loss: 2.3656 - val_accuracy: 0.2790 - val_f1: 0.1287\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2664 - accuracy: 0.2971 - f1: 0.1444 - val_loss: 2.4015 - val_accuracy: 0.2669 - val_f1: 0.1237\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2638 - accuracy: 0.2982 - f1: 0.1457 - val_loss: 2.3691 - val_accuracy: 0.2746 - val_f1: 0.1424\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2629 - accuracy: 0.2992 - f1: 0.1458 - val_loss: 2.3933 - val_accuracy: 0.2712 - val_f1: 0.1474\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2588 - accuracy: 0.3011 - f1: 0.1483 - val_loss: 2.3968 - val_accuracy: 0.2717 - val_f1: 0.1384\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2561 - accuracy: 0.3013 - f1: 0.1488 - val_loss: 2.3722 - val_accuracy: 0.2779 - val_f1: 0.1506\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2518 - accuracy: 0.3027 - f1: 0.1517 - val_loss: 2.3713 - val_accuracy: 0.2789 - val_f1: 0.1381\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2485 - accuracy: 0.3021 - f1: 0.1522 - val_loss: 2.3897 - val_accuracy: 0.2749 - val_f1: 0.1455\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2452 - accuracy: 0.3042 - f1: 0.1524 - val_loss: 2.3785 - val_accuracy: 0.2753 - val_f1: 0.1390\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2437 - accuracy: 0.3046 - f1: 0.1554 - val_loss: 2.3723 - val_accuracy: 0.2771 - val_f1: 0.1428\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2383 - accuracy: 0.3060 - f1: 0.1563 - val_loss: 2.3827 - val_accuracy: 0.2723 - val_f1: 0.1361\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2388 - accuracy: 0.3068 - f1: 0.1558 - val_loss: 2.3822 - val_accuracy: 0.2758 - val_f1: 0.1364\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2355 - accuracy: 0.3075 - f1: 0.1561 - val_loss: 2.4058 - val_accuracy: 0.2696 - val_f1: 0.1413\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2338 - accuracy: 0.3065 - f1: 0.1572 - val_loss: 2.3813 - val_accuracy: 0.2750 - val_f1: 0.1418\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2335 - accuracy: 0.3062 - f1: 0.1575 - val_loss: 2.3757 - val_accuracy: 0.2786 - val_f1: 0.1470\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2275 - accuracy: 0.3090 - f1: 0.1595 - val_loss: 2.3859 - val_accuracy: 0.2767 - val_f1: 0.1487\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2287 - accuracy: 0.3076 - f1: 0.1596 - val_loss: 2.4435 - val_accuracy: 0.2610 - val_f1: 0.1364\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2269 - accuracy: 0.3095 - f1: 0.1601 - val_loss: 2.4115 - val_accuracy: 0.2690 - val_f1: 0.1224\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2244 - accuracy: 0.3104 - f1: 0.1599 - val_loss: 2.3817 - val_accuracy: 0.2801 - val_f1: 0.1511\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2202 - accuracy: 0.3094 - f1: 0.1620 - val_loss: 2.3749 - val_accuracy: 0.2790 - val_f1: 0.1362\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2207 - accuracy: 0.3096 - f1: 0.1627 - val_loss: 2.3823 - val_accuracy: 0.2781 - val_f1: 0.1538\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2186 - accuracy: 0.3121 - f1: 0.1640 - val_loss: 2.3739 - val_accuracy: 0.2816 - val_f1: 0.1524\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.2173 - accuracy: 0.3120 - f1: 0.1648 - val_loss: 2.3798 - val_accuracy: 0.2776 - val_f1: 0.1399\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2127 - accuracy: 0.3139 - f1: 0.1654 - val_loss: 2.3747 - val_accuracy: 0.2802 - val_f1: 0.1536\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2100 - accuracy: 0.3144 - f1: 0.1665 - val_loss: 2.3909 - val_accuracy: 0.2777 - val_f1: 0.1590\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.2089 - accuracy: 0.3143 - f1: 0.1667 - val_loss: 2.3969 - val_accuracy: 0.2793 - val_f1: 0.1668\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.2090 - accuracy: 0.3138 - f1: 0.1673 - val_loss: 2.3857 - val_accuracy: 0.2809 - val_f1: 0.1642\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2066 - accuracy: 0.3136 - f1: 0.1702 - val_loss: 2.3945 - val_accuracy: 0.2788 - val_f1: 0.1552\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2038 - accuracy: 0.3145 - f1: 0.1696 - val_loss: 2.4334 - val_accuracy: 0.2663 - val_f1: 0.1388\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2030 - accuracy: 0.3157 - f1: 0.1705 - val_loss: 2.3988 - val_accuracy: 0.2740 - val_f1: 0.1376\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.1993 - accuracy: 0.3166 - f1: 0.1707 - val_loss: 2.4012 - val_accuracy: 0.2755 - val_f1: 0.1523\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.2009 - accuracy: 0.3162 - f1: 0.1698 - val_loss: 2.4285 - val_accuracy: 0.2694 - val_f1: 0.1431\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1992 - accuracy: 0.3189 - f1: 0.1717 - val_loss: 2.4064 - val_accuracy: 0.2755 - val_f1: 0.1399\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1952 - accuracy: 0.3188 - f1: 0.1727 - val_loss: 2.3935 - val_accuracy: 0.2796 - val_f1: 0.1603\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1940 - accuracy: 0.3187 - f1: 0.1731 - val_loss: 2.3978 - val_accuracy: 0.2738 - val_f1: 0.1478\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1914 - accuracy: 0.3191 - f1: 0.1737 - val_loss: 2.3907 - val_accuracy: 0.2800 - val_f1: 0.1558\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1912 - accuracy: 0.3190 - f1: 0.1753 - val_loss: 2.4075 - val_accuracy: 0.2774 - val_f1: 0.1560\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1869 - accuracy: 0.3199 - f1: 0.1763 - val_loss: 2.4153 - val_accuracy: 0.2700 - val_f1: 0.1465\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1885 - accuracy: 0.3189 - f1: 0.1758 - val_loss: 2.4043 - val_accuracy: 0.2758 - val_f1: 0.1605\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1899 - accuracy: 0.3200 - f1: 0.1764 - val_loss: 2.4087 - val_accuracy: 0.2741 - val_f1: 0.1546\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1844 - accuracy: 0.3196 - f1: 0.1775 - val_loss: 2.4206 - val_accuracy: 0.2732 - val_f1: 0.1565\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1854 - accuracy: 0.3206 - f1: 0.1779 - val_loss: 2.4425 - val_accuracy: 0.2710 - val_f1: 0.1587\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1804 - accuracy: 0.3223 - f1: 0.1777 - val_loss: 2.4030 - val_accuracy: 0.2782 - val_f1: 0.1523\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1808 - accuracy: 0.3209 - f1: 0.1798 - val_loss: 2.4074 - val_accuracy: 0.2769 - val_f1: 0.1473\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1806 - accuracy: 0.3220 - f1: 0.1800 - val_loss: 2.4157 - val_accuracy: 0.2745 - val_f1: 0.1432\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1793 - accuracy: 0.3222 - f1: 0.1799 - val_loss: 2.3835 - val_accuracy: 0.2800 - val_f1: 0.1450\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1782 - accuracy: 0.3229 - f1: 0.1809 - val_loss: 2.3879 - val_accuracy: 0.2812 - val_f1: 0.1540\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1773 - accuracy: 0.3234 - f1: 0.1814 - val_loss: 2.4122 - val_accuracy: 0.2757 - val_f1: 0.1565\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1762 - accuracy: 0.3237 - f1: 0.1817 - val_loss: 2.4563 - val_accuracy: 0.2689 - val_f1: 0.1583\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.1736 - accuracy: 0.3233 - f1: 0.1828 - val_loss: 2.4320 - val_accuracy: 0.2710 - val_f1: 0.1577\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1702 - accuracy: 0.3246 - f1: 0.1838 - val_loss: 2.3946 - val_accuracy: 0.2818 - val_f1: 0.1602\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1683 - accuracy: 0.3242 - f1: 0.1842 - val_loss: 2.3922 - val_accuracy: 0.2790 - val_f1: 0.1511\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1693 - accuracy: 0.3253 - f1: 0.1842 - val_loss: 2.3991 - val_accuracy: 0.2768 - val_f1: 0.1615\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1691 - accuracy: 0.3253 - f1: 0.1850 - val_loss: 2.4012 - val_accuracy: 0.2820 - val_f1: 0.1574\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1665 - accuracy: 0.3265 - f1: 0.1863 - val_loss: 2.4385 - val_accuracy: 0.2741 - val_f1: 0.1712\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1642 - accuracy: 0.3261 - f1: 0.1862 - val_loss: 2.4049 - val_accuracy: 0.2750 - val_f1: 0.1487\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1635 - accuracy: 0.3272 - f1: 0.1876 - val_loss: 2.4132 - val_accuracy: 0.2798 - val_f1: 0.1712\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1608 - accuracy: 0.3266 - f1: 0.1892 - val_loss: 2.4029 - val_accuracy: 0.2791 - val_f1: 0.1515\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1613 - accuracy: 0.3270 - f1: 0.1880 - val_loss: 2.4545 - val_accuracy: 0.2676 - val_f1: 0.1539\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.1609 - accuracy: 0.3275 - f1: 0.1896 - val_loss: 2.3914 - val_accuracy: 0.2821 - val_f1: 0.1580\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m3= CreateMultiPerceptron(4,100,100,0.0005,3,\"../music/music/tagged_feature_sets/msd-ssd_dev/msd-ssd_dev.csv\") \n",
    "# serialize model to JSON\n",
    "model_json = m3.to_json()\n",
    "with open(\"m3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m3.save_weights(\"m3.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.8505 - accuracy: 0.1424 - f1: 0.0058 - val_loss: 2.7777 - val_accuracy: 0.1603 - val_f1: 0.0137\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.7380 - accuracy: 0.1708 - f1: 0.0103 - val_loss: 2.7140 - val_accuracy: 0.1775 - val_f1: 0.0093\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.7040 - accuracy: 0.1781 - f1: 0.0157 - val_loss: 2.6855 - val_accuracy: 0.1850 - val_f1: 0.0162\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.6818 - accuracy: 0.1831 - f1: 0.0198 - val_loss: 2.6956 - val_accuracy: 0.1810 - val_f1: 0.0199\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6709 - accuracy: 0.1864 - f1: 0.0219 - val_loss: 2.6643 - val_accuracy: 0.1887 - val_f1: 0.0352\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6587 - accuracy: 0.1876 - f1: 0.0238 - val_loss: 2.6571 - val_accuracy: 0.1907 - val_f1: 0.0125\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6514 - accuracy: 0.1907 - f1: 0.0250 - val_loss: 2.6419 - val_accuracy: 0.1948 - val_f1: 0.0258\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6447 - accuracy: 0.1922 - f1: 0.0276 - val_loss: 2.6375 - val_accuracy: 0.1971 - val_f1: 0.0217\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6362 - accuracy: 0.1937 - f1: 0.0286 - val_loss: 2.6571 - val_accuracy: 0.1907 - val_f1: 0.0448\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6317 - accuracy: 0.1950 - f1: 0.0289 - val_loss: 2.6319 - val_accuracy: 0.1975 - val_f1: 0.0257\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6245 - accuracy: 0.1958 - f1: 0.0307 - val_loss: 2.6273 - val_accuracy: 0.2004 - val_f1: 0.0324\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6226 - accuracy: 0.1970 - f1: 0.0310 - val_loss: 2.6164 - val_accuracy: 0.2033 - val_f1: 0.0194\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6151 - accuracy: 0.1988 - f1: 0.0327 - val_loss: 2.6228 - val_accuracy: 0.2030 - val_f1: 0.0255\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6112 - accuracy: 0.2012 - f1: 0.0328 - val_loss: 2.6333 - val_accuracy: 0.1961 - val_f1: 0.0423\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6080 - accuracy: 0.2020 - f1: 0.0352 - val_loss: 2.6252 - val_accuracy: 0.2010 - val_f1: 0.0355\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6035 - accuracy: 0.2033 - f1: 0.0354 - val_loss: 2.6089 - val_accuracy: 0.2064 - val_f1: 0.0381\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5994 - accuracy: 0.2035 - f1: 0.0365 - val_loss: 2.6158 - val_accuracy: 0.2027 - val_f1: 0.0429\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5933 - accuracy: 0.2058 - f1: 0.0368 - val_loss: 2.6149 - val_accuracy: 0.2047 - val_f1: 0.0408\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5900 - accuracy: 0.2067 - f1: 0.0383 - val_loss: 2.6192 - val_accuracy: 0.1997 - val_f1: 0.0495\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5826 - accuracy: 0.2080 - f1: 0.0395 - val_loss: 2.5936 - val_accuracy: 0.2098 - val_f1: 0.0256\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5821 - accuracy: 0.2089 - f1: 0.0406 - val_loss: 2.5909 - val_accuracy: 0.2092 - val_f1: 0.0369\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5792 - accuracy: 0.2090 - f1: 0.0413 - val_loss: 2.5910 - val_accuracy: 0.2117 - val_f1: 0.0394\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5786 - accuracy: 0.2098 - f1: 0.0416 - val_loss: 2.6177 - val_accuracy: 0.2059 - val_f1: 0.0369\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5730 - accuracy: 0.2123 - f1: 0.0429 - val_loss: 2.5960 - val_accuracy: 0.2089 - val_f1: 0.0414\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5693 - accuracy: 0.2126 - f1: 0.0442 - val_loss: 2.6279 - val_accuracy: 0.2055 - val_f1: 0.0456\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5690 - accuracy: 0.2132 - f1: 0.0446 - val_loss: 2.6342 - val_accuracy: 0.2033 - val_f1: 0.0556\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5644 - accuracy: 0.2142 - f1: 0.0449 - val_loss: 2.5974 - val_accuracy: 0.2092 - val_f1: 0.0448\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5593 - accuracy: 0.2158 - f1: 0.0445 - val_loss: 2.5965 - val_accuracy: 0.2077 - val_f1: 0.0371\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5591 - accuracy: 0.2157 - f1: 0.0462 - val_loss: 2.5736 - val_accuracy: 0.2154 - val_f1: 0.0430\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5550 - accuracy: 0.2161 - f1: 0.0468 - val_loss: 2.6395 - val_accuracy: 0.2017 - val_f1: 0.0427\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5550 - accuracy: 0.2163 - f1: 0.0469 - val_loss: 2.6128 - val_accuracy: 0.2094 - val_f1: 0.0440\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5539 - accuracy: 0.2176 - f1: 0.0486 - val_loss: 2.5876 - val_accuracy: 0.2166 - val_f1: 0.0408\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5495 - accuracy: 0.2173 - f1: 0.0489 - val_loss: 2.6301 - val_accuracy: 0.2042 - val_f1: 0.0391\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5456 - accuracy: 0.2193 - f1: 0.0492 - val_loss: 2.5969 - val_accuracy: 0.2112 - val_f1: 0.0437\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5465 - accuracy: 0.2178 - f1: 0.0486 - val_loss: 2.6033 - val_accuracy: 0.2107 - val_f1: 0.0555\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5426 - accuracy: 0.2205 - f1: 0.0505 - val_loss: 2.5851 - val_accuracy: 0.2158 - val_f1: 0.0407\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5421 - accuracy: 0.2204 - f1: 0.0514 - val_loss: 2.5790 - val_accuracy: 0.2135 - val_f1: 0.0470\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5356 - accuracy: 0.2222 - f1: 0.0528 - val_loss: 2.5725 - val_accuracy: 0.2174 - val_f1: 0.0553\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5328 - accuracy: 0.2226 - f1: 0.0535 - val_loss: 2.6054 - val_accuracy: 0.2092 - val_f1: 0.0505\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5363 - accuracy: 0.2212 - f1: 0.0528 - val_loss: 2.5967 - val_accuracy: 0.2124 - val_f1: 0.0620\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5308 - accuracy: 0.2228 - f1: 0.0535 - val_loss: 2.5852 - val_accuracy: 0.2163 - val_f1: 0.0487\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5312 - accuracy: 0.2232 - f1: 0.0535 - val_loss: 2.5747 - val_accuracy: 0.2175 - val_f1: 0.0530\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5262 - accuracy: 0.2240 - f1: 0.0545 - val_loss: 2.5819 - val_accuracy: 0.2163 - val_f1: 0.0540\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5230 - accuracy: 0.2248 - f1: 0.0570 - val_loss: 2.5690 - val_accuracy: 0.2194 - val_f1: 0.0511\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5250 - accuracy: 0.2250 - f1: 0.0554 - val_loss: 2.5702 - val_accuracy: 0.2204 - val_f1: 0.0477\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5211 - accuracy: 0.2257 - f1: 0.0565 - val_loss: 2.6004 - val_accuracy: 0.2140 - val_f1: 0.0398\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5186 - accuracy: 0.2260 - f1: 0.0575 - val_loss: 2.5921 - val_accuracy: 0.2139 - val_f1: 0.0429\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5164 - accuracy: 0.2276 - f1: 0.0601 - val_loss: 2.6337 - val_accuracy: 0.2047 - val_f1: 0.0693\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5155 - accuracy: 0.2279 - f1: 0.0587 - val_loss: 2.5953 - val_accuracy: 0.2137 - val_f1: 0.0695\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5166 - accuracy: 0.2283 - f1: 0.0580 - val_loss: 2.5739 - val_accuracy: 0.2179 - val_f1: 0.0613\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5175 - accuracy: 0.2290 - f1: 0.0588 - val_loss: 2.5610 - val_accuracy: 0.2216 - val_f1: 0.0595\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5099 - accuracy: 0.2297 - f1: 0.0599 - val_loss: 2.5868 - val_accuracy: 0.2162 - val_f1: 0.0569\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.5076 - accuracy: 0.2288 - f1: 0.0603 - val_loss: 2.5740 - val_accuracy: 0.2185 - val_f1: 0.0617\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5071 - accuracy: 0.2296 - f1: 0.0604 - val_loss: 2.5868 - val_accuracy: 0.2177 - val_f1: 0.0655\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5048 - accuracy: 0.2301 - f1: 0.0623 - val_loss: 2.5657 - val_accuracy: 0.2201 - val_f1: 0.0574\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5038 - accuracy: 0.2315 - f1: 0.0619 - val_loss: 2.5686 - val_accuracy: 0.2197 - val_f1: 0.0630\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5014 - accuracy: 0.2326 - f1: 0.0644 - val_loss: 2.6504 - val_accuracy: 0.2019 - val_f1: 0.0544\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5030 - accuracy: 0.2311 - f1: 0.0637 - val_loss: 2.5625 - val_accuracy: 0.2239 - val_f1: 0.0583\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5010 - accuracy: 0.2317 - f1: 0.0633 - val_loss: 2.5758 - val_accuracy: 0.2191 - val_f1: 0.0663\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4968 - accuracy: 0.2340 - f1: 0.0648 - val_loss: 2.5857 - val_accuracy: 0.2165 - val_f1: 0.0490\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4962 - accuracy: 0.2324 - f1: 0.0645 - val_loss: 2.5611 - val_accuracy: 0.2229 - val_f1: 0.0644\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4935 - accuracy: 0.2334 - f1: 0.0660 - val_loss: 2.6078 - val_accuracy: 0.2104 - val_f1: 0.0655\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4947 - accuracy: 0.2334 - f1: 0.0664 - val_loss: 2.5660 - val_accuracy: 0.2208 - val_f1: 0.0577\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4926 - accuracy: 0.2336 - f1: 0.0673 - val_loss: 2.5650 - val_accuracy: 0.2229 - val_f1: 0.0577\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4908 - accuracy: 0.2348 - f1: 0.0655 - val_loss: 2.5834 - val_accuracy: 0.2164 - val_f1: 0.0658\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4913 - accuracy: 0.2334 - f1: 0.0676 - val_loss: 2.5800 - val_accuracy: 0.2198 - val_f1: 0.0621\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4897 - accuracy: 0.2347 - f1: 0.0662 - val_loss: 2.5709 - val_accuracy: 0.2259 - val_f1: 0.0597\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4843 - accuracy: 0.2350 - f1: 0.0694 - val_loss: 2.5628 - val_accuracy: 0.2230 - val_f1: 0.0662\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4862 - accuracy: 0.2348 - f1: 0.0687 - val_loss: 2.5885 - val_accuracy: 0.2168 - val_f1: 0.0529\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4870 - accuracy: 0.2361 - f1: 0.0688 - val_loss: 2.5815 - val_accuracy: 0.2201 - val_f1: 0.0626\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4834 - accuracy: 0.2365 - f1: 0.0703 - val_loss: 2.5969 - val_accuracy: 0.2185 - val_f1: 0.0666\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4826 - accuracy: 0.2363 - f1: 0.0700 - val_loss: 2.5748 - val_accuracy: 0.2240 - val_f1: 0.0723\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4828 - accuracy: 0.2375 - f1: 0.0694 - val_loss: 2.6286 - val_accuracy: 0.2083 - val_f1: 0.0727\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4809 - accuracy: 0.2379 - f1: 0.0710 - val_loss: 2.5768 - val_accuracy: 0.2188 - val_f1: 0.0627\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4794 - accuracy: 0.2384 - f1: 0.0710 - val_loss: 2.5852 - val_accuracy: 0.2163 - val_f1: 0.0629\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4811 - accuracy: 0.2367 - f1: 0.0703 - val_loss: 2.5647 - val_accuracy: 0.2239 - val_f1: 0.0635\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4770 - accuracy: 0.2390 - f1: 0.0721 - val_loss: 2.5687 - val_accuracy: 0.2239 - val_f1: 0.0582\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4735 - accuracy: 0.2391 - f1: 0.0731 - val_loss: 2.5733 - val_accuracy: 0.2253 - val_f1: 0.0804\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4730 - accuracy: 0.2394 - f1: 0.0719 - val_loss: 2.5587 - val_accuracy: 0.2261 - val_f1: 0.0720\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4722 - accuracy: 0.2400 - f1: 0.0736 - val_loss: 2.5927 - val_accuracy: 0.2183 - val_f1: 0.0683\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4717 - accuracy: 0.2402 - f1: 0.0736 - val_loss: 2.5621 - val_accuracy: 0.2245 - val_f1: 0.0662\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4684 - accuracy: 0.2405 - f1: 0.0741 - val_loss: 2.5868 - val_accuracy: 0.2201 - val_f1: 0.0704\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4710 - accuracy: 0.2395 - f1: 0.0737 - val_loss: 2.5685 - val_accuracy: 0.2219 - val_f1: 0.0492\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4651 - accuracy: 0.2411 - f1: 0.0753 - val_loss: 2.5850 - val_accuracy: 0.2237 - val_f1: 0.0666\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4625 - accuracy: 0.2427 - f1: 0.0751 - val_loss: 2.5712 - val_accuracy: 0.2261 - val_f1: 0.0589\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4660 - accuracy: 0.2417 - f1: 0.0761 - val_loss: 2.6194 - val_accuracy: 0.2096 - val_f1: 0.0726\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4642 - accuracy: 0.2417 - f1: 0.0756 - val_loss: 2.5754 - val_accuracy: 0.2227 - val_f1: 0.0776\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4636 - accuracy: 0.2428 - f1: 0.0772 - val_loss: 2.5703 - val_accuracy: 0.2261 - val_f1: 0.0724\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4626 - accuracy: 0.2426 - f1: 0.0761 - val_loss: 2.5706 - val_accuracy: 0.2218 - val_f1: 0.0735\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4606 - accuracy: 0.2436 - f1: 0.0781 - val_loss: 2.5846 - val_accuracy: 0.2193 - val_f1: 0.0594\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4582 - accuracy: 0.2436 - f1: 0.0777 - val_loss: 2.6064 - val_accuracy: 0.2146 - val_f1: 0.0669\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4612 - accuracy: 0.2419 - f1: 0.0787 - val_loss: 2.5764 - val_accuracy: 0.2233 - val_f1: 0.0519\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4562 - accuracy: 0.2432 - f1: 0.0789 - val_loss: 2.5797 - val_accuracy: 0.2223 - val_f1: 0.0629\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4563 - accuracy: 0.2444 - f1: 0.0779 - val_loss: 2.5841 - val_accuracy: 0.2200 - val_f1: 0.0619\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4529 - accuracy: 0.2451 - f1: 0.0784 - val_loss: 2.5766 - val_accuracy: 0.2225 - val_f1: 0.0644\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4541 - accuracy: 0.2431 - f1: 0.0804 - val_loss: 2.5962 - val_accuracy: 0.2124 - val_f1: 0.0607\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4537 - accuracy: 0.2446 - f1: 0.0801 - val_loss: 2.5969 - val_accuracy: 0.2199 - val_f1: 0.0703\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4527 - accuracy: 0.2452 - f1: 0.0811 - val_loss: 2.5766 - val_accuracy: 0.2237 - val_f1: 0.0711\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4526 - accuracy: 0.2453 - f1: 0.0808 - val_loss: 2.5745 - val_accuracy: 0.2257 - val_f1: 0.0625\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4476 - accuracy: 0.2461 - f1: 0.0815 - val_loss: 2.5731 - val_accuracy: 0.2254 - val_f1: 0.0656\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m4= CreateMultiPerceptron(4,100,100,0.0005,4,\"../music/music/tagged_feature_sets/msd-jmirspectral_dev/msd-jmirspectral_dev.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m4.to_json()\n",
    "with open(\"m4.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m4.save_weights(\"m4.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.8625 - accuracy: 0.1366 - f1: 2.7384e-04 - val_loss: 2.7619 - val_accuracy: 0.1625 - val_f1: 0.0012\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.7149 - accuracy: 0.1771 - f1: 0.0072 - val_loss: 2.7013 - val_accuracy: 0.1802 - val_f1: 0.0068\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6593 - accuracy: 0.1941 - f1: 0.0236 - val_loss: 2.6695 - val_accuracy: 0.1925 - val_f1: 0.0395\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.6294 - accuracy: 0.2016 - f1: 0.0341 - val_loss: 2.6168 - val_accuracy: 0.2058 - val_f1: 0.0318\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6105 - accuracy: 0.2079 - f1: 0.0400 - val_loss: 2.6128 - val_accuracy: 0.2034 - val_f1: 0.0485\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5978 - accuracy: 0.2105 - f1: 0.0442 - val_loss: 2.5809 - val_accuracy: 0.2153 - val_f1: 0.0366\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.5852 - accuracy: 0.2147 - f1: 0.0476 - val_loss: 2.5812 - val_accuracy: 0.2146 - val_f1: 0.0477\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.5708 - accuracy: 0.2186 - f1: 0.0523 - val_loss: 2.5617 - val_accuracy: 0.2211 - val_f1: 0.0445\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5621 - accuracy: 0.2198 - f1: 0.0536 - val_loss: 2.6211 - val_accuracy: 0.2111 - val_f1: 0.0485\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.5545 - accuracy: 0.2229 - f1: 0.0561 - val_loss: 2.5986 - val_accuracy: 0.2117 - val_f1: 0.0607\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5438 - accuracy: 0.2255 - f1: 0.0581 - val_loss: 2.5774 - val_accuracy: 0.2241 - val_f1: 0.0543\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5358 - accuracy: 0.2280 - f1: 0.0610 - val_loss: 2.5401 - val_accuracy: 0.2284 - val_f1: 0.0574\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.5291 - accuracy: 0.2304 - f1: 0.0623 - val_loss: 2.5856 - val_accuracy: 0.2165 - val_f1: 0.0783\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.5245 - accuracy: 0.2303 - f1: 0.0635 - val_loss: 2.5940 - val_accuracy: 0.2149 - val_f1: 0.0631\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.5166 - accuracy: 0.2337 - f1: 0.0661 - val_loss: 2.5437 - val_accuracy: 0.2197 - val_f1: 0.0460\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5082 - accuracy: 0.2361 - f1: 0.0660 - val_loss: 2.5217 - val_accuracy: 0.2320 - val_f1: 0.0566\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5025 - accuracy: 0.2381 - f1: 0.0691 - val_loss: 2.5547 - val_accuracy: 0.2297 - val_f1: 0.0674\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4970 - accuracy: 0.2388 - f1: 0.0694 - val_loss: 2.5036 - val_accuracy: 0.2379 - val_f1: 0.0577\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4898 - accuracy: 0.2407 - f1: 0.0717 - val_loss: 2.5500 - val_accuracy: 0.2256 - val_f1: 0.0765\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4889 - accuracy: 0.2412 - f1: 0.0724 - val_loss: 2.5658 - val_accuracy: 0.2245 - val_f1: 0.0633\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4836 - accuracy: 0.2417 - f1: 0.0740 - val_loss: 2.4996 - val_accuracy: 0.2414 - val_f1: 0.0667\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4784 - accuracy: 0.2438 - f1: 0.0753 - val_loss: 2.5047 - val_accuracy: 0.2370 - val_f1: 0.0839\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4738 - accuracy: 0.2443 - f1: 0.0754 - val_loss: 2.4906 - val_accuracy: 0.2412 - val_f1: 0.0736\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4694 - accuracy: 0.2450 - f1: 0.0790 - val_loss: 2.5316 - val_accuracy: 0.2299 - val_f1: 0.0896\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4648 - accuracy: 0.2482 - f1: 0.0796 - val_loss: 2.5549 - val_accuracy: 0.2277 - val_f1: 0.0571\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4633 - accuracy: 0.2481 - f1: 0.0802 - val_loss: 2.4896 - val_accuracy: 0.2438 - val_f1: 0.0663\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4575 - accuracy: 0.2493 - f1: 0.0817 - val_loss: 2.5156 - val_accuracy: 0.2346 - val_f1: 0.0720\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4535 - accuracy: 0.2504 - f1: 0.0819 - val_loss: 2.5060 - val_accuracy: 0.2401 - val_f1: 0.0621\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4506 - accuracy: 0.2503 - f1: 0.0824 - val_loss: 2.5034 - val_accuracy: 0.2393 - val_f1: 0.0799\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4473 - accuracy: 0.2509 - f1: 0.0838 - val_loss: 2.5049 - val_accuracy: 0.2389 - val_f1: 0.0799\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4409 - accuracy: 0.2541 - f1: 0.0865 - val_loss: 2.5061 - val_accuracy: 0.2342 - val_f1: 0.0552\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4378 - accuracy: 0.2555 - f1: 0.0860 - val_loss: 2.4765 - val_accuracy: 0.2464 - val_f1: 0.0708\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4357 - accuracy: 0.2552 - f1: 0.0880 - val_loss: 2.4970 - val_accuracy: 0.2417 - val_f1: 0.0782\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4334 - accuracy: 0.2560 - f1: 0.0882 - val_loss: 2.4887 - val_accuracy: 0.2427 - val_f1: 0.0749\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4297 - accuracy: 0.2567 - f1: 0.0897 - val_loss: 2.4835 - val_accuracy: 0.2465 - val_f1: 0.0886\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4258 - accuracy: 0.2582 - f1: 0.0907 - val_loss: 2.4811 - val_accuracy: 0.2469 - val_f1: 0.0901\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4238 - accuracy: 0.2592 - f1: 0.0908 - val_loss: 2.5605 - val_accuracy: 0.2252 - val_f1: 0.0878\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4211 - accuracy: 0.2597 - f1: 0.0926 - val_loss: 2.4984 - val_accuracy: 0.2455 - val_f1: 0.0810\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4172 - accuracy: 0.2607 - f1: 0.0926 - val_loss: 2.5185 - val_accuracy: 0.2370 - val_f1: 0.0725\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4140 - accuracy: 0.2614 - f1: 0.0943 - val_loss: 2.4885 - val_accuracy: 0.2441 - val_f1: 0.1047\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4127 - accuracy: 0.2612 - f1: 0.0954 - val_loss: 2.5086 - val_accuracy: 0.2404 - val_f1: 0.0922\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4101 - accuracy: 0.2639 - f1: 0.0956 - val_loss: 2.5052 - val_accuracy: 0.2422 - val_f1: 0.0810\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.4077 - accuracy: 0.2626 - f1: 0.0975 - val_loss: 2.4946 - val_accuracy: 0.2425 - val_f1: 0.0672\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4039 - accuracy: 0.2637 - f1: 0.0978 - val_loss: 2.5080 - val_accuracy: 0.2397 - val_f1: 0.0675\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3984 - accuracy: 0.2647 - f1: 0.0997 - val_loss: 2.4895 - val_accuracy: 0.2495 - val_f1: 0.0882\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3984 - accuracy: 0.2666 - f1: 0.1006 - val_loss: 2.4975 - val_accuracy: 0.2440 - val_f1: 0.0816\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3979 - accuracy: 0.2655 - f1: 0.1028 - val_loss: 2.5110 - val_accuracy: 0.2429 - val_f1: 0.0892\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3912 - accuracy: 0.2669 - f1: 0.1030 - val_loss: 2.4923 - val_accuracy: 0.2475 - val_f1: 0.0890\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3937 - accuracy: 0.2669 - f1: 0.1015 - val_loss: 2.4796 - val_accuracy: 0.2492 - val_f1: 0.0882\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3903 - accuracy: 0.2676 - f1: 0.1026 - val_loss: 2.4944 - val_accuracy: 0.2445 - val_f1: 0.0827\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3869 - accuracy: 0.2686 - f1: 0.1042 - val_loss: 2.5261 - val_accuracy: 0.2384 - val_f1: 0.0906\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3839 - accuracy: 0.2689 - f1: 0.1044 - val_loss: 2.4944 - val_accuracy: 0.2448 - val_f1: 0.0885\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3856 - accuracy: 0.2694 - f1: 0.1052 - val_loss: 2.4983 - val_accuracy: 0.2454 - val_f1: 0.0981\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3810 - accuracy: 0.2709 - f1: 0.1061 - val_loss: 2.4968 - val_accuracy: 0.2473 - val_f1: 0.1061\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3772 - accuracy: 0.2711 - f1: 0.1084 - val_loss: 2.4922 - val_accuracy: 0.2473 - val_f1: 0.1062\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3770 - accuracy: 0.2714 - f1: 0.1083 - val_loss: 2.5019 - val_accuracy: 0.2455 - val_f1: 0.0841\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3734 - accuracy: 0.2725 - f1: 0.1084 - val_loss: 2.4934 - val_accuracy: 0.2448 - val_f1: 0.0941\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3705 - accuracy: 0.2725 - f1: 0.1109 - val_loss: 2.4939 - val_accuracy: 0.2462 - val_f1: 0.0945\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3714 - accuracy: 0.2723 - f1: 0.1109 - val_loss: 2.5303 - val_accuracy: 0.2421 - val_f1: 0.1081\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3688 - accuracy: 0.2734 - f1: 0.1102 - val_loss: 2.4809 - val_accuracy: 0.2482 - val_f1: 0.0952\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3644 - accuracy: 0.2746 - f1: 0.1118 - val_loss: 2.5029 - val_accuracy: 0.2449 - val_f1: 0.0941\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3644 - accuracy: 0.2745 - f1: 0.1124 - val_loss: 2.4935 - val_accuracy: 0.2479 - val_f1: 0.0924\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3635 - accuracy: 0.2752 - f1: 0.1123 - val_loss: 2.5084 - val_accuracy: 0.2470 - val_f1: 0.0962\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3592 - accuracy: 0.2755 - f1: 0.1153 - val_loss: 2.5242 - val_accuracy: 0.2391 - val_f1: 0.0852\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3587 - accuracy: 0.2762 - f1: 0.1144 - val_loss: 2.5031 - val_accuracy: 0.2452 - val_f1: 0.0992\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3550 - accuracy: 0.2767 - f1: 0.1160 - val_loss: 2.5158 - val_accuracy: 0.2371 - val_f1: 0.0884\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3553 - accuracy: 0.2762 - f1: 0.1167 - val_loss: 2.5495 - val_accuracy: 0.2364 - val_f1: 0.1115\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3540 - accuracy: 0.2781 - f1: 0.1157 - val_loss: 2.4981 - val_accuracy: 0.2470 - val_f1: 0.0938\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3513 - accuracy: 0.2763 - f1: 0.1190 - val_loss: 2.4940 - val_accuracy: 0.2486 - val_f1: 0.1015\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3482 - accuracy: 0.2792 - f1: 0.1172 - val_loss: 2.5122 - val_accuracy: 0.2459 - val_f1: 0.1011\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3465 - accuracy: 0.2803 - f1: 0.1189 - val_loss: 2.5112 - val_accuracy: 0.2426 - val_f1: 0.1047\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3461 - accuracy: 0.2801 - f1: 0.1195 - val_loss: 2.5081 - val_accuracy: 0.2447 - val_f1: 0.1044\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3459 - accuracy: 0.2810 - f1: 0.1204 - val_loss: 2.5073 - val_accuracy: 0.2475 - val_f1: 0.0978\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3423 - accuracy: 0.2789 - f1: 0.1213 - val_loss: 2.5231 - val_accuracy: 0.2418 - val_f1: 0.0840\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3419 - accuracy: 0.2811 - f1: 0.1208 - val_loss: 2.5107 - val_accuracy: 0.2433 - val_f1: 0.0904\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3409 - accuracy: 0.2817 - f1: 0.1226 - val_loss: 2.5254 - val_accuracy: 0.2418 - val_f1: 0.0993\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3376 - accuracy: 0.2808 - f1: 0.1223 - val_loss: 2.5385 - val_accuracy: 0.2399 - val_f1: 0.1158\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3388 - accuracy: 0.2817 - f1: 0.1224 - val_loss: 2.5083 - val_accuracy: 0.2428 - val_f1: 0.0975\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3375 - accuracy: 0.2821 - f1: 0.1252 - val_loss: 2.5075 - val_accuracy: 0.2437 - val_f1: 0.0806\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3343 - accuracy: 0.2827 - f1: 0.1244 - val_loss: 2.5191 - val_accuracy: 0.2422 - val_f1: 0.0916\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3335 - accuracy: 0.2820 - f1: 0.1239 - val_loss: 2.5369 - val_accuracy: 0.2369 - val_f1: 0.0932\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3325 - accuracy: 0.2839 - f1: 0.1237 - val_loss: 2.5268 - val_accuracy: 0.2414 - val_f1: 0.1056\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3303 - accuracy: 0.2839 - f1: 0.1252 - val_loss: 2.5118 - val_accuracy: 0.2456 - val_f1: 0.1061\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3287 - accuracy: 0.2841 - f1: 0.1261 - val_loss: 2.5489 - val_accuracy: 0.2355 - val_f1: 0.0795\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3300 - accuracy: 0.2837 - f1: 0.1271 - val_loss: 2.5097 - val_accuracy: 0.2417 - val_f1: 0.0966\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3286 - accuracy: 0.2838 - f1: 0.1260 - val_loss: 2.5037 - val_accuracy: 0.2463 - val_f1: 0.0997\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3272 - accuracy: 0.2848 - f1: 0.1268 - val_loss: 2.5115 - val_accuracy: 0.2436 - val_f1: 0.0923\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3245 - accuracy: 0.2855 - f1: 0.1287 - val_loss: 2.5120 - val_accuracy: 0.2475 - val_f1: 0.1024\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3232 - accuracy: 0.2850 - f1: 0.1283 - val_loss: 2.5094 - val_accuracy: 0.2444 - val_f1: 0.0948\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3188 - accuracy: 0.2866 - f1: 0.1302 - val_loss: 2.5166 - val_accuracy: 0.2422 - val_f1: 0.1044\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3220 - accuracy: 0.2867 - f1: 0.1286 - val_loss: 2.5438 - val_accuracy: 0.2416 - val_f1: 0.1075\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3188 - accuracy: 0.2880 - f1: 0.1299 - val_loss: 2.5299 - val_accuracy: 0.2391 - val_f1: 0.1027\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3186 - accuracy: 0.2874 - f1: 0.1308 - val_loss: 2.5206 - val_accuracy: 0.2437 - val_f1: 0.1017\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3143 - accuracy: 0.2874 - f1: 0.1320 - val_loss: 2.5131 - val_accuracy: 0.2454 - val_f1: 0.0943\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3167 - accuracy: 0.2869 - f1: 0.1318 - val_loss: 2.5281 - val_accuracy: 0.2417 - val_f1: 0.1101\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3139 - accuracy: 0.2893 - f1: 0.1328 - val_loss: 2.5295 - val_accuracy: 0.2430 - val_f1: 0.1140\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3137 - accuracy: 0.2882 - f1: 0.1331 - val_loss: 2.5514 - val_accuracy: 0.2385 - val_f1: 0.1135\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.3110 - accuracy: 0.2898 - f1: 0.1340 - val_loss: 2.5126 - val_accuracy: 0.2476 - val_f1: 0.1048\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3092 - accuracy: 0.2895 - f1: 0.1354 - val_loss: 2.5332 - val_accuracy: 0.2443 - val_f1: 0.1106\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.3081 - accuracy: 0.2890 - f1: 0.1341 - val_loss: 2.5213 - val_accuracy: 0.2457 - val_f1: 0.1083\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m5= CreateMultiPerceptron(4,100,100,0.0005,5,\"../music/music/tagged_feature_sets/msd-jmirmfccs_dev/msd-jmirmfccs_dev.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m5.to_json()\n",
    "with open(\"m5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m5.save_weights(\"m5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 3.0238 - accuracy: 0.1111 - f1: 0.0206 - val_loss: 2.9846 - val_accuracy: 0.1251 - val_f1: 0.0079\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.9128 - accuracy: 0.1406 - f1: 0.0404 - val_loss: 2.8548 - val_accuracy: 0.1571 - val_f1: 0.0409\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.8467 - accuracy: 0.1574 - f1: 0.0473 - val_loss: 2.9008 - val_accuracy: 0.1434 - val_f1: 0.0218\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.8213 - accuracy: 0.1624 - f1: 0.0505 - val_loss: 2.8396 - val_accuracy: 0.1572 - val_f1: 0.0631\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.8041 - accuracy: 0.1654 - f1: 0.0515 - val_loss: 2.8184 - val_accuracy: 0.1636 - val_f1: 0.0393\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7946 - accuracy: 0.1684 - f1: 0.0515 - val_loss: 2.8295 - val_accuracy: 0.1589 - val_f1: 0.0471\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7881 - accuracy: 0.1689 - f1: 0.0530 - val_loss: 2.7756 - val_accuracy: 0.1731 - val_f1: 0.0438\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7815 - accuracy: 0.1709 - f1: 0.0538 - val_loss: 2.7992 - val_accuracy: 0.1692 - val_f1: 0.0492\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7722 - accuracy: 0.1718 - f1: 0.0548 - val_loss: 2.8072 - val_accuracy: 0.1672 - val_f1: 0.0598\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7679 - accuracy: 0.1733 - f1: 0.0555 - val_loss: 2.8394 - val_accuracy: 0.1598 - val_f1: 0.0550\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7622 - accuracy: 0.1750 - f1: 0.0568 - val_loss: 2.7505 - val_accuracy: 0.1778 - val_f1: 0.0548\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7570 - accuracy: 0.1758 - f1: 0.0572 - val_loss: 2.7710 - val_accuracy: 0.1748 - val_f1: 0.0659\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7495 - accuracy: 0.1778 - f1: 0.0585 - val_loss: 2.8363 - val_accuracy: 0.1643 - val_f1: 0.0426\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7445 - accuracy: 0.1786 - f1: 0.0595 - val_loss: 2.7839 - val_accuracy: 0.1707 - val_f1: 0.0675\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7393 - accuracy: 0.1794 - f1: 0.0594 - val_loss: 2.7319 - val_accuracy: 0.1840 - val_f1: 0.0511\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7315 - accuracy: 0.1821 - f1: 0.0598 - val_loss: 2.7277 - val_accuracy: 0.1838 - val_f1: 0.0572\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7316 - accuracy: 0.1817 - f1: 0.0593 - val_loss: 2.8206 - val_accuracy: 0.1677 - val_f1: 0.0368\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7255 - accuracy: 0.1841 - f1: 0.0600 - val_loss: 2.7567 - val_accuracy: 0.1815 - val_f1: 0.0605\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7195 - accuracy: 0.1842 - f1: 0.0617 - val_loss: 2.7249 - val_accuracy: 0.1851 - val_f1: 0.0649\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7203 - accuracy: 0.1843 - f1: 0.0617 - val_loss: 2.7270 - val_accuracy: 0.1814 - val_f1: 0.0507\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7165 - accuracy: 0.1850 - f1: 0.0628 - val_loss: 2.7499 - val_accuracy: 0.1779 - val_f1: 0.0611\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7090 - accuracy: 0.1870 - f1: 0.0634 - val_loss: 2.7291 - val_accuracy: 0.1859 - val_f1: 0.0490\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7063 - accuracy: 0.1876 - f1: 0.0636 - val_loss: 2.7600 - val_accuracy: 0.1773 - val_f1: 0.0667\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7024 - accuracy: 0.1879 - f1: 0.0641 - val_loss: 2.6911 - val_accuracy: 0.1905 - val_f1: 0.0713\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7001 - accuracy: 0.1885 - f1: 0.0638 - val_loss: 2.7018 - val_accuracy: 0.1919 - val_f1: 0.0581\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6997 - accuracy: 0.1880 - f1: 0.0646 - val_loss: 2.7065 - val_accuracy: 0.1891 - val_f1: 0.0618\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6928 - accuracy: 0.1912 - f1: 0.0642 - val_loss: 2.7162 - val_accuracy: 0.1860 - val_f1: 0.0765\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6953 - accuracy: 0.1889 - f1: 0.0659 - val_loss: 2.8222 - val_accuracy: 0.1679 - val_f1: 0.0529\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.6902 - accuracy: 0.1908 - f1: 0.0658 - val_loss: 2.7095 - val_accuracy: 0.1859 - val_f1: 0.0618\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6895 - accuracy: 0.1911 - f1: 0.0650 - val_loss: 2.7356 - val_accuracy: 0.1797 - val_f1: 0.0446\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6870 - accuracy: 0.1904 - f1: 0.0650 - val_loss: 2.7092 - val_accuracy: 0.1866 - val_f1: 0.0659\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6881 - accuracy: 0.1911 - f1: 0.0654 - val_loss: 2.6899 - val_accuracy: 0.1906 - val_f1: 0.0632\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 5s 40us/step - loss: 2.6834 - accuracy: 0.1924 - f1: 0.0667 - val_loss: 2.7211 - val_accuracy: 0.1847 - val_f1: 0.0706\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 5s 48us/step - loss: 2.6825 - accuracy: 0.1945 - f1: 0.0656 - val_loss: 2.6923 - val_accuracy: 0.1934 - val_f1: 0.0748\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 6s 50us/step - loss: 2.6804 - accuracy: 0.1926 - f1: 0.0678 - val_loss: 2.7099 - val_accuracy: 0.1875 - val_f1: 0.0538\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 5s 42us/step - loss: 2.6778 - accuracy: 0.1940 - f1: 0.0675 - val_loss: 2.6984 - val_accuracy: 0.1906 - val_f1: 0.0654\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 5s 44us/step - loss: 2.6788 - accuracy: 0.1930 - f1: 0.0666 - val_loss: 2.7816 - val_accuracy: 0.1766 - val_f1: 0.0706\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 4s 39us/step - loss: 2.6760 - accuracy: 0.1939 - f1: 0.0673 - val_loss: 2.7142 - val_accuracy: 0.1897 - val_f1: 0.0626\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 6s 51us/step - loss: 2.6733 - accuracy: 0.1928 - f1: 0.0675 - val_loss: 2.6919 - val_accuracy: 0.1913 - val_f1: 0.0662\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 5s 44us/step - loss: 2.6708 - accuracy: 0.1943 - f1: 0.0684 - val_loss: 2.7233 - val_accuracy: 0.1879 - val_f1: 0.0662\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 5s 46us/step - loss: 2.6701 - accuracy: 0.1944 - f1: 0.0681 - val_loss: 2.7129 - val_accuracy: 0.1897 - val_f1: 0.0764\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 5s 43us/step - loss: 2.6628 - accuracy: 0.1968 - f1: 0.0696 - val_loss: 2.6919 - val_accuracy: 0.1937 - val_f1: 0.0630\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.6642 - accuracy: 0.1961 - f1: 0.0694 - val_loss: 2.6867 - val_accuracy: 0.1955 - val_f1: 0.0620\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 5s 46us/step - loss: 2.6645 - accuracy: 0.1961 - f1: 0.0690 - val_loss: 2.6834 - val_accuracy: 0.1925 - val_f1: 0.0733\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 5s 42us/step - loss: 2.6599 - accuracy: 0.1974 - f1: 0.0697 - val_loss: 2.7333 - val_accuracy: 0.1856 - val_f1: 0.0677\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6615 - accuracy: 0.1968 - f1: 0.0698 - val_loss: 2.7118 - val_accuracy: 0.1880 - val_f1: 0.0628\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6576 - accuracy: 0.1987 - f1: 0.0698 - val_loss: 2.7155 - val_accuracy: 0.1901 - val_f1: 0.0763\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6585 - accuracy: 0.1979 - f1: 0.0704 - val_loss: 2.6870 - val_accuracy: 0.1936 - val_f1: 0.0658\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6576 - accuracy: 0.1978 - f1: 0.0704 - val_loss: 2.7059 - val_accuracy: 0.1851 - val_f1: 0.0790\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6570 - accuracy: 0.1980 - f1: 0.0698 - val_loss: 2.7119 - val_accuracy: 0.1864 - val_f1: 0.0665\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 5s 46us/step - loss: 2.6534 - accuracy: 0.1997 - f1: 0.0701 - val_loss: 2.6862 - val_accuracy: 0.1939 - val_f1: 0.0777\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 5s 39us/step - loss: 2.6545 - accuracy: 0.1984 - f1: 0.0702 - val_loss: 2.6915 - val_accuracy: 0.1943 - val_f1: 0.0630\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6487 - accuracy: 0.1999 - f1: 0.0718 - val_loss: 2.7359 - val_accuracy: 0.1862 - val_f1: 0.0719\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 5s 40us/step - loss: 2.6505 - accuracy: 0.1995 - f1: 0.0704 - val_loss: 2.6904 - val_accuracy: 0.1940 - val_f1: 0.0683\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 5s 43us/step - loss: 2.6473 - accuracy: 0.2004 - f1: 0.0722 - val_loss: 2.6871 - val_accuracy: 0.1941 - val_f1: 0.0611\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6441 - accuracy: 0.2017 - f1: 0.0722 - val_loss: 2.6797 - val_accuracy: 0.1959 - val_f1: 0.0680\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.6448 - accuracy: 0.2024 - f1: 0.0714 - val_loss: 2.6900 - val_accuracy: 0.1936 - val_f1: 0.0853\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6432 - accuracy: 0.2014 - f1: 0.0722 - val_loss: 2.7054 - val_accuracy: 0.1923 - val_f1: 0.0790\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6439 - accuracy: 0.2004 - f1: 0.0723 - val_loss: 2.6922 - val_accuracy: 0.1946 - val_f1: 0.0792\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6411 - accuracy: 0.2026 - f1: 0.0727 - val_loss: 2.7128 - val_accuracy: 0.1894 - val_f1: 0.0722\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6383 - accuracy: 0.2025 - f1: 0.0731 - val_loss: 2.6968 - val_accuracy: 0.1926 - val_f1: 0.0803\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6387 - accuracy: 0.2024 - f1: 0.0739 - val_loss: 2.6860 - val_accuracy: 0.1958 - val_f1: 0.0746\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.6401 - accuracy: 0.2028 - f1: 0.0729 - val_loss: 2.7340 - val_accuracy: 0.1845 - val_f1: 0.0768\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.6350 - accuracy: 0.2031 - f1: 0.0742 - val_loss: 2.7074 - val_accuracy: 0.1896 - val_f1: 0.0744\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6326 - accuracy: 0.2044 - f1: 0.0743 - val_loss: 2.7087 - val_accuracy: 0.1920 - val_f1: 0.0711\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 5s 40us/step - loss: 2.6330 - accuracy: 0.2030 - f1: 0.0741 - val_loss: 2.6918 - val_accuracy: 0.1921 - val_f1: 0.0705\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6295 - accuracy: 0.2049 - f1: 0.0741 - val_loss: 2.7051 - val_accuracy: 0.1904 - val_f1: 0.0787\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6284 - accuracy: 0.2055 - f1: 0.0749 - val_loss: 2.6886 - val_accuracy: 0.1951 - val_f1: 0.0650\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6276 - accuracy: 0.2051 - f1: 0.0746 - val_loss: 2.7166 - val_accuracy: 0.1923 - val_f1: 0.0700\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6273 - accuracy: 0.2056 - f1: 0.0751 - val_loss: 2.7484 - val_accuracy: 0.1827 - val_f1: 0.0693\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6249 - accuracy: 0.2052 - f1: 0.0754 - val_loss: 2.7096 - val_accuracy: 0.1895 - val_f1: 0.0621\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6237 - accuracy: 0.2062 - f1: 0.0752 - val_loss: 2.6833 - val_accuracy: 0.1957 - val_f1: 0.0656\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6238 - accuracy: 0.2065 - f1: 0.0759 - val_loss: 2.6819 - val_accuracy: 0.1960 - val_f1: 0.0700\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6233 - accuracy: 0.2067 - f1: 0.0764 - val_loss: 2.6857 - val_accuracy: 0.1968 - val_f1: 0.0651\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6220 - accuracy: 0.2057 - f1: 0.0764 - val_loss: 2.7107 - val_accuracy: 0.1882 - val_f1: 0.0684\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6209 - accuracy: 0.2052 - f1: 0.0761 - val_loss: 2.7587 - val_accuracy: 0.1834 - val_f1: 0.0773\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6223 - accuracy: 0.2063 - f1: 0.0771 - val_loss: 2.7011 - val_accuracy: 0.1893 - val_f1: 0.0585\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 4s 34us/step - loss: 2.6180 - accuracy: 0.2077 - f1: 0.0771 - val_loss: 2.7120 - val_accuracy: 0.1917 - val_f1: 0.0755\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6204 - accuracy: 0.2079 - f1: 0.0777 - val_loss: 2.7222 - val_accuracy: 0.1899 - val_f1: 0.0684\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6170 - accuracy: 0.2078 - f1: 0.0766 - val_loss: 2.7167 - val_accuracy: 0.1896 - val_f1: 0.0782\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6161 - accuracy: 0.2089 - f1: 0.0771 - val_loss: 2.7190 - val_accuracy: 0.1925 - val_f1: 0.0762\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6155 - accuracy: 0.2072 - f1: 0.0776 - val_loss: 2.6829 - val_accuracy: 0.1984 - val_f1: 0.0779\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6141 - accuracy: 0.2077 - f1: 0.0783 - val_loss: 2.7037 - val_accuracy: 0.1913 - val_f1: 0.0675\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6126 - accuracy: 0.2085 - f1: 0.0782 - val_loss: 2.6888 - val_accuracy: 0.1971 - val_f1: 0.0801\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6117 - accuracy: 0.2098 - f1: 0.0783 - val_loss: 2.7359 - val_accuracy: 0.1881 - val_f1: 0.0658\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6080 - accuracy: 0.2108 - f1: 0.0794 - val_loss: 2.6841 - val_accuracy: 0.1973 - val_f1: 0.0683\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6131 - accuracy: 0.2087 - f1: 0.0795 - val_loss: 2.6851 - val_accuracy: 0.1970 - val_f1: 0.0730\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6062 - accuracy: 0.2103 - f1: 0.0790 - val_loss: 2.6969 - val_accuracy: 0.1922 - val_f1: 0.0692\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6095 - accuracy: 0.2099 - f1: 0.0788 - val_loss: 2.6802 - val_accuracy: 0.1968 - val_f1: 0.0682\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6061 - accuracy: 0.2100 - f1: 0.0791 - val_loss: 2.7022 - val_accuracy: 0.1951 - val_f1: 0.0816\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.6042 - accuracy: 0.2107 - f1: 0.0787 - val_loss: 2.6919 - val_accuracy: 0.1950 - val_f1: 0.0708\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6033 - accuracy: 0.2110 - f1: 0.0798 - val_loss: 2.6983 - val_accuracy: 0.1947 - val_f1: 0.0698\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6050 - accuracy: 0.2099 - f1: 0.0800 - val_loss: 2.6910 - val_accuracy: 0.1972 - val_f1: 0.0771\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.6020 - accuracy: 0.2103 - f1: 0.0808 - val_loss: 2.6920 - val_accuracy: 0.1929 - val_f1: 0.0742\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6028 - accuracy: 0.2122 - f1: 0.0800 - val_loss: 2.7014 - val_accuracy: 0.1931 - val_f1: 0.0717\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5965 - accuracy: 0.2131 - f1: 0.0816 - val_loss: 2.7313 - val_accuracy: 0.1874 - val_f1: 0.0624\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6024 - accuracy: 0.2119 - f1: 0.0805 - val_loss: 2.7101 - val_accuracy: 0.1888 - val_f1: 0.0584\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.5978 - accuracy: 0.2121 - f1: 0.0807 - val_loss: 2.7639 - val_accuracy: 0.1846 - val_f1: 0.0645\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5978 - accuracy: 0.2116 - f1: 0.0811 - val_loss: 2.7099 - val_accuracy: 0.1920 - val_f1: 0.0688\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.5990 - accuracy: 0.2112 - f1: 0.0815 - val_loss: 2.7073 - val_accuracy: 0.1912 - val_f1: 0.0701\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m6= CreateMultiPerceptron(4,100,100,0.0005,6,\"../music/music/tagged_feature_sets/msd-trh_dev/msd-trh_dev.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m6.to_json()\n",
    "with open(\"m6.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m6.save_weights(\"m6.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.8038 - accuracy: 0.1599 - f1: 0.0023 - val_loss: 2.7332 - val_accuracy: 0.1771 - val_f1: 0.0119\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.7017 - accuracy: 0.1847 - f1: 0.0104 - val_loss: 2.6965 - val_accuracy: 0.1873 - val_f1: 0.0227\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6736 - accuracy: 0.1922 - f1: 0.0180 - val_loss: 2.6640 - val_accuracy: 0.1966 - val_f1: 0.0145\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.6548 - accuracy: 0.1961 - f1: 0.0225 - val_loss: 2.6568 - val_accuracy: 0.1986 - val_f1: 0.0166\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.6426 - accuracy: 0.2002 - f1: 0.0268 - val_loss: 2.6637 - val_accuracy: 0.1983 - val_f1: 0.0160\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.6309 - accuracy: 0.2042 - f1: 0.0302 - val_loss: 2.6466 - val_accuracy: 0.2010 - val_f1: 0.0303\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6231 - accuracy: 0.2064 - f1: 0.0316 - val_loss: 2.6379 - val_accuracy: 0.2042 - val_f1: 0.0357\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6159 - accuracy: 0.2090 - f1: 0.0345 - val_loss: 2.6309 - val_accuracy: 0.2067 - val_f1: 0.0357\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.6068 - accuracy: 0.2100 - f1: 0.0364 - val_loss: 2.6288 - val_accuracy: 0.2054 - val_f1: 0.0364\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.6016 - accuracy: 0.2126 - f1: 0.0370 - val_loss: 2.6282 - val_accuracy: 0.2058 - val_f1: 0.0343\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5953 - accuracy: 0.2131 - f1: 0.0395 - val_loss: 2.6297 - val_accuracy: 0.2079 - val_f1: 0.0361\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5905 - accuracy: 0.2157 - f1: 0.0403 - val_loss: 2.6180 - val_accuracy: 0.2089 - val_f1: 0.0326\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.5846 - accuracy: 0.2161 - f1: 0.0421 - val_loss: 2.6247 - val_accuracy: 0.2055 - val_f1: 0.0364\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5775 - accuracy: 0.2184 - f1: 0.0433 - val_loss: 2.6212 - val_accuracy: 0.2105 - val_f1: 0.0490\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5738 - accuracy: 0.2195 - f1: 0.0444 - val_loss: 2.6109 - val_accuracy: 0.2085 - val_f1: 0.0466\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5680 - accuracy: 0.2210 - f1: 0.0457 - val_loss: 2.6238 - val_accuracy: 0.2076 - val_f1: 0.0477\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5649 - accuracy: 0.2222 - f1: 0.0471 - val_loss: 2.6119 - val_accuracy: 0.2104 - val_f1: 0.0472\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5604 - accuracy: 0.2227 - f1: 0.0476 - val_loss: 2.6177 - val_accuracy: 0.2085 - val_f1: 0.0420\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5538 - accuracy: 0.2237 - f1: 0.0496 - val_loss: 2.6231 - val_accuracy: 0.2068 - val_f1: 0.0362\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5513 - accuracy: 0.2256 - f1: 0.0495 - val_loss: 2.6112 - val_accuracy: 0.2116 - val_f1: 0.0518\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5473 - accuracy: 0.2264 - f1: 0.0508 - val_loss: 2.6104 - val_accuracy: 0.2107 - val_f1: 0.0398\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5434 - accuracy: 0.2271 - f1: 0.0515 - val_loss: 2.6109 - val_accuracy: 0.2100 - val_f1: 0.0558\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5392 - accuracy: 0.2272 - f1: 0.0526 - val_loss: 2.6160 - val_accuracy: 0.2100 - val_f1: 0.0401\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5355 - accuracy: 0.2288 - f1: 0.0532 - val_loss: 2.6124 - val_accuracy: 0.2088 - val_f1: 0.0445\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5311 - accuracy: 0.2310 - f1: 0.0548 - val_loss: 2.6140 - val_accuracy: 0.2114 - val_f1: 0.0469\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5281 - accuracy: 0.2315 - f1: 0.0555 - val_loss: 2.6153 - val_accuracy: 0.2084 - val_f1: 0.0474\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5238 - accuracy: 0.2335 - f1: 0.0569 - val_loss: 2.6138 - val_accuracy: 0.2123 - val_f1: 0.0613\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5198 - accuracy: 0.2327 - f1: 0.0574 - val_loss: 2.6169 - val_accuracy: 0.2097 - val_f1: 0.0473\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5172 - accuracy: 0.2329 - f1: 0.0592 - val_loss: 2.6125 - val_accuracy: 0.2103 - val_f1: 0.0472\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5122 - accuracy: 0.2359 - f1: 0.0588 - val_loss: 2.6165 - val_accuracy: 0.2124 - val_f1: 0.0570\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5083 - accuracy: 0.2365 - f1: 0.0617 - val_loss: 2.6208 - val_accuracy: 0.2099 - val_f1: 0.0679\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.5070 - accuracy: 0.2357 - f1: 0.0609 - val_loss: 2.6190 - val_accuracy: 0.2129 - val_f1: 0.0545\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.5026 - accuracy: 0.2383 - f1: 0.0628 - val_loss: 2.6177 - val_accuracy: 0.2116 - val_f1: 0.0535\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4992 - accuracy: 0.2384 - f1: 0.0621 - val_loss: 2.6242 - val_accuracy: 0.2069 - val_f1: 0.0517\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4963 - accuracy: 0.2398 - f1: 0.0637 - val_loss: 2.6290 - val_accuracy: 0.2106 - val_f1: 0.0584\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4919 - accuracy: 0.2405 - f1: 0.0647 - val_loss: 2.6243 - val_accuracy: 0.2103 - val_f1: 0.0465\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4895 - accuracy: 0.2410 - f1: 0.0646 - val_loss: 2.6261 - val_accuracy: 0.2090 - val_f1: 0.0663\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4869 - accuracy: 0.2425 - f1: 0.0661 - val_loss: 2.6238 - val_accuracy: 0.2114 - val_f1: 0.0564\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4841 - accuracy: 0.2429 - f1: 0.0673 - val_loss: 2.6385 - val_accuracy: 0.2076 - val_f1: 0.0635\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4809 - accuracy: 0.2433 - f1: 0.0689 - val_loss: 2.6321 - val_accuracy: 0.2111 - val_f1: 0.0748\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4782 - accuracy: 0.2454 - f1: 0.0678 - val_loss: 2.6384 - val_accuracy: 0.2090 - val_f1: 0.0624\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4752 - accuracy: 0.2448 - f1: 0.0691 - val_loss: 2.6303 - val_accuracy: 0.2113 - val_f1: 0.0556\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4734 - accuracy: 0.2468 - f1: 0.0709 - val_loss: 2.6356 - val_accuracy: 0.2130 - val_f1: 0.0725\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4692 - accuracy: 0.2464 - f1: 0.0700 - val_loss: 2.6364 - val_accuracy: 0.2102 - val_f1: 0.0656\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4677 - accuracy: 0.2467 - f1: 0.0719 - val_loss: 2.6417 - val_accuracy: 0.2119 - val_f1: 0.0635\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4650 - accuracy: 0.2471 - f1: 0.0730 - val_loss: 2.6466 - val_accuracy: 0.2106 - val_f1: 0.0587\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4613 - accuracy: 0.2495 - f1: 0.0732 - val_loss: 2.6367 - val_accuracy: 0.2092 - val_f1: 0.0628\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4598 - accuracy: 0.2506 - f1: 0.0739 - val_loss: 2.6413 - val_accuracy: 0.2124 - val_f1: 0.0754\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4582 - accuracy: 0.2491 - f1: 0.0756 - val_loss: 2.6492 - val_accuracy: 0.2076 - val_f1: 0.0614\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4546 - accuracy: 0.2508 - f1: 0.0763 - val_loss: 2.6460 - val_accuracy: 0.2114 - val_f1: 0.0570\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4527 - accuracy: 0.2510 - f1: 0.0765 - val_loss: 2.6406 - val_accuracy: 0.2076 - val_f1: 0.0507\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4494 - accuracy: 0.2520 - f1: 0.0770 - val_loss: 2.6500 - val_accuracy: 0.2104 - val_f1: 0.0731\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4455 - accuracy: 0.2541 - f1: 0.0776 - val_loss: 2.6547 - val_accuracy: 0.2080 - val_f1: 0.0662\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4461 - accuracy: 0.2526 - f1: 0.0781 - val_loss: 2.6508 - val_accuracy: 0.2106 - val_f1: 0.0622\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4433 - accuracy: 0.2532 - f1: 0.0790 - val_loss: 2.6516 - val_accuracy: 0.2092 - val_f1: 0.0576\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4395 - accuracy: 0.2556 - f1: 0.0803 - val_loss: 2.6567 - val_accuracy: 0.2088 - val_f1: 0.0701\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4405 - accuracy: 0.2549 - f1: 0.0801 - val_loss: 2.6549 - val_accuracy: 0.2108 - val_f1: 0.0657\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4363 - accuracy: 0.2567 - f1: 0.0809 - val_loss: 2.6640 - val_accuracy: 0.2102 - val_f1: 0.0690\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4345 - accuracy: 0.2564 - f1: 0.0808 - val_loss: 2.6629 - val_accuracy: 0.2085 - val_f1: 0.0673\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4304 - accuracy: 0.2581 - f1: 0.0840 - val_loss: 2.6535 - val_accuracy: 0.2099 - val_f1: 0.0683\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4298 - accuracy: 0.2570 - f1: 0.0827 - val_loss: 2.6534 - val_accuracy: 0.2111 - val_f1: 0.0679\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4289 - accuracy: 0.2577 - f1: 0.0830 - val_loss: 2.6782 - val_accuracy: 0.2086 - val_f1: 0.0732\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.4267 - accuracy: 0.2595 - f1: 0.0846 - val_loss: 2.6680 - val_accuracy: 0.2067 - val_f1: 0.0715\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4251 - accuracy: 0.2595 - f1: 0.0851 - val_loss: 2.6730 - val_accuracy: 0.2082 - val_f1: 0.0736\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4225 - accuracy: 0.2585 - f1: 0.0846 - val_loss: 2.6741 - val_accuracy: 0.2061 - val_f1: 0.0639\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 5s 39us/step - loss: 2.4200 - accuracy: 0.2595 - f1: 0.0865 - val_loss: 2.6699 - val_accuracy: 0.2110 - val_f1: 0.0696\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.4185 - accuracy: 0.2601 - f1: 0.0872 - val_loss: 2.6726 - val_accuracy: 0.2059 - val_f1: 0.0679\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4173 - accuracy: 0.2620 - f1: 0.0868 - val_loss: 2.6773 - val_accuracy: 0.2055 - val_f1: 0.0664\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4155 - accuracy: 0.2612 - f1: 0.0885 - val_loss: 2.6676 - val_accuracy: 0.2075 - val_f1: 0.0720\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4129 - accuracy: 0.2618 - f1: 0.0902 - val_loss: 2.6755 - val_accuracy: 0.2057 - val_f1: 0.0593\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4115 - accuracy: 0.2618 - f1: 0.0897 - val_loss: 2.6746 - val_accuracy: 0.2080 - val_f1: 0.0654\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.4094 - accuracy: 0.2626 - f1: 0.0905 - val_loss: 2.6720 - val_accuracy: 0.2098 - val_f1: 0.0742\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.4084 - accuracy: 0.2636 - f1: 0.0905 - val_loss: 2.6821 - val_accuracy: 0.2080 - val_f1: 0.0729\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 2s 22us/step - loss: 2.4057 - accuracy: 0.2638 - f1: 0.0922 - val_loss: 2.6840 - val_accuracy: 0.2059 - val_f1: 0.0681\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4038 - accuracy: 0.2650 - f1: 0.0931 - val_loss: 2.6825 - val_accuracy: 0.2080 - val_f1: 0.0663\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4022 - accuracy: 0.2660 - f1: 0.0935 - val_loss: 2.6843 - val_accuracy: 0.2060 - val_f1: 0.0667\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4016 - accuracy: 0.2648 - f1: 0.0921 - val_loss: 2.6888 - val_accuracy: 0.2021 - val_f1: 0.0713\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.4009 - accuracy: 0.2637 - f1: 0.0945 - val_loss: 2.6873 - val_accuracy: 0.2078 - val_f1: 0.0741\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 23us/step - loss: 2.3976 - accuracy: 0.2662 - f1: 0.0958 - val_loss: 2.6896 - val_accuracy: 0.2065 - val_f1: 0.0726\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.3971 - accuracy: 0.2664 - f1: 0.0939 - val_loss: 2.7027 - val_accuracy: 0.2056 - val_f1: 0.0683\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3946 - accuracy: 0.2678 - f1: 0.0962 - val_loss: 2.6970 - val_accuracy: 0.2068 - val_f1: 0.0679\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3932 - accuracy: 0.2669 - f1: 0.0964 - val_loss: 2.7000 - val_accuracy: 0.2015 - val_f1: 0.0739\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3932 - accuracy: 0.2670 - f1: 0.0975 - val_loss: 2.7067 - val_accuracy: 0.2092 - val_f1: 0.0792\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.3910 - accuracy: 0.2673 - f1: 0.0970 - val_loss: 2.6972 - val_accuracy: 0.2047 - val_f1: 0.0662\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3881 - accuracy: 0.2677 - f1: 0.0983 - val_loss: 2.7116 - val_accuracy: 0.2039 - val_f1: 0.0706\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.3885 - accuracy: 0.2672 - f1: 0.0989 - val_loss: 2.7097 - val_accuracy: 0.2033 - val_f1: 0.0761\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.3874 - accuracy: 0.2685 - f1: 0.1006 - val_loss: 2.6984 - val_accuracy: 0.2053 - val_f1: 0.0639\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3855 - accuracy: 0.2695 - f1: 0.1008 - val_loss: 2.7084 - val_accuracy: 0.2063 - val_f1: 0.0888\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.3840 - accuracy: 0.2692 - f1: 0.1007 - val_loss: 2.7173 - val_accuracy: 0.2060 - val_f1: 0.0671\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3832 - accuracy: 0.2689 - f1: 0.1011 - val_loss: 2.7193 - val_accuracy: 0.2063 - val_f1: 0.0765\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3813 - accuracy: 0.2704 - f1: 0.1012 - val_loss: 2.7083 - val_accuracy: 0.2040 - val_f1: 0.0672\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.3798 - accuracy: 0.2702 - f1: 0.1024 - val_loss: 2.7082 - val_accuracy: 0.2030 - val_f1: 0.0651\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3795 - accuracy: 0.2705 - f1: 0.1029 - val_loss: 2.7316 - val_accuracy: 0.2020 - val_f1: 0.0692\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3776 - accuracy: 0.2711 - f1: 0.1031 - val_loss: 2.7238 - val_accuracy: 0.2017 - val_f1: 0.0722\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.3764 - accuracy: 0.2697 - f1: 0.1032 - val_loss: 2.7117 - val_accuracy: 0.2043 - val_f1: 0.0669\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3761 - accuracy: 0.2703 - f1: 0.1047 - val_loss: 2.7171 - val_accuracy: 0.2062 - val_f1: 0.0607\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3749 - accuracy: 0.2714 - f1: 0.1053 - val_loss: 2.7172 - val_accuracy: 0.2066 - val_f1: 0.0689\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3727 - accuracy: 0.2728 - f1: 0.1053 - val_loss: 2.7204 - val_accuracy: 0.2057 - val_f1: 0.0674\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 2s 21us/step - loss: 2.3717 - accuracy: 0.2728 - f1: 0.1052 - val_loss: 2.7300 - val_accuracy: 0.2053 - val_f1: 0.0690\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 22us/step - loss: 2.3704 - accuracy: 0.2725 - f1: 0.1065 - val_loss: 2.7349 - val_accuracy: 0.2023 - val_f1: 0.0656\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m7= CreateMultiPerceptron(4,100,100,0.0005,7,\"../music/music/tagged_feature_sets/msd-jmirlpc_dev/msd-jmirlpc_dev.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m7.to_json()\n",
    "with open(\"m7.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m7.save_weights(\"m7.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 25us/step - loss: 2.9891 - accuracy: 0.1227 - f1: 0.0270 - val_loss: 2.9551 - val_accuracy: 0.1318 - val_f1: 0.0298\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 26us/step - loss: 2.8826 - accuracy: 0.1495 - f1: 0.0418 - val_loss: 2.8320 - val_accuracy: 0.1633 - val_f1: 0.0435\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 24us/step - loss: 2.8146 - accuracy: 0.1650 - f1: 0.0501 - val_loss: 2.8076 - val_accuracy: 0.1635 - val_f1: 0.0465\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7872 - accuracy: 0.1698 - f1: 0.0528 - val_loss: 2.9267 - val_accuracy: 0.1468 - val_f1: 0.0527\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7703 - accuracy: 0.1735 - f1: 0.0542 - val_loss: 2.8352 - val_accuracy: 0.1579 - val_f1: 0.0381\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 4s 39us/step - loss: 2.7644 - accuracy: 0.1751 - f1: 0.0562 - val_loss: 2.7741 - val_accuracy: 0.1742 - val_f1: 0.0580\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 4s 36us/step - loss: 2.7508 - accuracy: 0.1791 - f1: 0.0571 - val_loss: 2.7838 - val_accuracy: 0.1725 - val_f1: 0.0409\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 5s 41us/step - loss: 2.7413 - accuracy: 0.1795 - f1: 0.0579 - val_loss: 2.7427 - val_accuracy: 0.1821 - val_f1: 0.0510\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 4s 39us/step - loss: 2.7369 - accuracy: 0.1817 - f1: 0.0590 - val_loss: 2.7355 - val_accuracy: 0.1801 - val_f1: 0.0544\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 5s 41us/step - loss: 2.7304 - accuracy: 0.1813 - f1: 0.0604 - val_loss: 2.7573 - val_accuracy: 0.1741 - val_f1: 0.0518\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 4s 37us/step - loss: 2.7261 - accuracy: 0.1830 - f1: 0.0599 - val_loss: 2.7378 - val_accuracy: 0.1775 - val_f1: 0.0500\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 4s 33us/step - loss: 2.7196 - accuracy: 0.1841 - f1: 0.0609 - val_loss: 2.7213 - val_accuracy: 0.1848 - val_f1: 0.0619\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 5s 40us/step - loss: 2.7154 - accuracy: 0.1857 - f1: 0.0610 - val_loss: 2.7156 - val_accuracy: 0.1843 - val_f1: 0.0564\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.7151 - accuracy: 0.1861 - f1: 0.0622 - val_loss: 2.7253 - val_accuracy: 0.1838 - val_f1: 0.0602\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 4s 32us/step - loss: 2.7089 - accuracy: 0.1875 - f1: 0.0635 - val_loss: 2.7548 - val_accuracy: 0.1785 - val_f1: 0.0566\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.7087 - accuracy: 0.1860 - f1: 0.0629 - val_loss: 2.7407 - val_accuracy: 0.1801 - val_f1: 0.0570\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.7022 - accuracy: 0.1892 - f1: 0.0642 - val_loss: 2.7235 - val_accuracy: 0.1847 - val_f1: 0.0592\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.7054 - accuracy: 0.1893 - f1: 0.0640 - val_loss: 2.7303 - val_accuracy: 0.1824 - val_f1: 0.0536\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.7006 - accuracy: 0.1893 - f1: 0.0654 - val_loss: 2.7156 - val_accuracy: 0.1864 - val_f1: 0.0529\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6929 - accuracy: 0.1909 - f1: 0.0661 - val_loss: 2.7058 - val_accuracy: 0.1846 - val_f1: 0.0535\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.6898 - accuracy: 0.1923 - f1: 0.0668 - val_loss: 2.7442 - val_accuracy: 0.1787 - val_f1: 0.0528\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6880 - accuracy: 0.1932 - f1: 0.0666 - val_loss: 2.6992 - val_accuracy: 0.1904 - val_f1: 0.0731\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6865 - accuracy: 0.1925 - f1: 0.0677 - val_loss: 2.7318 - val_accuracy: 0.1817 - val_f1: 0.0632\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6866 - accuracy: 0.1920 - f1: 0.0671 - val_loss: 2.7278 - val_accuracy: 0.1825 - val_f1: 0.0666\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6787 - accuracy: 0.1947 - f1: 0.0687 - val_loss: 2.7728 - val_accuracy: 0.1734 - val_f1: 0.0617\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6813 - accuracy: 0.1937 - f1: 0.0670 - val_loss: 2.7036 - val_accuracy: 0.1889 - val_f1: 0.0644\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6750 - accuracy: 0.1947 - f1: 0.0689 - val_loss: 2.8549 - val_accuracy: 0.1615 - val_f1: 0.0518\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6747 - accuracy: 0.1959 - f1: 0.0694 - val_loss: 2.7264 - val_accuracy: 0.1839 - val_f1: 0.0621\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6721 - accuracy: 0.1958 - f1: 0.0701 - val_loss: 2.7073 - val_accuracy: 0.1847 - val_f1: 0.0604\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6679 - accuracy: 0.1971 - f1: 0.0707 - val_loss: 2.6941 - val_accuracy: 0.1914 - val_f1: 0.0542\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6654 - accuracy: 0.1979 - f1: 0.0714 - val_loss: 2.7386 - val_accuracy: 0.1789 - val_f1: 0.0630\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6621 - accuracy: 0.1991 - f1: 0.0720 - val_loss: 2.6933 - val_accuracy: 0.1901 - val_f1: 0.0622\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6620 - accuracy: 0.1973 - f1: 0.0717 - val_loss: 2.7742 - val_accuracy: 0.1751 - val_f1: 0.0605\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6584 - accuracy: 0.1995 - f1: 0.0720 - val_loss: 2.7032 - val_accuracy: 0.1852 - val_f1: 0.0596\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6551 - accuracy: 0.2001 - f1: 0.0735 - val_loss: 2.7164 - val_accuracy: 0.1875 - val_f1: 0.0747\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6550 - accuracy: 0.1999 - f1: 0.0732 - val_loss: 2.7238 - val_accuracy: 0.1877 - val_f1: 0.0718\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6517 - accuracy: 0.2009 - f1: 0.0734 - val_loss: 2.7065 - val_accuracy: 0.1885 - val_f1: 0.0660\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6487 - accuracy: 0.2005 - f1: 0.0737 - val_loss: 2.6970 - val_accuracy: 0.1898 - val_f1: 0.0581\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6487 - accuracy: 0.2006 - f1: 0.0740 - val_loss: 2.7124 - val_accuracy: 0.1866 - val_f1: 0.0641\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.6484 - accuracy: 0.2006 - f1: 0.0742 - val_loss: 2.7028 - val_accuracy: 0.1876 - val_f1: 0.0672\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6441 - accuracy: 0.2043 - f1: 0.0744 - val_loss: 2.7022 - val_accuracy: 0.1859 - val_f1: 0.0549\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6439 - accuracy: 0.2030 - f1: 0.0751 - val_loss: 2.7041 - val_accuracy: 0.1896 - val_f1: 0.0641\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.6411 - accuracy: 0.2032 - f1: 0.0754 - val_loss: 2.6912 - val_accuracy: 0.1911 - val_f1: 0.0656\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6380 - accuracy: 0.2040 - f1: 0.0758 - val_loss: 2.6926 - val_accuracy: 0.1892 - val_f1: 0.0634\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 4s 35us/step - loss: 2.6330 - accuracy: 0.2060 - f1: 0.0772 - val_loss: 2.6973 - val_accuracy: 0.1873 - val_f1: 0.0653\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6339 - accuracy: 0.2053 - f1: 0.0772 - val_loss: 2.6928 - val_accuracy: 0.1919 - val_f1: 0.0656\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6320 - accuracy: 0.2048 - f1: 0.0769 - val_loss: 2.7211 - val_accuracy: 0.1852 - val_f1: 0.0558\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.6298 - accuracy: 0.2052 - f1: 0.0779 - val_loss: 2.6991 - val_accuracy: 0.1912 - val_f1: 0.0692\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6287 - accuracy: 0.2056 - f1: 0.0775 - val_loss: 2.6986 - val_accuracy: 0.1912 - val_f1: 0.0698\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.6252 - accuracy: 0.2077 - f1: 0.0785 - val_loss: 2.7035 - val_accuracy: 0.1913 - val_f1: 0.0766\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6277 - accuracy: 0.2056 - f1: 0.0786 - val_loss: 2.7095 - val_accuracy: 0.1865 - val_f1: 0.0643\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6213 - accuracy: 0.2083 - f1: 0.0786 - val_loss: 2.6959 - val_accuracy: 0.1913 - val_f1: 0.0701\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6237 - accuracy: 0.2069 - f1: 0.0791 - val_loss: 2.6957 - val_accuracy: 0.1913 - val_f1: 0.0665\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6194 - accuracy: 0.2086 - f1: 0.0803 - val_loss: 2.7077 - val_accuracy: 0.1905 - val_f1: 0.0607\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.6167 - accuracy: 0.2088 - f1: 0.0807 - val_loss: 2.7079 - val_accuracy: 0.1896 - val_f1: 0.0718\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6218 - accuracy: 0.2067 - f1: 0.0808 - val_loss: 2.7045 - val_accuracy: 0.1885 - val_f1: 0.0641\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6141 - accuracy: 0.2107 - f1: 0.0806 - val_loss: 2.7237 - val_accuracy: 0.1900 - val_f1: 0.0706\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6136 - accuracy: 0.2101 - f1: 0.0814 - val_loss: 2.7199 - val_accuracy: 0.1849 - val_f1: 0.0650\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6135 - accuracy: 0.2087 - f1: 0.0811 - val_loss: 2.7236 - val_accuracy: 0.1847 - val_f1: 0.0606\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6110 - accuracy: 0.2104 - f1: 0.0813 - val_loss: 2.7051 - val_accuracy: 0.1927 - val_f1: 0.0698\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6089 - accuracy: 0.2120 - f1: 0.0822 - val_loss: 2.7337 - val_accuracy: 0.1832 - val_f1: 0.0708\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6094 - accuracy: 0.2111 - f1: 0.0814 - val_loss: 2.7037 - val_accuracy: 0.1901 - val_f1: 0.0784\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6051 - accuracy: 0.2124 - f1: 0.0821 - val_loss: 2.7073 - val_accuracy: 0.1878 - val_f1: 0.0684\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6039 - accuracy: 0.2120 - f1: 0.0830 - val_loss: 2.6984 - val_accuracy: 0.1915 - val_f1: 0.0709\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6032 - accuracy: 0.2129 - f1: 0.0839 - val_loss: 2.7088 - val_accuracy: 0.1908 - val_f1: 0.0711\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6004 - accuracy: 0.2127 - f1: 0.0837 - val_loss: 2.6965 - val_accuracy: 0.1924 - val_f1: 0.0690\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5998 - accuracy: 0.2120 - f1: 0.0855 - val_loss: 2.7397 - val_accuracy: 0.1818 - val_f1: 0.0629\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5999 - accuracy: 0.2123 - f1: 0.0847 - val_loss: 2.7569 - val_accuracy: 0.1803 - val_f1: 0.0671\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5991 - accuracy: 0.2119 - f1: 0.0852 - val_loss: 2.7128 - val_accuracy: 0.1868 - val_f1: 0.0587\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5937 - accuracy: 0.2154 - f1: 0.0859 - val_loss: 2.7163 - val_accuracy: 0.1890 - val_f1: 0.0651\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5913 - accuracy: 0.2155 - f1: 0.0860 - val_loss: 2.7036 - val_accuracy: 0.1918 - val_f1: 0.0669\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5905 - accuracy: 0.2141 - f1: 0.0870 - val_loss: 2.7280 - val_accuracy: 0.1893 - val_f1: 0.0736\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5943 - accuracy: 0.2139 - f1: 0.0863 - val_loss: 2.7862 - val_accuracy: 0.1714 - val_f1: 0.0671\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5880 - accuracy: 0.2150 - f1: 0.0872 - val_loss: 2.7090 - val_accuracy: 0.1898 - val_f1: 0.0720\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5887 - accuracy: 0.2159 - f1: 0.0879 - val_loss: 2.7606 - val_accuracy: 0.1744 - val_f1: 0.0490\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5863 - accuracy: 0.2165 - f1: 0.0882 - val_loss: 2.7193 - val_accuracy: 0.1853 - val_f1: 0.0633\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5846 - accuracy: 0.2174 - f1: 0.0882 - val_loss: 2.7136 - val_accuracy: 0.1898 - val_f1: 0.0703\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5835 - accuracy: 0.2179 - f1: 0.0877 - val_loss: 2.7370 - val_accuracy: 0.1827 - val_f1: 0.0638\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5849 - accuracy: 0.2173 - f1: 0.0890 - val_loss: 2.7192 - val_accuracy: 0.1892 - val_f1: 0.0633\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5822 - accuracy: 0.2166 - f1: 0.0901 - val_loss: 2.7146 - val_accuracy: 0.1893 - val_f1: 0.0644\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5803 - accuracy: 0.2180 - f1: 0.0891 - val_loss: 2.7553 - val_accuracy: 0.1841 - val_f1: 0.0707\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5786 - accuracy: 0.2188 - f1: 0.0900 - val_loss: 2.7256 - val_accuracy: 0.1856 - val_f1: 0.0638\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5787 - accuracy: 0.2182 - f1: 0.0903 - val_loss: 2.7469 - val_accuracy: 0.1876 - val_f1: 0.0783\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5799 - accuracy: 0.2191 - f1: 0.0900 - val_loss: 2.7386 - val_accuracy: 0.1877 - val_f1: 0.0768\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5718 - accuracy: 0.2208 - f1: 0.0917 - val_loss: 2.7255 - val_accuracy: 0.1850 - val_f1: 0.0664\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5765 - accuracy: 0.2195 - f1: 0.0905 - val_loss: 2.7151 - val_accuracy: 0.1884 - val_f1: 0.0695\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5716 - accuracy: 0.2198 - f1: 0.0921 - val_loss: 2.7265 - val_accuracy: 0.1874 - val_f1: 0.0684\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5696 - accuracy: 0.2204 - f1: 0.0916 - val_loss: 2.7301 - val_accuracy: 0.1859 - val_f1: 0.0762\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5725 - accuracy: 0.2204 - f1: 0.0929 - val_loss: 2.7248 - val_accuracy: 0.1885 - val_f1: 0.0652\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5689 - accuracy: 0.2211 - f1: 0.0923 - val_loss: 2.7244 - val_accuracy: 0.1897 - val_f1: 0.0661\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5659 - accuracy: 0.2219 - f1: 0.0930 - val_loss: 2.7354 - val_accuracy: 0.1880 - val_f1: 0.0744\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5664 - accuracy: 0.2220 - f1: 0.0934 - val_loss: 2.7204 - val_accuracy: 0.1919 - val_f1: 0.0738\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5654 - accuracy: 0.2220 - f1: 0.0934 - val_loss: 2.7235 - val_accuracy: 0.1871 - val_f1: 0.0692\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.5670 - accuracy: 0.2223 - f1: 0.0944 - val_loss: 2.7522 - val_accuracy: 0.1860 - val_f1: 0.0739\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5627 - accuracy: 0.2223 - f1: 0.0958 - val_loss: 2.7198 - val_accuracy: 0.1930 - val_f1: 0.0801\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 27us/step - loss: 2.5643 - accuracy: 0.2209 - f1: 0.0951 - val_loss: 2.7307 - val_accuracy: 0.1855 - val_f1: 0.0685\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5603 - accuracy: 0.2228 - f1: 0.0944 - val_loss: 2.7705 - val_accuracy: 0.1826 - val_f1: 0.0770\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5605 - accuracy: 0.2217 - f1: 0.0950 - val_loss: 2.7354 - val_accuracy: 0.1896 - val_f1: 0.0778\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5623 - accuracy: 0.2233 - f1: 0.0959 - val_loss: 2.7343 - val_accuracy: 0.1875 - val_f1: 0.0756\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5587 - accuracy: 0.2234 - f1: 0.0962 - val_loss: 2.7282 - val_accuracy: 0.1882 - val_f1: 0.0721\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m8= CreateMultiPerceptron(4,100,100,0.0005,8,\"../music/music/tagged_feature_sets/msd-rh_dev_new/msd-rh_dev_new.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m8.to_json()\n",
    "with open(\"m8.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m8.save_weights(\"m8.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.8122 - accuracy: 0.1488 - f1: 0.0055 - val_loss: 2.6909 - val_accuracy: 0.1752 - val_f1: 0.0027\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.6794 - accuracy: 0.1800 - f1: 0.0168 - val_loss: 2.6355 - val_accuracy: 0.1861 - val_f1: 0.0190\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.6370 - accuracy: 0.1918 - f1: 0.0271 - val_loss: 2.6796 - val_accuracy: 0.1866 - val_f1: 0.0102\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.6124 - accuracy: 0.2001 - f1: 0.0320 - val_loss: 2.6029 - val_accuracy: 0.1978 - val_f1: 0.0347\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.6040 - accuracy: 0.2006 - f1: 0.0331 - val_loss: 2.6010 - val_accuracy: 0.2011 - val_f1: 0.0149\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5909 - accuracy: 0.2035 - f1: 0.0364 - val_loss: 2.6242 - val_accuracy: 0.1917 - val_f1: 0.0458\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5797 - accuracy: 0.2072 - f1: 0.0411 - val_loss: 2.5778 - val_accuracy: 0.2043 - val_f1: 0.0467\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5734 - accuracy: 0.2091 - f1: 0.0419 - val_loss: 2.5889 - val_accuracy: 0.2012 - val_f1: 0.0542\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5627 - accuracy: 0.2109 - f1: 0.0447 - val_loss: 2.5979 - val_accuracy: 0.1972 - val_f1: 0.0279\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5549 - accuracy: 0.2136 - f1: 0.0467 - val_loss: 2.5572 - val_accuracy: 0.2126 - val_f1: 0.0462\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5486 - accuracy: 0.2168 - f1: 0.0485 - val_loss: 2.5468 - val_accuracy: 0.2158 - val_f1: 0.0607\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.5426 - accuracy: 0.2177 - f1: 0.0504 - val_loss: 2.5508 - val_accuracy: 0.2118 - val_f1: 0.0433\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5346 - accuracy: 0.2199 - f1: 0.0540 - val_loss: 2.5285 - val_accuracy: 0.2232 - val_f1: 0.0396\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5287 - accuracy: 0.2220 - f1: 0.0543 - val_loss: 2.5601 - val_accuracy: 0.2099 - val_f1: 0.0448\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5261 - accuracy: 0.2217 - f1: 0.0546 - val_loss: 2.5407 - val_accuracy: 0.2169 - val_f1: 0.0457\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5172 - accuracy: 0.2255 - f1: 0.0573 - val_loss: 2.5864 - val_accuracy: 0.2066 - val_f1: 0.0612\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5151 - accuracy: 0.2248 - f1: 0.0573 - val_loss: 2.5483 - val_accuracy: 0.2172 - val_f1: 0.0470\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5107 - accuracy: 0.2266 - f1: 0.0594 - val_loss: 2.5203 - val_accuracy: 0.2259 - val_f1: 0.0567\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5056 - accuracy: 0.2273 - f1: 0.0608 - val_loss: 2.5341 - val_accuracy: 0.2171 - val_f1: 0.0657\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.5058 - accuracy: 0.2292 - f1: 0.0637 - val_loss: 2.5518 - val_accuracy: 0.2121 - val_f1: 0.0436\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.4973 - accuracy: 0.2311 - f1: 0.0639 - val_loss: 2.5338 - val_accuracy: 0.2202 - val_f1: 0.0755\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4942 - accuracy: 0.2318 - f1: 0.0640 - val_loss: 2.5200 - val_accuracy: 0.2228 - val_f1: 0.0495\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4883 - accuracy: 0.2327 - f1: 0.0656 - val_loss: 2.5184 - val_accuracy: 0.2214 - val_f1: 0.0645\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4886 - accuracy: 0.2328 - f1: 0.0669 - val_loss: 2.5798 - val_accuracy: 0.2088 - val_f1: 0.0507\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.4817 - accuracy: 0.2354 - f1: 0.0678 - val_loss: 2.5426 - val_accuracy: 0.2151 - val_f1: 0.0386\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4751 - accuracy: 0.2372 - f1: 0.0704 - val_loss: 2.5045 - val_accuracy: 0.2272 - val_f1: 0.0585\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4740 - accuracy: 0.2373 - f1: 0.0710 - val_loss: 2.5399 - val_accuracy: 0.2206 - val_f1: 0.0512\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4707 - accuracy: 0.2394 - f1: 0.0709 - val_loss: 2.5205 - val_accuracy: 0.2249 - val_f1: 0.0668\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4679 - accuracy: 0.2400 - f1: 0.0729 - val_loss: 2.5815 - val_accuracy: 0.2120 - val_f1: 0.0689\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4634 - accuracy: 0.2394 - f1: 0.0740 - val_loss: 2.5087 - val_accuracy: 0.2240 - val_f1: 0.0668\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4626 - accuracy: 0.2400 - f1: 0.0752 - val_loss: 2.5163 - val_accuracy: 0.2240 - val_f1: 0.0641\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4602 - accuracy: 0.2412 - f1: 0.0754 - val_loss: 2.5206 - val_accuracy: 0.2253 - val_f1: 0.0816\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4552 - accuracy: 0.2426 - f1: 0.0779 - val_loss: 2.5034 - val_accuracy: 0.2279 - val_f1: 0.0655\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4536 - accuracy: 0.2423 - f1: 0.0783 - val_loss: 2.4858 - val_accuracy: 0.2323 - val_f1: 0.0744\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4501 - accuracy: 0.2425 - f1: 0.0780 - val_loss: 2.4975 - val_accuracy: 0.2329 - val_f1: 0.0738\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4496 - accuracy: 0.2448 - f1: 0.0784 - val_loss: 2.4943 - val_accuracy: 0.2316 - val_f1: 0.0608\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4442 - accuracy: 0.2458 - f1: 0.0803 - val_loss: 2.5126 - val_accuracy: 0.2280 - val_f1: 0.0633\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4406 - accuracy: 0.2460 - f1: 0.0814 - val_loss: 2.5110 - val_accuracy: 0.2266 - val_f1: 0.0609\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4376 - accuracy: 0.2477 - f1: 0.0820 - val_loss: 2.5365 - val_accuracy: 0.2239 - val_f1: 0.0569\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4403 - accuracy: 0.2466 - f1: 0.0817 - val_loss: 2.5033 - val_accuracy: 0.2320 - val_f1: 0.0824\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4333 - accuracy: 0.2485 - f1: 0.0844 - val_loss: 2.4917 - val_accuracy: 0.2329 - val_f1: 0.0744\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4295 - accuracy: 0.2502 - f1: 0.0832 - val_loss: 2.4934 - val_accuracy: 0.2336 - val_f1: 0.0753\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4293 - accuracy: 0.2511 - f1: 0.0850 - val_loss: 2.5779 - val_accuracy: 0.2149 - val_f1: 0.0687\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4276 - accuracy: 0.2503 - f1: 0.0864 - val_loss: 2.5312 - val_accuracy: 0.2258 - val_f1: 0.0586\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4218 - accuracy: 0.2511 - f1: 0.0868 - val_loss: 2.5465 - val_accuracy: 0.2213 - val_f1: 0.0839\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4191 - accuracy: 0.2512 - f1: 0.0879 - val_loss: 2.5035 - val_accuracy: 0.2297 - val_f1: 0.0748\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4193 - accuracy: 0.2510 - f1: 0.0878 - val_loss: 2.5188 - val_accuracy: 0.2284 - val_f1: 0.0879\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4163 - accuracy: 0.2537 - f1: 0.0885 - val_loss: 2.4911 - val_accuracy: 0.2352 - val_f1: 0.0785\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4134 - accuracy: 0.2550 - f1: 0.0901 - val_loss: 2.4930 - val_accuracy: 0.2356 - val_f1: 0.0806\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4122 - accuracy: 0.2545 - f1: 0.0907 - val_loss: 2.5450 - val_accuracy: 0.2201 - val_f1: 0.0867\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.4099 - accuracy: 0.2552 - f1: 0.0904 - val_loss: 2.4894 - val_accuracy: 0.2331 - val_f1: 0.0895\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4089 - accuracy: 0.2542 - f1: 0.0909 - val_loss: 2.4890 - val_accuracy: 0.2335 - val_f1: 0.0715\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4050 - accuracy: 0.2561 - f1: 0.0924 - val_loss: 2.4923 - val_accuracy: 0.2342 - val_f1: 0.0682\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4049 - accuracy: 0.2566 - f1: 0.0932 - val_loss: 2.5156 - val_accuracy: 0.2331 - val_f1: 0.0958\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.4021 - accuracy: 0.2572 - f1: 0.0922 - val_loss: 2.5794 - val_accuracy: 0.2109 - val_f1: 0.0557\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4001 - accuracy: 0.2574 - f1: 0.0943 - val_loss: 2.5004 - val_accuracy: 0.2330 - val_f1: 0.0833\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3988 - accuracy: 0.2589 - f1: 0.0964 - val_loss: 2.5299 - val_accuracy: 0.2262 - val_f1: 0.0886\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3958 - accuracy: 0.2582 - f1: 0.0959 - val_loss: 2.5160 - val_accuracy: 0.2300 - val_f1: 0.0888\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3937 - accuracy: 0.2592 - f1: 0.0961 - val_loss: 2.5203 - val_accuracy: 0.2310 - val_f1: 0.0895\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3941 - accuracy: 0.2582 - f1: 0.0963 - val_loss: 2.5192 - val_accuracy: 0.2320 - val_f1: 0.0943\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3894 - accuracy: 0.2604 - f1: 0.0973 - val_loss: 2.5168 - val_accuracy: 0.2307 - val_f1: 0.0912\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3910 - accuracy: 0.2604 - f1: 0.0981 - val_loss: 2.5432 - val_accuracy: 0.2240 - val_f1: 0.0753\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3878 - accuracy: 0.2607 - f1: 0.0990 - val_loss: 2.5109 - val_accuracy: 0.2319 - val_f1: 0.0966\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3844 - accuracy: 0.2607 - f1: 0.0995 - val_loss: 2.4905 - val_accuracy: 0.2355 - val_f1: 0.0790\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3795 - accuracy: 0.2624 - f1: 0.1010 - val_loss: 2.5301 - val_accuracy: 0.2263 - val_f1: 0.0778\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3823 - accuracy: 0.2623 - f1: 0.1014 - val_loss: 2.5192 - val_accuracy: 0.2336 - val_f1: 0.0889\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3817 - accuracy: 0.2627 - f1: 0.1007 - val_loss: 2.5323 - val_accuracy: 0.2290 - val_f1: 0.0783\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3796 - accuracy: 0.2627 - f1: 0.1017 - val_loss: 2.5028 - val_accuracy: 0.2366 - val_f1: 0.0904\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3779 - accuracy: 0.2632 - f1: 0.1022 - val_loss: 2.5477 - val_accuracy: 0.2252 - val_f1: 0.1051\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3782 - accuracy: 0.2622 - f1: 0.1015 - val_loss: 2.5030 - val_accuracy: 0.2365 - val_f1: 0.0837\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3718 - accuracy: 0.2649 - f1: 0.1052 - val_loss: 2.4991 - val_accuracy: 0.2353 - val_f1: 0.0818\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3725 - accuracy: 0.2654 - f1: 0.1032 - val_loss: 2.4945 - val_accuracy: 0.2360 - val_f1: 0.0897\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3691 - accuracy: 0.2650 - f1: 0.1048 - val_loss: 2.4917 - val_accuracy: 0.2367 - val_f1: 0.0897\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3664 - accuracy: 0.2663 - f1: 0.1058 - val_loss: 2.5147 - val_accuracy: 0.2321 - val_f1: 0.0858\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3671 - accuracy: 0.2675 - f1: 0.1068 - val_loss: 2.5230 - val_accuracy: 0.2309 - val_f1: 0.0952\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3648 - accuracy: 0.2663 - f1: 0.1060 - val_loss: 2.5056 - val_accuracy: 0.2358 - val_f1: 0.0810\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3631 - accuracy: 0.2680 - f1: 0.1071 - val_loss: 2.5853 - val_accuracy: 0.2203 - val_f1: 0.1039\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3618 - accuracy: 0.2689 - f1: 0.1097 - val_loss: 2.5006 - val_accuracy: 0.2358 - val_f1: 0.0990\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3595 - accuracy: 0.2687 - f1: 0.1094 - val_loss: 2.5036 - val_accuracy: 0.2363 - val_f1: 0.0835\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3587 - accuracy: 0.2690 - f1: 0.1098 - val_loss: 2.5326 - val_accuracy: 0.2279 - val_f1: 0.0818\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3596 - accuracy: 0.2688 - f1: 0.1085 - val_loss: 2.5230 - val_accuracy: 0.2323 - val_f1: 0.0899\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3589 - accuracy: 0.2696 - f1: 0.1092 - val_loss: 2.5182 - val_accuracy: 0.2328 - val_f1: 0.0825\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3516 - accuracy: 0.2704 - f1: 0.1110 - val_loss: 2.5416 - val_accuracy: 0.2273 - val_f1: 0.0734\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 28us/step - loss: 2.3548 - accuracy: 0.2685 - f1: 0.1110 - val_loss: 2.5345 - val_accuracy: 0.2334 - val_f1: 0.1005\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3531 - accuracy: 0.2712 - f1: 0.1113 - val_loss: 2.5680 - val_accuracy: 0.2210 - val_f1: 0.0653\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3507 - accuracy: 0.2723 - f1: 0.1118 - val_loss: 2.5090 - val_accuracy: 0.2390 - val_f1: 0.1018\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3525 - accuracy: 0.2703 - f1: 0.1122 - val_loss: 2.5023 - val_accuracy: 0.2395 - val_f1: 0.0817\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3496 - accuracy: 0.2710 - f1: 0.1124 - val_loss: 2.5234 - val_accuracy: 0.2341 - val_f1: 0.0794\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3478 - accuracy: 0.2721 - f1: 0.1138 - val_loss: 2.5439 - val_accuracy: 0.2317 - val_f1: 0.0921\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3485 - accuracy: 0.2711 - f1: 0.1128 - val_loss: 2.5310 - val_accuracy: 0.2298 - val_f1: 0.0882\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3428 - accuracy: 0.2736 - f1: 0.1151 - val_loss: 2.5107 - val_accuracy: 0.2368 - val_f1: 0.0916\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3425 - accuracy: 0.2731 - f1: 0.1150 - val_loss: 2.5041 - val_accuracy: 0.2337 - val_f1: 0.0844\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3426 - accuracy: 0.2726 - f1: 0.1153 - val_loss: 2.5337 - val_accuracy: 0.2325 - val_f1: 0.0928\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3447 - accuracy: 0.2736 - f1: 0.1158 - val_loss: 2.5732 - val_accuracy: 0.2197 - val_f1: 0.0910\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3403 - accuracy: 0.2731 - f1: 0.1160 - val_loss: 2.5430 - val_accuracy: 0.2330 - val_f1: 0.0966\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3407 - accuracy: 0.2737 - f1: 0.1164 - val_loss: 2.5292 - val_accuracy: 0.2296 - val_f1: 0.0838\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3383 - accuracy: 0.2748 - f1: 0.1174 - val_loss: 2.5351 - val_accuracy: 0.2313 - val_f1: 0.0887\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3373 - accuracy: 0.2751 - f1: 0.1175 - val_loss: 2.5093 - val_accuracy: 0.2376 - val_f1: 0.0855\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3363 - accuracy: 0.2755 - f1: 0.1181 - val_loss: 2.5352 - val_accuracy: 0.2324 - val_f1: 0.1092\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3338 - accuracy: 0.2764 - f1: 0.1184 - val_loss: 2.5408 - val_accuracy: 0.2329 - val_f1: 0.0990\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut \n",
    "m9= CreateMultiPerceptron(4,100,100,0.0005,9,\"../music/music/tagged_feature_sets/msd-jmirderivatives_dev/msd-jmirderivatives_dev.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m9.to_json()\n",
    "with open(\"m9.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m9.save_weights(\"m9.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114915 samples, validate on 28729 samples\n",
      "Epoch 1/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.6916 - accuracy: 0.1877 - f1: 0.0474 - val_loss: 2.5827 - val_accuracy: 0.2176 - val_f1: 0.0674\n",
      "Epoch 2/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.5410 - accuracy: 0.2265 - f1: 0.0765 - val_loss: 2.4817 - val_accuracy: 0.2429 - val_f1: 0.0977\n",
      "Epoch 3/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4900 - accuracy: 0.2400 - f1: 0.0856 - val_loss: 2.4960 - val_accuracy: 0.2375 - val_f1: 0.0860\n",
      "Epoch 4/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4590 - accuracy: 0.2466 - f1: 0.0929 - val_loss: 2.4501 - val_accuracy: 0.2505 - val_f1: 0.0801\n",
      "Epoch 5/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4406 - accuracy: 0.2536 - f1: 0.0962 - val_loss: 2.4335 - val_accuracy: 0.2535 - val_f1: 0.1113\n",
      "Epoch 6/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4289 - accuracy: 0.2548 - f1: 0.1010 - val_loss: 2.4212 - val_accuracy: 0.2577 - val_f1: 0.1017\n",
      "Epoch 7/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.4140 - accuracy: 0.2574 - f1: 0.1042 - val_loss: 2.3844 - val_accuracy: 0.2661 - val_f1: 0.1060\n",
      "Epoch 8/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.4018 - accuracy: 0.2614 - f1: 0.1086 - val_loss: 2.4445 - val_accuracy: 0.2564 - val_f1: 0.1245\n",
      "Epoch 9/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3928 - accuracy: 0.2645 - f1: 0.1114 - val_loss: 2.3619 - val_accuracy: 0.2738 - val_f1: 0.1164\n",
      "Epoch 10/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3789 - accuracy: 0.2686 - f1: 0.1152 - val_loss: 2.4109 - val_accuracy: 0.2600 - val_f1: 0.0990\n",
      "Epoch 11/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3711 - accuracy: 0.2698 - f1: 0.1163 - val_loss: 2.3934 - val_accuracy: 0.2698 - val_f1: 0.1312\n",
      "Epoch 12/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3657 - accuracy: 0.2722 - f1: 0.1178 - val_loss: 2.3565 - val_accuracy: 0.2745 - val_f1: 0.1231\n",
      "Epoch 13/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3550 - accuracy: 0.2744 - f1: 0.1212 - val_loss: 2.3839 - val_accuracy: 0.2713 - val_f1: 0.1284\n",
      "Epoch 14/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3490 - accuracy: 0.2757 - f1: 0.1241 - val_loss: 2.3513 - val_accuracy: 0.2787 - val_f1: 0.1281\n",
      "Epoch 15/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3437 - accuracy: 0.2775 - f1: 0.1250 - val_loss: 2.3566 - val_accuracy: 0.2754 - val_f1: 0.1193\n",
      "Epoch 16/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3360 - accuracy: 0.2786 - f1: 0.1280 - val_loss: 2.3626 - val_accuracy: 0.2730 - val_f1: 0.1107\n",
      "Epoch 17/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3271 - accuracy: 0.2826 - f1: 0.1308 - val_loss: 2.3546 - val_accuracy: 0.2765 - val_f1: 0.1169\n",
      "Epoch 18/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3230 - accuracy: 0.2835 - f1: 0.1323 - val_loss: 2.3509 - val_accuracy: 0.2754 - val_f1: 0.1299\n",
      "Epoch 19/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3177 - accuracy: 0.2839 - f1: 0.1337 - val_loss: 2.3872 - val_accuracy: 0.2717 - val_f1: 0.1397\n",
      "Epoch 20/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.3125 - accuracy: 0.2866 - f1: 0.1357 - val_loss: 2.3376 - val_accuracy: 0.2844 - val_f1: 0.1342\n",
      "Epoch 21/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.3047 - accuracy: 0.2876 - f1: 0.1382 - val_loss: 2.3457 - val_accuracy: 0.2812 - val_f1: 0.1218\n",
      "Epoch 22/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2996 - accuracy: 0.2911 - f1: 0.1404 - val_loss: 2.3199 - val_accuracy: 0.2871 - val_f1: 0.1363\n",
      "Epoch 23/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2974 - accuracy: 0.2898 - f1: 0.1397 - val_loss: 2.3394 - val_accuracy: 0.2837 - val_f1: 0.1429\n",
      "Epoch 24/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2903 - accuracy: 0.2916 - f1: 0.1434 - val_loss: 2.3374 - val_accuracy: 0.2822 - val_f1: 0.1464\n",
      "Epoch 25/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2820 - accuracy: 0.2945 - f1: 0.1462 - val_loss: 2.3354 - val_accuracy: 0.2824 - val_f1: 0.1415\n",
      "Epoch 26/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2794 - accuracy: 0.2941 - f1: 0.1470 - val_loss: 2.3245 - val_accuracy: 0.2862 - val_f1: 0.1386\n",
      "Epoch 27/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2766 - accuracy: 0.2959 - f1: 0.1473 - val_loss: 2.3373 - val_accuracy: 0.2800 - val_f1: 0.1409\n",
      "Epoch 28/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2696 - accuracy: 0.2986 - f1: 0.1492 - val_loss: 2.3425 - val_accuracy: 0.2853 - val_f1: 0.1578\n",
      "Epoch 29/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2675 - accuracy: 0.2974 - f1: 0.1512 - val_loss: 2.3519 - val_accuracy: 0.2803 - val_f1: 0.1492\n",
      "Epoch 30/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2641 - accuracy: 0.3004 - f1: 0.1526 - val_loss: 2.3193 - val_accuracy: 0.2888 - val_f1: 0.1563\n",
      "Epoch 31/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2573 - accuracy: 0.3000 - f1: 0.1545 - val_loss: 2.3207 - val_accuracy: 0.2890 - val_f1: 0.1565\n",
      "Epoch 32/100\n",
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.2554 - accuracy: 0.3022 - f1: 0.1555 - val_loss: 2.3286 - val_accuracy: 0.2887 - val_f1: 0.1495\n",
      "Epoch 33/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2501 - accuracy: 0.3029 - f1: 0.1569 - val_loss: 2.3408 - val_accuracy: 0.2857 - val_f1: 0.1337\n",
      "Epoch 34/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2469 - accuracy: 0.3033 - f1: 0.1580 - val_loss: 2.3315 - val_accuracy: 0.2888 - val_f1: 0.1438\n",
      "Epoch 35/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2438 - accuracy: 0.3037 - f1: 0.1599 - val_loss: 2.3234 - val_accuracy: 0.2919 - val_f1: 0.1670\n",
      "Epoch 36/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2412 - accuracy: 0.3049 - f1: 0.1616 - val_loss: 2.3547 - val_accuracy: 0.2796 - val_f1: 0.1430\n",
      "Epoch 37/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2349 - accuracy: 0.3054 - f1: 0.1631 - val_loss: 2.3463 - val_accuracy: 0.2834 - val_f1: 0.1555\n",
      "Epoch 38/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2319 - accuracy: 0.3076 - f1: 0.1647 - val_loss: 2.3462 - val_accuracy: 0.2862 - val_f1: 0.1685\n",
      "Epoch 39/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2284 - accuracy: 0.3083 - f1: 0.1652 - val_loss: 2.3316 - val_accuracy: 0.2896 - val_f1: 0.1625\n",
      "Epoch 40/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2286 - accuracy: 0.3066 - f1: 0.1658 - val_loss: 2.3199 - val_accuracy: 0.2920 - val_f1: 0.1577\n",
      "Epoch 41/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2221 - accuracy: 0.3108 - f1: 0.1680 - val_loss: 2.3399 - val_accuracy: 0.2873 - val_f1: 0.1628\n",
      "Epoch 42/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2178 - accuracy: 0.3115 - f1: 0.1690 - val_loss: 2.3587 - val_accuracy: 0.2858 - val_f1: 0.1601\n",
      "Epoch 43/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2166 - accuracy: 0.3103 - f1: 0.1718 - val_loss: 2.3547 - val_accuracy: 0.2852 - val_f1: 0.1553\n",
      "Epoch 44/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.2130 - accuracy: 0.3122 - f1: 0.1711 - val_loss: 2.3441 - val_accuracy: 0.2864 - val_f1: 0.1585\n",
      "Epoch 45/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2124 - accuracy: 0.3124 - f1: 0.1726 - val_loss: 2.3342 - val_accuracy: 0.2901 - val_f1: 0.1704\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 4s 31us/step - loss: 2.2090 - accuracy: 0.3139 - f1: 0.1740 - val_loss: 2.3303 - val_accuracy: 0.2898 - val_f1: 0.1489\n",
      "Epoch 47/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2059 - accuracy: 0.3151 - f1: 0.1757 - val_loss: 2.3378 - val_accuracy: 0.2871 - val_f1: 0.1691\n",
      "Epoch 48/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.2008 - accuracy: 0.3152 - f1: 0.1756 - val_loss: 2.3538 - val_accuracy: 0.2871 - val_f1: 0.1546\n",
      "Epoch 49/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1977 - accuracy: 0.3159 - f1: 0.1783 - val_loss: 2.3276 - val_accuracy: 0.2903 - val_f1: 0.1537\n",
      "Epoch 50/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1983 - accuracy: 0.3154 - f1: 0.1774 - val_loss: 2.3295 - val_accuracy: 0.2879 - val_f1: 0.1559\n",
      "Epoch 51/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1933 - accuracy: 0.3173 - f1: 0.1789 - val_loss: 2.3509 - val_accuracy: 0.2848 - val_f1: 0.1587\n",
      "Epoch 52/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1904 - accuracy: 0.3172 - f1: 0.1798 - val_loss: 2.3301 - val_accuracy: 0.2906 - val_f1: 0.1606\n",
      "Epoch 53/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1903 - accuracy: 0.3168 - f1: 0.1815 - val_loss: 2.3564 - val_accuracy: 0.2849 - val_f1: 0.1609\n",
      "Epoch 54/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1879 - accuracy: 0.3189 - f1: 0.1817 - val_loss: 2.3457 - val_accuracy: 0.2877 - val_f1: 0.1659\n",
      "Epoch 55/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1856 - accuracy: 0.3196 - f1: 0.1824 - val_loss: 2.3411 - val_accuracy: 0.2880 - val_f1: 0.1692\n",
      "Epoch 56/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1857 - accuracy: 0.3191 - f1: 0.1835 - val_loss: 2.3911 - val_accuracy: 0.2852 - val_f1: 0.1685\n",
      "Epoch 57/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1826 - accuracy: 0.3201 - f1: 0.1837 - val_loss: 2.3476 - val_accuracy: 0.2880 - val_f1: 0.1536\n",
      "Epoch 58/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1771 - accuracy: 0.3237 - f1: 0.1856 - val_loss: 2.3601 - val_accuracy: 0.2844 - val_f1: 0.1638\n",
      "Epoch 59/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1769 - accuracy: 0.3220 - f1: 0.1868 - val_loss: 2.3502 - val_accuracy: 0.2873 - val_f1: 0.1575\n",
      "Epoch 60/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1741 - accuracy: 0.3220 - f1: 0.1883 - val_loss: 2.3425 - val_accuracy: 0.2885 - val_f1: 0.1614\n",
      "Epoch 61/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1690 - accuracy: 0.3245 - f1: 0.1902 - val_loss: 2.3514 - val_accuracy: 0.2842 - val_f1: 0.1583\n",
      "Epoch 62/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1665 - accuracy: 0.3245 - f1: 0.1902 - val_loss: 2.3510 - val_accuracy: 0.2872 - val_f1: 0.1617\n",
      "Epoch 63/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1659 - accuracy: 0.3244 - f1: 0.1908 - val_loss: 2.3483 - val_accuracy: 0.2891 - val_f1: 0.1737\n",
      "Epoch 64/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1652 - accuracy: 0.3238 - f1: 0.1918 - val_loss: 2.3535 - val_accuracy: 0.2886 - val_f1: 0.1675\n",
      "Epoch 65/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1634 - accuracy: 0.3256 - f1: 0.1931 - val_loss: 2.3672 - val_accuracy: 0.2823 - val_f1: 0.1663\n",
      "Epoch 66/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1594 - accuracy: 0.3263 - f1: 0.1948 - val_loss: 2.3574 - val_accuracy: 0.2863 - val_f1: 0.1749\n",
      "Epoch 67/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1586 - accuracy: 0.3264 - f1: 0.1954 - val_loss: 2.3512 - val_accuracy: 0.2900 - val_f1: 0.1716\n",
      "Epoch 68/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1592 - accuracy: 0.3261 - f1: 0.1933 - val_loss: 2.3520 - val_accuracy: 0.2888 - val_f1: 0.1676\n",
      "Epoch 69/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1556 - accuracy: 0.3273 - f1: 0.1942 - val_loss: 2.3725 - val_accuracy: 0.2857 - val_f1: 0.1832\n",
      "Epoch 70/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1514 - accuracy: 0.3285 - f1: 0.1989 - val_loss: 2.3798 - val_accuracy: 0.2825 - val_f1: 0.1612\n",
      "Epoch 71/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1546 - accuracy: 0.3272 - f1: 0.1969 - val_loss: 2.3618 - val_accuracy: 0.2869 - val_f1: 0.1689\n",
      "Epoch 72/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1506 - accuracy: 0.3278 - f1: 0.1968 - val_loss: 2.3635 - val_accuracy: 0.2860 - val_f1: 0.1685\n",
      "Epoch 73/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1489 - accuracy: 0.3289 - f1: 0.1997 - val_loss: 2.3747 - val_accuracy: 0.2871 - val_f1: 0.1715\n",
      "Epoch 74/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1466 - accuracy: 0.3298 - f1: 0.2002 - val_loss: 2.3604 - val_accuracy: 0.2862 - val_f1: 0.1704\n",
      "Epoch 75/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1460 - accuracy: 0.3274 - f1: 0.1980 - val_loss: 2.3581 - val_accuracy: 0.2909 - val_f1: 0.1802\n",
      "Epoch 76/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1427 - accuracy: 0.3287 - f1: 0.2014 - val_loss: 2.3758 - val_accuracy: 0.2889 - val_f1: 0.1855\n",
      "Epoch 77/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1442 - accuracy: 0.3292 - f1: 0.2015 - val_loss: 2.4069 - val_accuracy: 0.2794 - val_f1: 0.1699\n",
      "Epoch 78/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1383 - accuracy: 0.3327 - f1: 0.2013 - val_loss: 2.3676 - val_accuracy: 0.2870 - val_f1: 0.1621\n",
      "Epoch 79/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1401 - accuracy: 0.3316 - f1: 0.2012 - val_loss: 2.3586 - val_accuracy: 0.2902 - val_f1: 0.1612\n",
      "Epoch 80/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1395 - accuracy: 0.3309 - f1: 0.2016 - val_loss: 2.3730 - val_accuracy: 0.2903 - val_f1: 0.1772\n",
      "Epoch 81/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1338 - accuracy: 0.3321 - f1: 0.2046 - val_loss: 2.3675 - val_accuracy: 0.2874 - val_f1: 0.1615\n",
      "Epoch 82/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1339 - accuracy: 0.3331 - f1: 0.2051 - val_loss: 2.3666 - val_accuracy: 0.2881 - val_f1: 0.1695\n",
      "Epoch 83/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1371 - accuracy: 0.3338 - f1: 0.2048 - val_loss: 2.3964 - val_accuracy: 0.2767 - val_f1: 0.1634\n",
      "Epoch 84/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1327 - accuracy: 0.3336 - f1: 0.2045 - val_loss: 2.3756 - val_accuracy: 0.2881 - val_f1: 0.1740\n",
      "Epoch 85/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1301 - accuracy: 0.3327 - f1: 0.2059 - val_loss: 2.3828 - val_accuracy: 0.2862 - val_f1: 0.1754\n",
      "Epoch 86/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1288 - accuracy: 0.3356 - f1: 0.2076 - val_loss: 2.3803 - val_accuracy: 0.2869 - val_f1: 0.1755\n",
      "Epoch 87/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1281 - accuracy: 0.3355 - f1: 0.2075 - val_loss: 2.3756 - val_accuracy: 0.2851 - val_f1: 0.1664\n",
      "Epoch 88/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1256 - accuracy: 0.3349 - f1: 0.2078 - val_loss: 2.3867 - val_accuracy: 0.2845 - val_f1: 0.1729\n",
      "Epoch 89/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1231 - accuracy: 0.3355 - f1: 0.2089 - val_loss: 2.3742 - val_accuracy: 0.2882 - val_f1: 0.1667\n",
      "Epoch 90/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1250 - accuracy: 0.3346 - f1: 0.2098 - val_loss: 2.3792 - val_accuracy: 0.2852 - val_f1: 0.1580\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1206 - accuracy: 0.3370 - f1: 0.2099 - val_loss: 2.4039 - val_accuracy: 0.2839 - val_f1: 0.1732\n",
      "Epoch 92/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1192 - accuracy: 0.3388 - f1: 0.2104 - val_loss: 2.3698 - val_accuracy: 0.2895 - val_f1: 0.1639\n",
      "Epoch 93/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1176 - accuracy: 0.3377 - f1: 0.2116 - val_loss: 2.3702 - val_accuracy: 0.2922 - val_f1: 0.1875\n",
      "Epoch 94/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1224 - accuracy: 0.3379 - f1: 0.2093 - val_loss: 2.4228 - val_accuracy: 0.2832 - val_f1: 0.1764\n",
      "Epoch 95/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1140 - accuracy: 0.3392 - f1: 0.2132 - val_loss: 2.4015 - val_accuracy: 0.2809 - val_f1: 0.1761\n",
      "Epoch 96/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1191 - accuracy: 0.3370 - f1: 0.2107 - val_loss: 2.3779 - val_accuracy: 0.2846 - val_f1: 0.1674\n",
      "Epoch 97/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1160 - accuracy: 0.3389 - f1: 0.2121 - val_loss: 2.3679 - val_accuracy: 0.2905 - val_f1: 0.1727\n",
      "Epoch 98/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1118 - accuracy: 0.3391 - f1: 0.2144 - val_loss: 2.3909 - val_accuracy: 0.2856 - val_f1: 0.1691\n",
      "Epoch 99/100\n",
      "114915/114915 [==============================] - 3s 30us/step - loss: 2.1099 - accuracy: 0.3398 - f1: 0.2140 - val_loss: 2.3813 - val_accuracy: 0.2847 - val_f1: 0.1777\n",
      "Epoch 100/100\n",
      "114915/114915 [==============================] - 3s 29us/step - loss: 2.1131 - accuracy: 0.3382 - f1: 0.2136 - val_loss: 2.3744 - val_accuracy: 0.2894 - val_f1: 0.1831\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Avec les paramètres par défaut\n",
    "m10= CreateMultiPerceptron(4,100,100,0.0005,10,\"../music/music/tagged_feature_sets/msd-marsyas_dev_new/msd-marsyas_dev_new.csv\")\n",
    "# serialize model to JSON\n",
    "model_json = m10.to_json()\n",
    "with open(\"m10.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m10.save_weights(\"m10.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrait les données du fichier CSV et créé un jeu de données soit pour la production (paramètre prod = True)\n",
    "# Soit pour des test (paramètre production = False)\n",
    "def DataSet(path, prod):\n",
    "    #Extraire les données des ensembles \n",
    "    dataset = read_csv(path)\n",
    "    \n",
    "    if prod == False:\n",
    "        labels = dataset.loc[:,dataset.columns == (dataset.shape[1]-1)]\n",
    "        labels = labels.to_numpy()\n",
    "        y = []\n",
    "        for e in labels:\n",
    "            y.append(music_class[e[0]])\n",
    "        y = np.array(y)\n",
    "        \n",
    "    ident = dataset.loc[:][1]\n",
    "    dataset = dataset.drop([0,1,(dataset.shape[1]-1)],axis=1)\n",
    "    \n",
    "    X = dataset.to_numpy()\n",
    "    \n",
    "    if prod == False:\n",
    "        X = X[0-100:]\n",
    "        y = y[0-100:]\n",
    "        y_binary = []\n",
    "        for e in y:\n",
    "            y_binary.append(music_class_discrete_to_binary[e])\n",
    "    \n",
    "        y = np.array(y_binary)\n",
    "    \n",
    "    if prod == True:\n",
    "        return X, ident\n",
    "    elif prod == False:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combinaison(X3,X5,X10):\n",
    "    \n",
    "    #On charge les 3 modèles en mémoire \n",
    "        # load json and create model\n",
    "    json_file = open('m3.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    m3 = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    m3.load_weights(\"m3.h5\")\n",
    "    print(\"Loaded model m3 from disk\")\n",
    "\n",
    " \n",
    "        # load json and create model\n",
    "    json_file = open('m5.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    m5 = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    m5.load_weights(\"m5.h5\")\n",
    "    print(\"Loaded model m5 from disk\")\n",
    " \n",
    "        # load json and create model\n",
    "    json_file = open('m10.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    m10 = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    m10.load_weights(\"m10.h5\")\n",
    "    print(\"Loaded model m10 from disk\")\n",
    "   \n",
    "    # Et pour chaque entrée, on récupère leurs prédictions sur les jeux de données spécifiques pour eux\n",
    "    res  =[]\n",
    "    res.append(m1.predict_classes(X1))\n",
    "   \n",
    "    res.append(m3.predict_classes(X3))\n",
    " \n",
    "    res.append(m5.predict_classes(X5))\n",
    "\n",
    "    res.append(m10.predict_classes(X10))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrit les résultats des prédictions dans un fichier CSV\n",
    "def resultsCSV(file, predictions,ident):\n",
    "\n",
    "    with open(file, 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow([\"id\",\"genre\"])\n",
    "        #Parmi toutes les prédictions, on choisi celle qui a le plus d'occurences\n",
    "        for elem in range(0,len(ident)):\n",
    "            predic = []\n",
    "            for e in range(0,len(predictions)):\n",
    "                predic.append(predictions[e][elem])\n",
    "            unique, counts = np.unique(predic, return_counts=True)\n",
    "            i = np.argmax(counts)\n",
    "            # On écrit le style musical ainsi que l'identifiant de la chanson dans le fichier csv\n",
    "            filewriter.writerow([ident[elem],music_class_number_to_text[unique[i]]])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3, y3 = DataSet(\"../music/music/untagged_feature_sets/msd-ssd_test_nolabels/msd-ssd_test_nolabels.csv\",True)\n",
    "X5, y5 = DataSet(\"../music/music/untagged_feature_sets/msd-jmirmfccs_test_nolabels/msd-jmirmfccs_test_nolabels.csv\",True)\n",
    "X10, y10 = DataSet(\"../music/music/untagged_feature_sets/msd-marsyas_test_new_nolabels/msd-marsyas_test_new_nolabels.csv\",True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model m3 from disk\n",
      "Loaded model m5 from disk\n",
      "Loaded model m10 from disk\n"
     ]
    }
   ],
   "source": [
    "predictions = combinaison(X3,X5,X10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsCSV(\"results.csv\", predictions,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
