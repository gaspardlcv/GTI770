{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 2 - KNN, NAIVE BAYES, DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "start = \"\\033[1m\"\n",
    "end = \"\\033[0;0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to drop Cabin\n",
    "#titanic.drop(\"Cabin\",axis=1,inplace=True)\n",
    "# function to get the data frame from csv\n",
    "def read_csv(url):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        url (string): the url of the file\n",
    "    Returns:\n",
    "        df: the dataframe filled\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes(X_train,Y_train,X_test,Y_test) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train (list): the train sample\n",
    "        X_test (list): the test sample\n",
    "        Y_train (list): the train output\n",
    "        Y_test (list): the test output\n",
    "    Returns:\n",
    "        clf: the naive bayes model\n",
    "    \"\"\"\n",
    "    clf  = BernoulliNB()\n",
    "    clf1 = GaussianNB()\n",
    "    clf2 = MultinomialNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Accuracy with training set \" + str(clf.score(X_test, Y_test)))\n",
    "    y_true = Y_test\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"F1 score with training set \" + str(f1_score(y_true, y_pred,average=\"weighted\")))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingAccuracyAndFscoreKNN(X_train,X_test,y_train,y_test):\n",
    "    accuracyArray = []\n",
    "    fscoreArray = []\n",
    "    best=0\n",
    "    bestAcc=0\n",
    "    for x in range(1,51):\n",
    "        knn = KNeighborsClassifier(n_neighbors = x)\n",
    "        knn.fit(X_train,y_train)\n",
    "        #accuracy\n",
    "        accuracyArray.append(knn.score(X_test,y_test))\n",
    "        #f1 score\n",
    "        y_true = y_test\n",
    "        y_pred = knn.predict(X_test)\n",
    "        fscoreArray.append(f1_score(y_true,y_pred,average=\"weighted\"))\n",
    "        if accuracyArray[x-1] >= bestAcc:\n",
    "            best = x\n",
    "    \n",
    "    print(\"Accuracy with training set \" + str(accuracyArray[best-1]))\n",
    "    print(\"F1 score with training set \" + str(fscoreArray[best-1]))\n",
    "    knn = KNeighborsClassifier(n_neighbors = best)\n",
    "    knn.fit(X_train,y_train)\n",
    "    return knn, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingPretreatments(model,galaxy,X_train,X_test,y_train,y_test):\n",
    "    col_names =  ['Accuracy', 'F1 score']\n",
    "    Results = pd.DataFrame(columns = col_names)\n",
    "    y_true = y_test\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "    score = model.score(X_test, y_test)\n",
    "    Results.loc[\"Aucun prétraitement\"] = [score , f1]\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "    X_test_minmax = min_max_scaler.fit_transform(X_test)\n",
    "    model.fit(X_train_minmax,y_train)\n",
    "    y_pred = model.predict(X_test_minmax)\n",
    "    f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "    score = model.score(X_test_minmax, y_test)\n",
    "    Results.loc[\"MinMaxScaler\"] = [score , f1]\n",
    "    \n",
    "    if galaxy == False:\n",
    "        enc = KBinsDiscretizer(n_bins=5,encode='ordinal')\n",
    "        X_train_binned = enc.fit_transform(X_train)\n",
    "        X_test_binned = enc.fit_transform(X_test)\n",
    "        y_pred = model.predict(X_test_binned)\n",
    "        model.fit(X_train_binned,y_train)\n",
    "        f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "        score = model.score(X_test_binned, y_test)\n",
    "        Results.loc[\"Discrétisation non-supervisée\"] = [score , f1]\n",
    "        \n",
    "    print(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def Cross_Validation(model,X_train,Y_train) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (sklearn classifier): the model to fit\n",
    "        X_train (list): the train sample\n",
    "        X_test (list): the test sample\n",
    "    Returns:\n",
    "        best_model: the best trained model in the cross validation\n",
    "    \"\"\"\n",
    "    col_names =  ['Accuracy', 'F1 score']\n",
    "    Results = pd.DataFrame(columns = col_names)\n",
    "    best_score = 0\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    skf.get_n_splits(X_train, Y_train) \n",
    "\n",
    "    for train_index, test_index in skf.split(X_train, Y_train):\n",
    "        # split train test\n",
    "        xtrain, xtest = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        ytrain, ytest = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "        # fitting and score for this sample\n",
    "        temp_model = model.fit(xtrain, ytrain)\n",
    "        y_true = ytest\n",
    "        y_pred = model.predict(xtest)\n",
    "        f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "        score = model.score(xtest, ytest)\n",
    "        Results = Results.append(pd.Series([score , f1], index=Results.columns ), ignore_index=True)\n",
    "        #print(\"Accuracy with training set \" + str(score) + \"F1 score with training set \" + str(f1))\n",
    "        if(score > best_score):\n",
    "            best_score = score\n",
    "            best_model = temp_model\n",
    "    print(Results)\n",
    "    return(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verify_results(model,best_model,X,Y) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (sklearn classifier): the model hyperparametered\n",
    "        model (sklearn classifier): the model cross validated\n",
    "        X (list): the test sample\n",
    "        Y (list): the test sample\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    col_names =  ['Accuracy', 'F1 score']\n",
    "    Results = pd.DataFrame(columns = col_names)\n",
    "    y_true = Y\n",
    "    \n",
    "    # score for the first model\n",
    "    y_pred = model.predict(X)\n",
    "    f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "    score = model.score(X, Y)\n",
    "    Results.loc[\"model hyperparametered\"] = [score , f1]\n",
    "    #Results = Results.append(pd.Series([score , f1], index=\"model hyperparametered\" ), ignore_index=True)\n",
    "    \n",
    "    #score for the best model\n",
    "    y_pred = best_model.predict(X)\n",
    "    f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "    score = best_model.score(X, Y)\n",
    "    Results.loc[\"model cross validated\"] = [score , f1]\n",
    "    #Results = Results.append(pd.Series([score , f1], index=\"model cross validated\" ), ignore_index=True)\n",
    "    print(Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice avec le set de données spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv and get the dataframe\n",
    "df = read_csv(\"spam.csv\")\n",
    "# get the train and test sample\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.loc[:, df.columns != 57], df[57], test_size=0.2,stratify=df[57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRésultat du training modèle \n",
      "\u001b[0;0m\n",
      "Accuracy with training set 0.8985507246376812\n",
      "F1 score with training set 0.8976342394048767\n",
      "\n",
      "\n",
      "\u001b[1mRésulat de la cross validation \n",
      "\u001b[0;0m\n",
      "   Accuracy  F1 score\n",
      "0  0.855856  0.852827\n",
      "1  0.864865  0.862897\n",
      "2  0.909910  0.909542\n",
      "3  0.900901  0.898094\n",
      "4  0.886364  0.885758\n",
      "5  0.872727  0.870838\n",
      "6  0.845455  0.845147\n",
      "7  0.927273  0.926970\n",
      "8  0.868182  0.867779\n",
      "9  0.881818  0.881818\n",
      "\n",
      "\n",
      "\u001b[1mDifférence entre les deux modèles \n",
      "\u001b[0;0m\n",
      "                        Accuracy  F1 score\n",
      "model hyperparametered  0.898551  0.897634\n",
      "model cross validated   0.902174  0.901290\n"
     ]
    }
   ],
   "source": [
    "# entraîner le modèle naive bayes\n",
    "print(start + \"Résultat du training modèle \\n\" + end)\n",
    "naive = Naive_Bayes(X_train,Y_train,X_test,Y_test)\n",
    "\n",
    "# faire la cross validation et récupérer le meilleur modèle train\n",
    "\"\"\"\n",
    "    créer un nouveau modèle avec le bon hyperparamètre \n",
    "    surtout pas passer la copie du modèle trainé déjà\n",
    "\"\"\"\n",
    "print(\"\\n\\n\" + start + \"Résulat de la cross validation \\n\" + end)\n",
    "naive_cp = BernoulliNB()\n",
    "best_cross_validated_model = Cross_Validation(naive_cp,X_train,Y_train)\n",
    "\n",
    "# regarder différence entre modèle hyperpamètré et modèle mieux train par cross validation \n",
    "print(\"\\n\\n\" + start + \"Différence entre les deux modèles \\n\" + end)\n",
    "Verify_results(naive,best_cross_validated_model,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRésultat du training modèle knn \n",
      "\u001b[0;0m\n",
      "Accuracy with training set 0.7681159420289855\n",
      "F1 score with training set 0.7673631442068359\n",
      "Le meilleur hyperparamètre est k = 50 \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mDifférent prétraitements selon l'ensemble de donnnées knn \n",
      "\u001b[0;0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaspa\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\gaspa\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\gaspa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  F1 score\n",
      "Aucun prétraitement            0.768116  0.767363\n",
      "MinMaxScaler                   0.882246  0.882933\n",
      "Discrétisation non-supervisée  0.902174  0.449558\n",
      "\n",
      "\n",
      "\u001b[1mRésulat de la cross validation knn \n",
      "\u001b[0;0m\n",
      "   Accuracy  F1 score\n",
      "0  0.734234  0.734475\n",
      "1  0.707207  0.707964\n",
      "2  0.788288  0.787182\n",
      "3  0.707207  0.701550\n",
      "4  0.736364  0.736364\n",
      "5  0.713636  0.712111\n",
      "6  0.727273  0.727764\n",
      "7  0.750000  0.747384\n",
      "8  0.731818  0.726534\n",
      "9  0.795455  0.795643\n",
      "\n",
      "\n",
      "\u001b[1mDifférence entre les deux modèles knn \n",
      "\u001b[0;0m\n",
      "                        Accuracy  F1 score\n",
      "model hyperparametered  0.768116  0.767363\n",
      "model cross validated   0.759058  0.757952\n"
     ]
    }
   ],
   "source": [
    "print(start + \"Résultat du training modèle knn \\n\" + end)\n",
    "knn_model,k = trainingAccuracyAndFscoreKNN(X_train,X_test,Y_train,Y_test)\n",
    "print(\"Le meilleur hyperparamètre est k = \" + str(k) + \" \\n\" )\n",
    "\n",
    "print(\"\\n\\n\" + start + \"Différent prétraitements selon l'ensemble de donnnées knn \\n\" + end)\n",
    "knn_cp = KNeighborsClassifier(n_neighbors=k)\n",
    "trainingPretreatments(knn_cp,False,X_train,X_test,Y_train,Y_test)\n",
    "\n",
    "# faire la cross validation et récupérer le meilleur modèle train\n",
    "\"\"\"\n",
    "    créer un nouveau modèle avec le bon hyperparamètre \n",
    "    surtout pas passer la copie du modèle trainé déjà\n",
    "\"\"\"\n",
    "print(\"\\n\\n\" + start + \"Résulat de la cross validation knn \\n\" + end)\n",
    "knn_cp = KNeighborsClassifier(n_neighbors=k)\n",
    "best_cross_validated_model_knn = Cross_Validation(knn_cp,X_train,Y_train)\n",
    "\n",
    "# regarder différence entre modèle hyperpamètré et modèle mieux train par cross validation \n",
    "print(\"\\n\\n\" + start + \"Différence entre les deux modèles knn \\n\" + end)\n",
    "Verify_results(knn_model,best_cross_validated_model_knn,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice avec le set de données galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv and get the dataframe\n",
    "df = read_csv(\"galaxy_feature_vectors.csv\")\n",
    "# get the train and test sample\n",
    "df = df.drop(0, axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.loc[:, df.columns != 75], df[75], test_size=0.2,stratify=df[75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRésultat du training modèle \n",
      "\u001b[0;0m\n",
      "Accuracy with training set 0.7069781194559432\n",
      "F1 score with training set 0.7054644369172113\n",
      "\n",
      "\n",
      "\u001b[1mRésulat de la cross validation \n",
      "\u001b[0;0m\n",
      "   Accuracy  F1 score\n",
      "0  0.720827  0.719581\n",
      "1  0.725055  0.723974\n",
      "2  0.686622  0.685976\n",
      "3  0.696970  0.696056\n",
      "4  0.695492  0.691052\n",
      "5  0.678994  0.675940\n",
      "6  0.733728  0.732480\n",
      "7  0.717456  0.716758\n",
      "8  0.709320  0.708382\n",
      "9  0.709320  0.708165\n",
      "\n",
      "\n",
      "\u001b[1mDifférence entre les deux modèles \n",
      "\u001b[0;0m\n",
      "                        Accuracy  F1 score\n",
      "model hyperparametered  0.706978  0.705464\n",
      "model cross validated   0.705795  0.704301\n"
     ]
    }
   ],
   "source": [
    "# entraîner le modèle naive bayes\n",
    "print(start + \"Résultat du training modèle \\n\" + end)\n",
    "naive = Naive_Bayes(X_train,Y_train,X_test,Y_test)\n",
    "\n",
    "# faire la cross validation et récupérer le meilleur modèle train\n",
    "\"\"\"\n",
    "    créer un nouveau modèle avec le bon hyperparamètre \n",
    "    surtout pas passer la copie du modèle trainé déjà\n",
    "\"\"\"\n",
    "print(\"\\n\\n\" + start + \"Résulat de la cross validation \\n\" + end)\n",
    "naive_cp = BernoulliNB()\n",
    "best_cross_validated_model = Cross_Validation(naive_cp,X_train,Y_train)\n",
    "\n",
    "# regarder différence entre modèle hyperpamètré et modèle mieux train par cross validation \n",
    "print(\"\\n\\n\" + start + \"Différence entre les deux modèles \\n\" + end)\n",
    "Verify_results(naive,best_cross_validated_model,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRésultat du training modèle knn \n",
      "\u001b[0;0m\n",
      "Accuracy with training set 0.6088113542282673\n",
      "F1 score with training set 0.6054277173551267\n",
      "Le meilleur hyperparamètre est k = 50 \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mDifférent prétraitements selon l'ensemble de donnnées knn \n",
      "\u001b[0;0m\n",
      "                     Accuracy  F1 score\n",
      "Aucun prétraitement  0.608811  0.605428\n",
      "MinMaxScaler         0.902720  0.902742\n",
      "\n",
      "\n",
      "\u001b[1mRésulat de la cross validation knn \n",
      "\u001b[0;0m\n",
      "   Accuracy  F1 score\n",
      "0  0.608567  0.606471\n",
      "1  0.612712  0.610987\n",
      "2  0.628973  0.626560\n",
      "3  0.607539  0.603628\n",
      "4  0.610495  0.608379\n",
      "5  0.627959  0.625280\n",
      "6  0.616124  0.612615\n",
      "7  0.597633  0.594683\n",
      "8  0.619822  0.615945\n",
      "9  0.619083  0.615928\n",
      "\n",
      "\n",
      "\u001b[1mDifférence entre les deux modèles knn \n",
      "\u001b[0;0m\n",
      "                        Accuracy  F1 score\n",
      "model hyperparametered  0.608811  0.605428\n",
      "model cross validated   0.604376  0.601370\n"
     ]
    }
   ],
   "source": [
    "print(start + \"Résultat du training modèle knn \\n\" + end)\n",
    "knn_model,k = trainingAccuracyAndFscoreKNN(X_train,X_test,Y_train,Y_test)\n",
    "print(\"Le meilleur hyperparamètre est k = \" + str(k) + \" \\n\" )\n",
    "\n",
    "print(\"\\n\\n\" + start + \"Différent prétraitements selon l'ensemble de donnnées knn \\n\" + end)\n",
    "knn_cp = KNeighborsClassifier(n_neighbors=k)\n",
    "trainingPretreatments(knn_cp,True,X_train,X_test,Y_train,Y_test)\n",
    "\n",
    "# faire la cross validation et récupérer le meilleur modèle train\n",
    "\"\"\"\n",
    "    créer un nouveau modèle avec le bon hyperparamètre \n",
    "    surtout pas passer la copie du modèle trainé déjà\n",
    "\"\"\"\n",
    "print(\"\\n\\n\" + start + \"Résulat de la cross validation knn \\n\" + end)\n",
    "knn_cp = KNeighborsClassifier(n_neighbors=k)\n",
    "best_cross_validated_model_knn = Cross_Validation(knn_cp,X_train,Y_train)\n",
    "\n",
    "# regarder différence entre modèle hyperpamètré et modèle mieux train par cross validation \n",
    "print(\"\\n\\n\" + start + \"Différence entre les deux modèles knn \\n\" + end)\n",
    "Verify_results(knn_model,best_cross_validated_model_knn,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
