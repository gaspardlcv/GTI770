{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 2 - KNN, NAIVE BAYES, DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "start = \"\\033[1m\"\n",
    "end = \"\\033[0;0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to drop Cabin\n",
    "#titanic.drop(\"Cabin\",axis=1,inplace=True)\n",
    "# function to get the data frame from csv\n",
    "def read_csv(url):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        url (string): the url of the file\n",
    "    Returns:\n",
    "        df: the dataframe filled\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes(X_train,Y_train,X_test,Y_test) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train (list): the train sample\n",
    "        X_test (list): the test sample\n",
    "        Y_train (list): the train output\n",
    "        Y_test (list): the test output\n",
    "    Returns:\n",
    "        clf: the naive bayes model\n",
    "    \"\"\"\n",
    "    clf  = BernoulliNB()\n",
    "    clf1 = GaussianNB()\n",
    "    clf2 = MultinomialNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    clf1.fit(X_train, Y_train)\n",
    "    clf2.fit(X_train, Y_train)\n",
    "    print(\"Accuracy with training set \" + str(clf.score(X_test, Y_test)))\n",
    "    y_true = Y_test\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"F1 score with training set \" + str(f1_score(y_true, y_pred,average=\"weighted\")))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingAccuracyAndFscoreKNN(X_train,X_test,y_train,y_test):\n",
    "    accuracyArray = []\n",
    "    fscoreArray = []\n",
    "    best=0\n",
    "    bestAcc=0\n",
    "    for x in range(1,51):\n",
    "        knn = KNeighborsClassifier(n_neighbors = x)\n",
    "        knn.fit(X_train,y_train)\n",
    "        #accuracy\n",
    "        accuracyArray.append(knn.score(X_test,y_test))\n",
    "        #f1 score\n",
    "        y_true = y_test\n",
    "        y_pred = knn.predict(X_test)\n",
    "        fscoreArray.append(f1_score(y_true,y_pred,average=\"weighted\"))\n",
    "        if accuracyArray[x-1] >= bestAcc:\n",
    "            best = x\n",
    "    \n",
    "    print(\"Accuracy with training set \" + str(accuracyArray[best-1]))\n",
    "    print(\"F1 score with training set \" + str(fscoreArray[best-1]))\n",
    "    knn = KNeighborsClassifier(n_neighbors = best)\n",
    "    knn.fit(X_train,y_train)\n",
    "    return knn, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def Cross_Validation(model,X_train,Y_train) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (sklearn classifier): the model to fit\n",
    "        X_train (list): the train sample\n",
    "        X_test (list): the test sample\n",
    "    Returns:\n",
    "        best_model: the best trained model in the cross validation\n",
    "    \"\"\"\n",
    "    col_names =  ['Accuracy', 'F1 score']\n",
    "    Results = pd.DataFrame(columns = col_names)\n",
    "    best_score = 0\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    skf.get_n_splits(X_train, Y_train) \n",
    "\n",
    "    for train_index, test_index in skf.split(X_train, Y_train):\n",
    "        # split train test\n",
    "        xtrain, xtest = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        ytrain, ytest = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "        # fitting and score for this sample\n",
    "        temp_model = model.fit(xtrain, ytrain)\n",
    "        y_true = ytest\n",
    "        y_pred = model.predict(xtest)\n",
    "        f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "        score = model.score(xtest, ytest)\n",
    "        Results = Results.append(pd.Series([score , f1], index=Results.columns ), ignore_index=True)\n",
    "        #print(\"Accuracy with training set \" + str(score) + \"F1 score with training set \" + str(f1))\n",
    "        if(score > best_score):\n",
    "            best_score = score\n",
    "            best_model = temp_model\n",
    "    print(Results)\n",
    "    return(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verify_results(model,best_model,X,Y) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (sklearn classifier): the model hyperparametered\n",
    "        model (sklearn classifier): the model cross validated\n",
    "        X (list): the test sample\n",
    "        Y (list): the test sample\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    col_names =  ['Accuracy', 'F1 score']\n",
    "    Results = pd.DataFrame(columns = col_names)\n",
    "    y_true = Y\n",
    "    \n",
    "    # score for the first model\n",
    "    y_pred = model.predict(X)\n",
    "    f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "    score = model.score(X, Y)\n",
    "    Results.loc[\"model hyperparametered\"] = [score , f1]\n",
    "    #Results = Results.append(pd.Series([score , f1], index=\"model hyperparametered\" ), ignore_index=True)\n",
    "    \n",
    "    #score for the best model\n",
    "    y_pred = best_model.predict(X)\n",
    "    f1 = f1_score(y_true, y_pred,average=\"weighted\")\n",
    "    score = best_model.score(X, Y)\n",
    "    Results.loc[\"model cross validated\"] = [score , f1]\n",
    "    #Results = Results.append(pd.Series([score , f1], index=\"model cross validated\" ), ignore_index=True)\n",
    "    print(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRésultat du training modèle \n",
      "\u001b[0;0m\n",
      "Accuracy with training set 0.8731884057971014\n",
      "F1 score with training set 0.8719065175014832\n",
      "\n",
      "\n",
      "\u001b[1mRésulat de la cross validation \n",
      "\u001b[0;0m\n",
      "   Accuracy  F1 score\n",
      "0  0.896396  0.894729\n",
      "1  0.869369  0.868978\n",
      "2  0.918919  0.917975\n",
      "3  0.891892  0.891199\n",
      "4  0.868182  0.867480\n",
      "5  0.850000  0.848431\n",
      "6  0.913636  0.913176\n",
      "7  0.877273  0.874855\n",
      "8  0.854545  0.853221\n",
      "9  0.918182  0.917210\n",
      "\n",
      "\n",
      "\u001b[1mDifférence entre les deux modèles \n",
      "\u001b[0;0m\n",
      "                        Accuracy  F1 score\n",
      "model hyperparametered  0.873188  0.871907\n",
      "model cross validated   0.875000  0.873804\n"
     ]
    }
   ],
   "source": [
    "# read the csv and get the dataframe\n",
    "df = read_csv(\"spam.csv\")\n",
    "# get the train and test sample\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.loc[:, df.columns != 57], df[57], test_size=0.2,stratify=df[57])\n",
    "\n",
    "# entraîner le modèle naive bayes\n",
    "print(start + \"Résultat du training modèle \\n\" + end)\n",
    "naive = Naive_Bayes(X_train,Y_train,X_test,Y_test)\n",
    "\n",
    "# faire la cross validation et récupérer le meilleur modèle train\n",
    "\"\"\"\n",
    "    créer un nouveau modèle avec le bon hyperparamètre \n",
    "    surtout pas passer la copie du modèle trainé déjà\n",
    "\"\"\"\n",
    "print(\"\\n\\n\" + start + \"Résulat de la cross validation \\n\" + end)\n",
    "naive_cp = BernoulliNB()\n",
    "best_cross_validated_model = Cross_Validation(naive_cp,X_train,Y_train)\n",
    "\n",
    "# regarder différence entre modèle hyperpamètré et modèle mieux train par cross validation \n",
    "print(\"\\n\\n\" + start + \"Différence entre les deux modèles \\n\" + end)\n",
    "Verify_results(naive,best_cross_validated_model,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRésultat du training modèle knn \n",
      "\u001b[0;0m\n",
      "Accuracy with training set 0.7626811594202898\n",
      "F1 score with training set 0.7636945834808769\n",
      "\n",
      "\n",
      "\u001b[1mRésulat de la cross validation knn \n",
      "\u001b[0;0m\n",
      "   Accuracy  F1 score\n",
      "0  0.738739  0.739984\n",
      "1  0.720721  0.721214\n",
      "2  0.770270  0.769070\n",
      "3  0.716216  0.717375\n",
      "4  0.722727  0.719030\n",
      "5  0.736364  0.735840\n",
      "6  0.709091  0.710085\n",
      "7  0.800000  0.797626\n",
      "8  0.740909  0.740118\n",
      "9  0.704545  0.706173\n",
      "\n",
      "\n",
      "\u001b[1mDifférence entre les deux modèles knn \n",
      "\u001b[0;0m\n",
      "                        Accuracy  F1 score\n",
      "model hyperparametered  0.762681  0.763695\n",
      "model cross validated   0.755435  0.756479\n"
     ]
    }
   ],
   "source": [
    "# read the csv and get the dataframe\n",
    "df = read_csv(\"spam.csv\")\n",
    "# get the train and test sample\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.loc[:, df.columns != 57], df[57], test_size=0.2,stratify=df[57])\n",
    "print(start + \"Résultat du training modèle knn \\n\" + end)\n",
    "knn_model,k = trainingAccuracyAndFscoreKNN(X_train,X_test,Y_train,Y_test)\n",
    "\n",
    "# faire la cross validation et récupérer le meilleur modèle train\n",
    "\"\"\"\n",
    "    créer un nouveau modèle avec le bon hyperparamètre \n",
    "    surtout pas passer la copie du modèle trainé déjà\n",
    "\"\"\"\n",
    "print(\"\\n\\n\" + start + \"Résulat de la cross validation knn \\n\" + end)\n",
    "knn_cp = KNeighborsClassifier(n_neighbors=k)\n",
    "best_cross_validated_model_knn = Cross_Validation(knn_cp,X_train,Y_train)\n",
    "\n",
    "# regarder différence entre modèle hyperpamètré et modèle mieux train par cross validation \n",
    "print(\"\\n\\n\" + start + \"Différence entre les deux modèles knn \\n\" + end)\n",
    "Verify_results(knn_model,best_cross_validated_model_knn,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
